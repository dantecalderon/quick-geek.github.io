<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Artificial intelligence against lies and deceit</title>
  <meta name="description" content="In all the tasks of learning artificial intelligence there is one most unpleasant phenomenon - errors in the marking of the training sequence. These e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="https://quick-geek.github.io/search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <section class="page js-page"><h1>Artificial intelligence against lies and deceit</h1><div class="post__text post__text-html js-mediator-article">  In all the tasks of learning artificial intelligence there is one most unpleasant phenomenon - errors in the marking of the training sequence.  These errors are inevitable, since all the markup is done manually, because if there is a way to mark up real data programmatically, then why do we need someone else to teach them to mark and waste time and money to create an absolutely unnecessary construction! <br><br>  The task of finding and removing fake masks in a large training sequence is quite complex, You can view them all manually, but this will not save you from repeated errors.  But if you look closely at the neural network research tools proposed in <a href="https://habr.com/ru/post/433946/">previous posts</a> , it turns out there is a simple and effective way to detect and extract all the artifacts from the training sequence. <br><br>  And in this post there is a specific example, it is obvious that a simple, on ellipses and polygons, for an ordinary U-net, is again a Lego in the sandbox, but unusually concrete, useful and effective.  We show how a simple method reveals and finds almost all the artifacts, all the lies of the training sequence. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9r/r1/h7/9rr1h7wzzm_tnixujjpx1ow3rge.png" width="300"></div><br>  So, let's begin! <br><a name="habracut"></a><br>  As before, we will study the sequences of the picture / mask pairs.  In the picture in different quarters chosen randomly we will place an ellipse of random size and a quadrilateral also of arbitrary size and both of them are painted in the same color, also randomly chosen from both.  In the second remaining color we paint the background.  Sizes of both ellipse and quad are of course limited. <br><br>  But in this case, we‚Äôll make changes to the steam generation program and prepare together with a completely correct mask an incorrect one, poisoned by a lie - in approximately one percent of cases we replace the quadrilateral with an ellipse in the mask,  The true object for segmentation is the ellipse rather than the quadrilateral on the false masks. <br><br>  <b>Examples of random 10</b> <br><br><img src="https://habrastorage.org/webt/ff/7n/fo/ff7nfoxyodiogbucb6oqivjsm5e.png"><br><br>  <b>Examples of random 10, but from erroneous markup.</b>  <b>The upper mask is true, the lower is false and the numbers in the pictures are in the training sequence.</b> <br><br><img src="https://habrastorage.org/webt/sa/ww/wx/sawwwxtlmqvixgrab-sv3btbfdm.png"><br><br>  for segmentation, we take the same metrics and loss calculation programs and the same simple U-net, just don‚Äôt use Dropout. <br><br><div class="spoiler">  <b class="spoiler_title">Libraries</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> matplotlib.colors <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> NoNorm %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-comment"><span class="hljs-comment">#from joblib import Parallel, delayed from skimage.draw import ellipse, polygon from keras import Model from keras.optimizers import Adam from keras.layers import Input,Conv2D,Conv2DTranspose,MaxPooling2D,concatenate from keras.layers import BatchNormalization,Activation,Add,Dropout from keras.losses import binary_crossentropy from keras import backend as K from keras.models import load_model import tensorflow as tf import keras as keras w_size = 128 train_num = 10000 radius_min = 10 radius_max = 30</span></span></code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Metric and loss functions</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_coef</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> y_true_f = K.flatten(y_true) y_pred = K.cast(y_pred, <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) y_pred_f = K.cast(K.greater(K.flatten(y_pred), <span class="hljs-number"><span class="hljs-number">0.5</span></span>), <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) intersection = y_true_f * y_pred_f score = <span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smooth = <span class="hljs-number"><span class="hljs-number">1.</span></span> y_true_f = K.flatten(y_true) y_pred_f = K.flatten(y_pred) intersection = y_true_f * y_pred_f score = (<span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bce_dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_iou_vector</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(A, B)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Numpy version batch_size = A.shape[0] metric = 0.0 for batch in range(batch_size): t, p = A[batch], B[batch] true = np.sum(t) pred = np.sum(p) # deal with empty mask first if true == 0: metric += (pred == 0) continue # non empty mask case. Union is never empty # hence it is safe to divide by its number of pixels intersection = np.sum(t * p) union = true + pred - intersection iou = intersection / union # iou metrric is a stepwise approximation of the real iou over 0.5 iou = np.floor(max(0, (iou - 0.45)*20)) / 10 metric += iou # teake the average over all images in batch metric /= batch_size return metric def my_iou_metric(label, pred): # Tensorflow version return tf.py_func(get_iou_vector, [label, pred &gt; 0.5], tf.float64) from keras.utils.generic_utils import get_custom_objects get_custom_objects().update({'bce_dice_loss': bce_dice_loss }) get_custom_objects().update({'dice_loss': dice_loss }) get_custom_objects().update({'dice_coef': dice_coef }) get_custom_objects().update({'my_iou_metric': my_iou_metric })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Normal U-net</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(input_layer, start_neurons)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># 128 -&gt; 64 conv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(input_layer) conv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(conv1) pool1 = Conv2D(start_neurons * 1, (2, 2), strides=(2, 2), activation="relu", padding="same")(conv1) # pool1 = Dropout(0.25)(pool1) # 64 -&gt; 32 conv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(pool1) conv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(conv2) pool2 = Conv2D(start_neurons * 1, (2, 2), strides=(2, 2), activation="relu", padding="same")(conv2) # pool2 = Dropout(0.5)(pool2) # 32 -&gt; 16 conv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(pool2) conv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(conv3) pool3 = Conv2D(start_neurons * 1, (2, 2), strides=(2, 2), activation="relu", padding="same")(conv3) # pool3 = Dropout(0.5)(pool3) # 16 -&gt; 8 conv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(pool3) conv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(conv4) pool4 = Conv2D(start_neurons * 1, (2, 2), strides=(2, 2), activation="relu", padding="same")(conv4) # pool4 = Dropout(0.5)(pool4) # Middle convm = Conv2D(start_neurons * 16, (3, 3), activation="relu", padding="same")(pool4) convm = Conv2D(start_neurons * 16, (3, 3) , activation="relu", padding="same")(convm) # 8 -&gt; 16 deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding="same")(convm) uconv4 = concatenate([deconv4, conv4]) # uconv4 = Dropout(0.5)(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3) , activation="relu", padding="same")(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3) , activation="relu", padding="same")(uconv4) # 16 -&gt; 32 deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding="same")(uconv4) uconv3 = concatenate([deconv3, conv3]) # uconv3 = Dropout(0.5)(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3) , activation="relu", padding="same")(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3) , activation="relu", padding="same")(uconv3) # 32 -&gt; 64 deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding="same")(uconv3) uconv2 = concatenate([deconv2, conv2]) # uconv2 = Dropout(0.5)(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3) , activation="relu", padding="same")(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3) , activation="relu", padding="same")(uconv2) # 64 -&gt; 128 deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding="same")(uconv2) uconv1 = concatenate([deconv1, conv1]) # uconv1 = Dropout(0.5)(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3) , activation="relu", padding="same")(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3) , activation="relu", padding="same")(uconv1) # uncov1 = Dropout(0.5)(uconv1) output_layer = Conv2D(1, (1,1), padding="same", activation="sigmoid")(uconv1) return output_layer input_layer = Input((w_size, w_size, 1)) output_layer = build_model(input_layer, 27) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=1e-4), metrics=[my_iou_metric]) model.summary()</span></span></code> </pre> <br></div></div><br>  The program for generating images and masks - true and fake.  In the array is placed the first layer of the picture, the second true mask and the third layer false mask. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair_f</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(idx)</span></span></span><span class="hljs-function">:</span></span> img_l = np.ones((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>)*<span class="hljs-number"><span class="hljs-number">0.45</span></span> img_h = np.ones((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>)*<span class="hljs-number"><span class="hljs-number">0.55</span></span> img = np.zeros((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>) i0_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) i1_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> i0_qua == i1_qua: i1_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) _qua = np.int(w_size/<span class="hljs-number"><span class="hljs-number">4</span></span>) qua = np.array([[_qua,_qua],[_qua,_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>],[_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>,_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>],[_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>,_qua]]) p = np.random.sample() - <span class="hljs-number"><span class="hljs-number">0.5</span></span> r = qua[i0_qua,<span class="hljs-number"><span class="hljs-number">0</span></span>] c = qua[i0_qua,<span class="hljs-number"><span class="hljs-number">1</span></span>] r_radius = np.random.sample()*(radius_max-radius_min) + radius_min c_radius = np.random.sample()*(radius_max-radius_min) + radius_min rot = np.random.sample()*<span class="hljs-number"><span class="hljs-number">360</span></span> rr, cc = ellipse( r, c, r_radius, c_radius, rotation=np.deg2rad(rot), shape=img_l.shape ) p0 = np.rint(np.random.sample()*(radius_max-radius_min) + radius_min) p1 = qua[i1_qua,<span class="hljs-number"><span class="hljs-number">0</span></span>] - (radius_max-radius_min) p2 = qua[i1_qua,<span class="hljs-number"><span class="hljs-number">1</span></span>] - (radius_max-radius_min) p3 = np.rint(np.random.sample()*radius_min) p4 = np.rint(np.random.sample()*radius_min) p5 = np.rint(np.random.sample()*radius_min) p6 = np.rint(np.random.sample()*radius_min) p7 = np.rint(np.random.sample()*radius_min) p8 = np.rint(np.random.sample()*radius_min) poly = np.array(( (p1, p2), (p1+p3, p2+p4+p0), (p1+p5+p0, p2+p6+p0), (p1+p7+p0, p2+p8), (p1, p2), )) rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h[rr_p, cc_p] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l[rr_p, cc_p] img[:,:,<span class="hljs-number"><span class="hljs-number">1</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> img[:,:,<span class="hljs-number"><span class="hljs-number">1</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> img[rr_p, cc_p,<span class="hljs-number"><span class="hljs-number">1</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> img[:,:,<span class="hljs-number"><span class="hljs-number">2</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> p_f = np.random.sample()*<span class="hljs-number"><span class="hljs-number">1000.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p_f &gt; <span class="hljs-number"><span class="hljs-number">10</span></span>: img[rr_p, cc_p,<span class="hljs-number"><span class="hljs-number">2</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: img[rr, cc,<span class="hljs-number"><span class="hljs-number">2</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> i_false[idx] = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> img</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Program for the calculation of the cheat sheet</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_sh</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(f_imgs, f_msks, val_len)</span></span></span><span class="hljs-function">:</span></span> precision = <span class="hljs-number"><span class="hljs-number">0.85</span></span> batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> t = tqdm() t_batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> raw_len = val_len id_train = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-comment"><span class="hljs-comment">#id_select = 1 v_false = np.zeros((train_num), dtype='float') while True: if id_train == 1: fit = model.fit(f_imgs[m2_select&gt;0], f_msks[m2_select&gt;0], batch_size=batch_size, epochs=1, verbose=0 ) current_accu = fit.history['my_iou_metric'][0] current_loss = fit.history['loss'][0] if current_accu &gt; precision: id_train = 0 else: t_pred = model.predict( f_imgs[raw_len: min(raw_len+t_batch_size,f_imgs.shape[0])], batch_size=batch_size ) for kk in range(t_pred.shape[0]): val_iou = get_iou_vector( f_msks[raw_len+kk].reshape(1,w_size,w_size,1), t_pred[kk].reshape(1,w_size,w_size,1) &gt; 0.5) v_false[raw_len+kk] = val_iou if val_iou &lt; precision*0.95: new_img_test = 1 m2_select[raw_len+kk] = 1 val_len += 1 break raw_len += (kk+1) id_train = 1 t.set_description("Accuracy {0:6.4f} loss {1:6.4f} selected img {2:5d} tested img {3:5d} ". format(current_accu, current_loss, val_len, raw_len)) t.update(1) if raw_len &gt;= train_num: break t.close() return v_false</span></span></code> </pre><br></div></div><br>  The main program of calculations.  We made minor changes to the same program from the previous post and some variables require clarification and comment. <br><br><pre> <code class="python hljs">i_false = np.zeros((train_num), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>)</code> </pre> <br>  There is an indicator of the falsity of the mask.  If 1, then the mask from F_msks does not match the mask from f_msks.  This is an indicator of what we are actually looking for - false masks. <br><br><pre> <code class="python hljs">m2_select = np.zeros((train_num), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>)</code> </pre> <br>  Indicator that this picture is selected in the cheat sheet. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> val_len = batch_size + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-comment"><span class="hljs-comment"># i_false - false mask marked as 1 i_false = np.zeros((train_num), dtype='int') # t_imgs, t_msks -test images and masks _txy = [next_pair_f(idx) for idx in range(train_num)] t_imgs = np.array(_txy)[:,:,:,:1].reshape(-1,w_size ,w_size ,1) t_msks = np.array(_txy)[:,:,:,1].reshape(-1,w_size ,w_size ,1) # m2_select - initial 51 pair m2_select = np.zeros((train_num), dtype='int') for k in range(val_len): m2_select[k] = 1 # i_false - false mask marked as 1 i_false = np.zeros((train_num), dtype='int') _txy = [next_pair_f(idx) for idx in range(train_num)] f_imgs = np.array(_txy)[:,:,:,:1].reshape(-1,w_size ,w_size ,1) f_msks = np.array(_txy)[:,:,:,1].reshape(-1,w_size ,w_size ,1) # F_msks - mask array with ~1% false mask F_msks = np.array(_txy)[:,:,:,2].reshape(-1,w_size ,w_size ,1) fig, axes = plt.subplots(2, 10, figsize=(20, 5)) for k in range(10): kk = np.random.randint(train_num) axes[0,k].set_axis_off() axes[0,k].imshow(f_imgs[kk].squeeze(), cmap="gray", norm=NoNorm()) axes[1,k].set_axis_off() axes[1,k].imshow(f_msks[kk].squeeze(), cmap="gray", norm=NoNorm()) plt.show(block=True) false_num = np.arange(train_num)[i_false&gt;0] fig, axes = plt.subplots(3, 10, figsize=(20, 7)) for k in range(10): kk = np.random.randint(false_num.shape[0]) axes[0,k].set_axis_off() axes[0,k].set_title(false_num[kk]) axes[0,k].imshow(f_imgs[false_num[kk]].squeeze(), cmap="gray", norm=NoNorm()) axes[1,k].set_axis_off() axes[1,k].imshow(f_msks[false_num[kk]].squeeze(), cmap="gray", norm=NoNorm()) axes[2,k].set_axis_off() axes[2,k].imshow(F_msks[false_num[kk]].squeeze(), cmap="gray", norm=NoNorm()) plt.show(block=True)</span></span></code> </pre><br>  We build sequences of pairs of picture / mask for training and another sequence for testing.  Those.  We will check on a new, independent sequence of 10,000 pairs.  We display and visually selectively check random pictures with true and false masks.  The pictures themselves are shown above. <br><br>  In this particular case, there were 93 fake masks, in which an ellipse, not a quad, is marked as a mask. <br><br>  We start training on the correct set, as a mask we use f_msks <br><br><pre> <code class="python hljs">input_layer = Input((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>)) output_layer = build_model(input_layer, <span class="hljs-number"><span class="hljs-number">25</span></span>) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>), metrics=[my_iou_metric]) v_false = make_sh(f_imgs, f_msks, val_len) t_pred = model.predict(t_imgs,batch_size=batch_size) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (get_iou_vector(t_msks,t_pred.reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>)))</code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9807 loss 0.0092 selected img 404 tested img 10000 : : 1801it [08:13, 3.65it/s] 0.9895299999999841</code> </pre> <br>  The cheat sheet turned out to be only 404 pictures and obtained acceptable accuracy on an independent test sequence. <br><br>  Now we re-compile the network and train on the same training sequence, but as masks, we feed F_msks with 1% false masks <br><br><pre> <code class="python hljs">input_layer = Input((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>)) output_layer = build_model(input_layer, <span class="hljs-number"><span class="hljs-number">25</span></span>) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>), metrics=[my_iou_metric]) v_false = make_sh(f_imgs, F_msks, val_len) t_pred = model.predict(t_imgs,batch_size=batch_size) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (get_iou_vector(t_msks,t_pred.reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>)))</code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9821 loss 0.0324 selected img 727 tested img 10000 : : 1679it [25:44, 1.09it/s] 0.9524099999999959</code> </pre> <br>  We got a cheat sheet in 727 pictures, which is significantly more and the accuracy of the test predictions, the same as in the previous test, was reduced from 0.98953 to 0.9525.  We added lies to the training sequence by less than 1%, only 93 out of 10,000 masks were lies, but the result worsened by 3.7%.  And this is no longer just a lie, this is the real treachery!  And the cheat sheet has increased from just 404 to 727 already. <br><br>  Soothes and pleases only one <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (len(set(np.arange(train_num)[m2_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>]).intersection(set(np.arange(train_num)[i_false&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>])))) <span class="hljs-number"><span class="hljs-number">93</span></span></code> </pre> <br>  Let me explain this long formula, we take the intersection of the set of pictures selected in the cheat sheet with a lot of false pictures and see that all 93 false pictures the algorithm chose in the cheat sheet. <br><br>  The task was simplified significantly, it is not 10,000 images viewed manually, it‚Äôs only 727 and all the lies are concentrated here. <br><br>  But there is a more interesting and useful way.  When we compiled the cheat sheet, we included only those picture / mask pairs whose prediction is less than the threshold, and in this particular case we saved the prediction accuracy value into the v_false array.  Let's look at the pairs from the training sequence which have a very small prediction, for example, less than 0.1 and see how many lies there are. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (len(set(np.arange(train_num)[v_false&lt;<span class="hljs-number"><span class="hljs-number">0.01</span></span>]).intersection(set(np.arange(train_num)[i_false&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>])))) <span class="hljs-number"><span class="hljs-number">89</span></span></code> </pre> <br><br>  As you can see, the main part of the false masks 89 out of 93 fell into these masks <br><pre> <code class="python hljs">np.arange(train_num)[v_false&lt;<span class="hljs-number"><span class="hljs-number">0.01</span></span>].shape (<span class="hljs-number"><span class="hljs-number">382</span></span>,)</code> </pre> <br>  Thus, if we test only 382 masks manually, and this is from 10,000 pieces, then most of the false masks will be identified and destroyed by us without any pity. <br><br>  If it is possible to view pictures and masks while making decisions about their inclusion in the cheat sheet, then starting with a certain step, all the false masks, all lies will be determined by the minimum level of prediction already a little trained network, and the correct masks will have a prediction greater than this level . <br><br><h3>  Let's sum up </h3><br>  If in some imaginary world truth is always quadrangular, and oval lies and some unknown entity decided to distort the truth and called some ellipses true, and quadrilaterals are false, then using artificial intelligence and natural ability to make cheat sheets, the local inquisition will quickly and easily find and eliminate lies and deceit completely and cleaned. <br><br>  PS: The ability to detect ovals, triangles, simple polygons is a necessary condition for creating any AI driving a car.  If you don‚Äôt know how to search for ovals and triangles, you won‚Äôt find all the road signs and your AI will not go there by car. </div><p>Source: <a href="https://habr.com/ru/post/440120/">https://habr.com/ru/post/440120/</a></p>
<section class="navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container">Waiting for the list from <a href="../../index.html">here</a>...</nav>
</section>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52319614 = new Ya.Metrika({
                  id:52319614,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52319614" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>
</body>

</html>
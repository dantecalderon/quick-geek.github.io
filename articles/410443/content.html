<div class="post__text post__text-html js-mediator-article"><h2>  Artificial intelligence is a moving target.  And so, how best to aim at it. </h2><br><img src="https://habrastorage.org/getpro/geektimes/post_images/7e7/850/e0b/7e7850e0bd059d86738cf869053b51ae.jpg"><br><br>  It seems that artificial intelligence (AI) surrounds us from all sides.  We run into him at home and on the phone.  We don’t have time to come to our senses - if we are to believe entrepreneurs and business innovators - how AI will be present in almost all products and services that we buy and use.  In addition, the <a href="https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/ask-the-ai-experts-what-are-the-applications-of-ai">area of ​​its application to solving business problems is</a> growing by leaps and bounds.  At the same time, doubts are growing about the consequences of the appearance of AI;  we worry about how automation will affect the workplace, job availability and society. <br><br>  Sometimes reality is lost between the fears and the triumphs of the headlines telling about Alexa, Siri and AlphaGo, since AI-technology - machine learning and its subset, in-depth learning - there are many limitations that need to be spent to overcome them.  This article describes such limitations, and it should help directors better understand what is hindering their attempts at introducing AI.  We will also describe promising breakthroughs aimed at removing some restrictions and creating a new wave of opportunities. <br><a name="habracut"></a><br>  Our perspectives depend on a combination of work in the forefront - research, analysis, evaluating hundreds of actual use cases - and working together with some advanced thinkers, scientists and engineers working in advanced areas associated with AI.  We tried to extract the essence of their experience and help the directors of enterprises, who, as our experience shows, are often guided only by their own initiative and do not always understand well where the leading edge is or what is already available for AI. <br><br>  Simply put, the problems and limitations of AI create for the leaders the problem of a "moving target": it is difficult for them to reach the leading edge, because it constantly moves.  Frequently, disappointment also occurs when attempts to use AI stumble on the barriers of the real world — this can reduce motivation for further investment or lead to a wait and see point of view, while others will continue to rush forward.  A recent <a href="https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/how-artificial-intelligence-can-deliver-real-value-to-companies">study by the</a> McKinsey World Institute shows that there is a growing gap between leaders and laggards in the use of AI — and this can be seen in the comparison of different industries, and within each of them (Exhibit 1). <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/b82/01c/117/b8201c1178e980ad27b6a9ceda35ba66.svg"><br>  <i>Exhibit 1: In the near future, the leaders of AI are going to invest even more in it.</i>  <i>Vertical: estimate of the increase in spending on AI in% over the next three years;</i>  <i>horizontal: percentage of companies already using AI</i> <br><br>  Directors trying to narrow the gap should be able to work with AI in an informed way.  In other words, they need to understand not only in which areas of AI can spur innovation, ideas and decision making, lead to increased profits and efficiency - but where AI is still not able to help.  Moreover, they must accept the interrelationship and differences between technical and organizational constraints — cultural barriers, lack of staff capable of creating ready-made AI solutions for businesses, and the “last mile” problem of integrating AI into products and processes.  If you want to become a leader who understands some of the critical technical problems that slow down the progress of AI, and are ready to take advantage of promising developments that can overcome these limitations and potentially change the trajectory of the development of AI, read on. <br><br><h2>  Problems, limitations and opportunities </h2><br>  A useful benchmark will be to understand the recent advances in deep learning technology (GD).  These are probably the most exciting developments in the field of AI, and they have achieved an explosive increase in efficiency in matters of classifications and predictions, without traditional training under supervision.  GO uses large-scale neural networks capable of containing millions of simulated "neurons" distributed in layers.  The most common network options are called <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25B2%25D1%2591%25D1%2580%25D1%2582%25D0%25BE%25D1%2587%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25B5%25D0%25B9%25D1%2580%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C">convolutional neural networks</a> (SNS) and <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B5%25D0%25BA%25D1%2583%25D1%2580%25D1%2580%25D0%25B5%25D0%25BD%25D1%2582%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25B5%25D0%25B9%25D1%2580%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C">recurrent neural networks</a> (PHS).  These neural networks are trained using training data and <a href="https://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4_%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D1%2582%25D0%25BD%25D0%25BE%25D0%25B3%25D0%25BE_%25D1%2580%25D0%25B0%25D1%2581%25D0%25BF%25D1%2580%25D0%25BE%25D1%2581%25D1%2582%25D1%2580%25D0%25B0%25D0%25BD%25D0%25B5%25D0%25BD%25D0%25B8%25D1%258F_%25D0%25BE%25D1%2588%25D0%25B8%25D0%25B1%25D0%25BA%25D0%25B8">back-propagation algorithms</a> . <br><br>  Although impressive progress has been made in this area, much remains to be done.  The critical moment is to fine-tune the AI ​​to a specific task and available data.  Since these systems are not programmed, but are trained, various processes for their work to accurately perform complex tasks often require a huge amount of tagged data.  Getting a large dataset can be tricky.  In some areas, they simply may not be, but even if they are, a huge amount of human resources can go to the design of tags. <br><br>  In addition, in these models, it can be difficult to decipher how a mathematical model trained with GO comes to a certain prediction, recommendation, or solution.  The usefulness of a black box, even if it fulfills its purpose, may be limited, especially in cases where its predictions or decisions affect the community and have consequences related to human health.  In such cases, the user often needs to know “why” —for example, exactly how the algorithm came to such recommendations — if his actions may have legal or regulatory implications.  Why certain factors, and not some other, turned out to be critical in this case. <br><br>  Let's look at five interconnected factors in which these limitations and the emerging workarounds begin to play a role. <br><br><h2>  Restriction 1: data markup </h2><br>  Most modern AI models are trained with the help of “supervised learning”.  This means that people need to tag and categorize source data - and such work can be difficult and error-prone.  For example, companies that develop ro-mobiles hire hundreds of people who manually mark many hours of video recordings to help train these systems.  At the same time, new promising technologies are emerging - for example, streaming control (demonstrated by Eric Horvitz and colleagues from Microsoft Research), in which data can be tagged during natural use.  Uncontrolled or partially controlled approaches reduce the need for large tagged data sets.  Two promising technology - <a href="https://ru.wikipedia.org/wiki/%25D0%259E%25D0%25B1%25D1%2583%25D1%2587%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_%25D1%2581_%25D0%25BF%25D0%25BE%25D0%25B4%25D0%25BA%25D1%2580%25D0%25B5%25D0%25BF%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5%25D0%25BC">training with reinforcements</a> and <a href="https://ru.wikipedia.org/wiki/%25D0%2593%25D0%25B5%25D0%25BD%25D0%25B5%25D1%2580%25D0%25B0%25D1%2582%25D0%25B8%25D0%25B2%25D0%25BD%25D0%25BE-%25D1%2581%25D0%25BE%25D1%2581%25D1%2582%25D1%258F%25D0%25B7%25D0%25B0%25D1%2582%25D0%25B5%25D0%25BB%25D1%258C%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C">generative-adversary network</a> . <br><br>  Training with reinforcements.  This unsupervised learning technique allows algorithms to learn simply by trial and error.  The methodology uses the carrot and stick method: for each attempt to perform a task, the algorithm receives a reward (for example, a high score) if its behavior was successful, or a punishment - otherwise.  As the number of repetitions grows, efficiency also grows, and in many cases it exceeds the capabilities of a person — as long as the learning environment corresponds to the real world. <br><br>  Training with reinforcements is famous for the use of computer games when training computers - recently, GO has also been integrated into this scheme.  In May 2017, for example, this helped the <a href="https://ru.wikipedia.org/wiki/AlphaGo">AlphaGo</a> AI system beat the world champion <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D1%258D_%25D0%25A6%25D0%25B7%25D0%25B5">Ke Ze</a> in a go game.  As another example, Microsoft began providing reinforced training services that adapt to user preferences.  The potential application of reinforcement training is suitable for various types of enterprises.  Opportunities include: securities trading using AI, which gains or loses points for acquiring or losing finances;  product recommendation engine, receiving points for each sale made on the recommendation;  Software building routes for trucking, receiving a reward for deliveries made on time or reducing fuel consumption. <br><br>  Reinforcement training can also help the AI ​​to exceed the natural and social limitations of human markup by developing solutions that no one has thought of before, and strategies that even experienced players did not think of using.  Recently, for example, the AlphaGo Zero system, using learning with reinforcements of a new type, defeated its predecessor AlphaGo, learning to play it from scratch.  It meant starting with a completely random game with itself, instead of training in games played by people and with people. <br><br>  Generative Competition Networks (GSS).  In this model of training with partial control, two networks compete with each other for the improvement and clarification of their understanding of a certain concept.  For example, in order to recognize how birds look, one network tries to find differences between real and fake images of birds, and its competitor tries to deceive it by giving out pictures that are very similar to images of birds, but are not.  When the two networks begin to draw, the representation of the bird in each model becomes more accurate. <br><br>  The ability of the GSS to produce increasingly plausible examples of data can significantly reduce the need for people to mark up data sets.  For example, to train a tumor recognition algorithm on medical images would usually require millions of images marked up by people, where the types and stages of tumor development would be indicated.  Using the GSS, trained to produce more and more realistic images of various types of tumors, researchers can train a tumor recognition algorithm that combines a much smaller database of human-tagged data with output from the GSS. <br><br>  And although the use of GSS for making accurate diagnoses of diseases is still far from implementation, researchers are already starting to use GSS in more and more complex contexts.  These include: understanding and producing works of art in the style of a particular artist;  the use of satellite images and recognition of geographic features to create actual maps of rapidly developing territories. <br><br><h2>  Limit 2: Get massive training datasets </h2><br>  It has already been shown that simple AI technologies using linear models may in some cases come close to the capabilities of medical experts in other areas.  The current wave of machine learning, however, requires training data sets — not only labeled, but also large in number, as well as comprehensive.  GO methods require thousands of records to produce relatively good models capable of classification, and in some cases millions of records in order to get closer to the level of a person. <br><br>  The difficulty is that such massive data sets can be difficult to obtain or create in many commercial cases.  Each small change in a task can demand other large data set and new trainings.  For example, learning autonomous vehicles to move around a mining site, where the weather changes often, may require a set of data that includes various environmental conditions that a machine may encounter. <br><br>  <a href="https://en.wikipedia.org/wiki/One-shot_learning">One-shot learning</a> can reduce the need for large data sets and allow the AI ​​model to learn the features of an object in a <a href="https://blog.openai.com/robots-that-learn">small number of real demonstrations</a> or examples (in some cases, even one).  The capabilities of AI will approach a person who is able to accurately recognize various members of the same category after he becomes acquainted with only one example - say, one pick-up truck.  In this methodology, which is still under development, scientists first pre-train models in simulated virtual reality, in which there are task variants, or, in the case of pattern recognition, an image of an object.  Then, after the models demonstrate several variants of the object in the real world, which the AI ​​did not see in virtual reality, he will use the existing knowledge to make the right decision. <br><br>  This kind of learning from one point of time can, as a result, help to create a system that scans texts for copyright infringement or recognizes a corporate logo in a video clip, after getting acquainted with just one example of it.  Today, such applications are in their early stages.  But their benefits and effectiveness can quickly expand the possibilities of using AI in various industries. <br><br><h2>  Restriction 3: the problem of explicability </h2><br>  Explainability is not a new problem for AI systems.  But it grows with the success and acceptance of HE, because of which not only the diversity of applications increases, but also their opacity.  The larger and more complex the model, the more difficult it is to explain in human terms why this or that decision was made (it is even more difficult to do this if everything happens in real time).  This is one of the reasons why the use of some AI tools is not so much expanded in those areas where explanability is useful or even necessary.  Moreover, with the expansion of AI applications, the requirements of regulators can also increase the need for AI models with a greater level of intelligibility. <br><br>  Two nascent promising approaches to increasing model transparency are locally interpretable model-agnostic explanations (LIME) and attentional techniques (Exhibit 2).  LIME is trying to determine on which parts of the input data the trained model basically bases its calculations in order to work out an intermediate, interpretable model.  This technique looks at several data segments at a time and observes how the results of the predictions change to fine-tune the intermediate model and work out a more accurate interpretation (for example, excluding the eyes instead of the nose, to check which of them is more important for face recognition).  Attention techniques visualize the parts of the input data that the model mainly relies on when making a certain decision (for example, concentrating on the mouth to determine if the person is depicted in the picture). <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/144/3ca/670/1443ca6704b63030a2e8d2c50ab3415c.svg"><br>  <i>Exhibit 2</i> <br><br>  Another technology that has been used for some time is <a href="https://en.wikipedia.org/wiki/Generalized_additive_model">generalized additive models</a> (OAM).  Using models with one feature, OAM limits the interaction of features, with the result that each of them becomes more interpretable for users.  It is expected that the adoption of these and other technologies, seeking to remove the veil of mystery from AI, will greatly help to increase the use of AI. <br><br><h2>  Restriction 4: generalizability of learning </h2><br>  Unlike people, AI models hardly transfer their experience from one set of circumstances to another.  In fact, everything that the model has achieved in a particular application case remains applicable only to this case.  As a result, companies have to constantly spend resources on training the next model, although the tasks for their use are very similar. <br><br>  One promising answer to this challenge is transferable learning.  In this approach, the AI ​​model is trained to solve a specific task, and then quickly apply this training to similar, but different work.  Researchers at DeepMind demonstrated promising results with the transfer of training in experiments in which training with the use of virtual reality was transferred to the management of real robotic limbs. <br><br>  Portable learning and other generic approaches are evolving, and they can help organizations more quickly create new ways of applying and add new functionality to existing and working methods.  For example, when creating a virtual assistant, transferable learning can summarize user preferences from one area (say, music) to another (say, to books).  Examples of use are not limited to digital products.  Portable training can help, for example, oil and gas companies to extend the use of AI algorithms, trained in predictive well maintenance, to other equipment - for example, to pipelines and drilling platforms.  Portable learning, even in principle, can revolutionize business intelligence: imagine an AI tool that analyzes data and understands how to optimize airline profits, adapt your model to changes in weather or local economies. <br><br>  Another approach is to use something that roughly describes a generalized structure as applied to various problems.  For example, AlphaZero from DeepMind used the same structure for three different games: using this generalized structure, it was possible to train a model of a game of chess in one day so that it would then win the world champion program. <br><br>  Finally, imagine the possibilities of emerging meta-learning techniques trying to automate the development of machine learning models.  For example, the Google Brain team uses AutoML to automate the development of neural networks to classify images on large-scale data sets.  Today, these techniques work as well as those developed by humans.  This development looks promising, especially due to the fact that many organizations are experiencing a shortage of talented workers.  It is also possible that meta-learning will exceed the capabilities of the person and improve the results.  It is important to understand that these technologies are still in the early stages of development. <br><br><h2>  Restriction 5: bias data and algorithms </h2><br>  So far, we have focused on constraints that can be overcome by technical methods that are already in development, some of which we have described.  Bias is a different kind of problem.  Potentially disruptive social consequences can await us when human addictions (conscious or unconscious) determine which data to use and which to ignore.  Moreover, when the process and frequency of data collection varies depending on different groups and behavior, problems can be expected with how the algorithms will analyze this data, learn from it, and make predictions.  Adverse effects include hiring decisions based on misinformation, distorted scientific or medical predictions, incorrect financial models and decisions on criminal cases, and incorrect legal decisions.  In many cases, this bias remains undetected or ignored under the sauce of “advanced data science,” “proprietary data and algorithms,” or “objective analysis.” <br><br>  By expanding machine learning and AI algorithms in new areas, we may encounter new manifestations of these bias problems encountered in data sets and algorithms.  And they usually remain there, because in order to recognize them and take steps to eliminate them, it is necessary to deeply understand both the data processing technologies and the existing social interactions, including the data collection process itself.  In general, bias is one of the most difficult obstacles, and definitely the most socially burdensome. <br><br>  Now there is a lot of research, both theoretical and collecting data on the best methods of using AI, trying to solve the described problems in the academic, non-profit and private areas.  And it's time to go - this problem is likely to become more and more critical, and raise more and more questions.  Consider, for example, the fact that many of these predictive approaches based on learning and statistics, tacitly assume that the future looks like the past.  And what will we do in the socio-cultural environment, when the actions we take will change it - and where decisions based on past behavior can slow down progress (or, even worse, develop resistance to change)?  Many leaders, including business leaders, may soon face the need to find answers to such questions. <br><br><h2>  How to hit a moving target </h2><br>  The emergence of solutions for the described limitations and the spread of commercial implementation of the advanced developments indicated here can take years.  But an exciting range of possibilities associated with the use of AI, suggests that the most important limitation of AI may be the imagination.  Here are some tips for leaders trying to be at the forefront, or at least keep up with leading trends. <br><br><h3>  Learn new information, adjust, keep up. </h3><br>  Although most company directors do not need to know the difference between convolutional and recurrent neural networks, you need to be generally familiar with the capabilities of modern tools, have a general feeling of when breakthroughs can occur in the short term, and see the perspectives of what lies beyond the horizon.  Interview your data and machine learning experts, talk to the AI ​​pioneers, to tune in to current knowledge, visit a couple of AI conferences to get information about the real facts;  news articles may be helpful, but may also be part of the hype.  Another good way to keep up with new developments is research conducted by knowledgeable experts, such as the <a href="http://aiindex.org/">AI Index</a> (the project of the <a href="https://ai100.stanford.edu/">Hundred Years Study of AI</a> from Stanford). <br><br><h3>  Start using a sophisticated data strategy. </h3><br>  AI algorithms require assistance in disclosing new ideas that are hidden in the data created by your system.  They can be helped by developing a comprehensive data management strategy that focuses not only on the technologies needed to collect data from individual systems, but also on data availability, their acquisition system, markup and management.  And although new technologies promise to reduce the amount of data needed to train AI algorithms, controlled learning, which requires large amounts of data, is still the dominant technology.  And even technologies aimed at minimizing the required amount of data still need some kind of data.  Therefore, the key point of all this will be accurate knowledge of your own data and how best to use it. <br><br><h3>  Think outside the box. </h3><br>  Techniques for transferring training are still in their infancy, but there is always the opportunity to achieve solutions using AI in several areas, and not just in one.  If you have solved this problem, such as predictive equipment maintenance in a large warehouse, can this solution be applied to consumer products?  Is it possible to use effective tips “what else to buy” in several product distribution channels? Поощряйте отделения компании делиться друг с другом знаниями, которые могут раскрыть способы использования лучших ИИ-решений и идей в нескольких областях вашей компании. <br><br><h3> Станьте новатором. </h3><br> Просто не отставать от современных ИИ-технологий и примеров использования не достаточно для того, чтобы оставаться конкурентоспособным в долгосрочной перспективе. Убедите ваших специалистов по обработке данных или договоритесь со сторонними экспертами на решение полезной задачи при помощи зарождающихся технологий – таких, например, которые были упомянуты в этой статье. Постоянно узнавайте о том, что можно сделать и что стало доступным. Многие инструменты машинного обучения, наборы данных и модели, натренированные для стандартного применения (включая речь, зрение и распознавание эмоций) уже доступны для широкого пользователя. Иногда они доступны в виде проектов с исходным кодом, в других случаях – через программные интерфейсы (API), созданные передовыми исследователями и компаниями. Следите за этими возможностями, они могут помочь вам заметить преимущества для первопроходцев. <br><br> Перспективы ИИ огромны, а технологии, инструменты, и процессы, требуемые для претворения этих обещаний в жизнь, пока ещё не полностью готовы. Если вы думаете, что можете подождать, дать технологии полностью оформиться, а потом успешно воспользоваться ею одним из первых – подумайте заново. Очень сложно совершить прыжок из стоячего положения, особенно если цель движется очень быстро, а вы не понимаете, что могут и чего не могут делать современные технологии ИИ. И пока исследователи и пионеры в области ИИ подготовились к решению самых острых из сегодняшних проблем, пора начинать понимать, что происходит на переднем крае ИИ, чтобы вы смоли правильно настроить свою организацию, и помочь ей обучиться новым возможностям, использовать их и может даже продвигать их дальше. </div>
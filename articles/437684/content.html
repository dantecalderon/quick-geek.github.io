<div class="post__text post__text-html js-mediator-article">  Good time to read, dear users of Habr! <br><br>  The article is devoted to the book "High Algorithm", Pedro Domingos (Pedro Domingos), translation of the book "The Master Algorithm" <br><br>  The author devotes a book to the memory of his sister, and the main leitmotif of the book is the use of machine learning to search for means of combating diseases. <br><a name="habracut"></a><br>  In the prologue, the author shows the existing applications of machine learning. <br><blockquote>  Machine learning is a technology that builds itself.  This is new <br>  phenomenon in our world. </blockquote><blockquote>  Learning algorithms - artifacts that create other artifacts </blockquote><br>  In the first chapter, the author describes the increasing complexity of software algorithms - spatial, temporal, human (the ability to detect errors). <blockquote>  Learning algorithms are those that create other algorithms that are trained on the basis of data. </blockquote>  The controversial thesis is given: <blockquote>  Someday the inevitable will happen: the learning algorithms will become an indispensable intermediary and power will be concentrated in them </blockquote>  The second chapter provides the central hypothesis of the book: <blockquote>  All knowledge — past, present, and future — can be extracted from the data with one universal learning algorithm. </blockquote>  Arguments from the fields of neurobiology, evolution, physics, statistics, computer science are given. <blockquote>  As Isaiah Berlin remarked, some thinkers are like foxes and know many different things, and some are hedgehogs who know one thing, but important </blockquote><blockquote>  The universal learning algorithm is an incredibly powerful weapon against Monster Difficulty. </blockquote>  Lists the five identified types of machine learning: <blockquote>  The search for the High Algorithm is difficult, but they are revived by the rivalry of various scientific schools operating in the field of machine learning.  The most important of them are symbolists, connectionists, evolutionists, Bayesians and analogists. </blockquote><blockquote>  For symbolists, intellect is reduced to the manipulation of symbols - this is how mathematicians solve equations, replacing one expression with another </blockquote><blockquote>  For connectionists, learning is what the brain does, and therefore they believe that this organ should be reproduced by reverse engineering. </blockquote><blockquote>  Evolutionists believe that the mother of learning is natural selection. </blockquote><blockquote>  Bayesians are primarily concerned with uncertainty. </blockquote><blockquote>  For analogists, the key to learning is to find similarities between different situations and thereby logically derive other similarities. </blockquote>  Further, in five chapters, the main methods for each type of approach are considered, after which the author describes his own way of combining them based on Markov's logical networks: <blockquote>  To summarize, the unified machine learning algorithm to which we arrived uses the Markov logical network as a representation, the a posteriori probability, and the optimizer in it — the genetic search in combination with gradient descent — as the evaluation function </blockquote>  The tenth chapter describes the benefits in a world equipped with good learning algorithms. <br><br>  Why abstract biased?  Because I took the described algorithms as a basis, but instead of compressing them into one, I proposed to build a pipeline out of them :) </div>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Manage secrets with HashiCorp Vault</title>
  <meta name="description" content="How to keep secrets? In the repository, in the deployment system or in the configuration management system? On a personal computer, on servers, and ma...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="https://quick-geek.github.io/search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <section class="page js-page"><h1>Manage secrets with HashiCorp Vault</h1><div class="post__text post__text-html js-mediator-article">  How to keep secrets?  In the repository, in the deployment system or in the configuration management system?  On a personal computer, on servers, and maybe in a box under the bed?  How to manage secrets to prevent leaks? <br><br>  <strong>Sergey Noskov ( <a href="https://habr.com/ru/users/albibek/" class="user_link">Albibek</a> ) - head of the group of information security platform from Avito</strong> , knows the answer to these questions and will share with us.  In Avito, two years have been actively using HashiCorp Vault, during which time lumps have been made, and they have pumped the experience up to the ‚ÄúMaster‚Äù level. <br><br>  In the article we will talk comprehensively about Vault: what it is, where and how it is used in the company, how Avito manage secrets with the help of HashiCorp Vault, how Puppet and Kubernetes are used, use cases with Puppet and other SCM, what problems arise, what hurts the security men and developers, and, of course, share ideas on how to fix it. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/oDdDPU6moTs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><a name="habracut"></a><h2>  What is the secret </h2><br>  Any confidential information: <br><br><ul><li>  login and password, for example, to the database; </li><li>  API keys; </li><li>  server certificate key (* .google.com); </li><li>  client certificate key (partners, Yandex money, QIWI); </li><li>  key for signing mobile apps. </li></ul><br>  All the information that we want to keep secret, we call a secret.  This creates a problem with storage: storing badly in the repository, in encrypted form - you need to keep the encryption keys somewhere. <br><br>  <strong>HashiCorp Vault</strong> is one of the good solutions to the problem. <br><br><ul><li>  Safely stores and manages keys. </li><li>  It is sharpened on the world of microservices, as microservice in itself. </li><li>  In <strong>HashiCorp Vault, a</strong> lot has been done to authenticate and authorize access to secrets, for example, ACL and the principle of minimal privileges. </li><li>  REST interface with JSON. </li><li>  Security is not perfect, but at a high enough level. </li></ul><br>  In my opinion, this is quite a convenient tool. <br><br><h2>  What's new in HashiCorp Vault <br></h2><br>  The tool is developing and lately many interesting features have appeared in it: CORS headers for GUI without intermediaries;  built-in GUI;  native integration with Kubernetes;  plugins for logical- and auth-backends and frameworks. <br><br>  Most of the changes that I personally liked were the <strong>possibility not to write extensions and add-ons</strong> that would stand outside the tool. <br><br>  For example, there is a Vault, you want to expand it - write additional logic or your UI for automation, which will automate something.  Before the changes, we had to raise an additional service that stands before the Vault, and proxies all requests: first, requests go to the service, then to Vault.  This is bad because there may be a reduced level of security in the intermediate service, and all the secrets go through it.  <strong>Security risks are much higher when the secret passes through several points at once!</strong> <br><br><h2>  Chicken and egg problem <br></h2><br>  When you raise the issue of storing confidential information and decide to encrypt, then as soon as you encrypt something, your secret shifts from the location of the encryption to where the key is stored.  This happens all the time: as soon as you keep a secret somewhere or change an existing one, you have another one and the vicious circle begins - <strong>where to keep the secret for accessing the secret</strong> . <br><br>  The secret to accessing a secret is that part of security called <strong>authentication</strong> .  Security has another part - <strong>authorization.</strong>  The authorization process checks if the user can access exactly where he is requesting.  In the case of Vault, there is a trusted third party who decides whether to give a secret or not.  Authorization only partially solves the problem. <br><br><h2>  HashiCorp Vault in Avito <br></h2><br>  In Avito, HashiCorp is installed in a single large installation on the entire network.  HashiCorp Vault has many different backends.  We use the <strong>Consul</strong> backend from HashiCorp, too, because Vault can only maintain its own fault tolerance through Consul. <br><br>  <strong>Unseal</strong> is a way to not keep a master key in one place.  When Vault is launched, it encrypts everything on some key, and the chicken and egg problem again appears: where to keep the secret, which will encrypt all the other secrets.  To avoid this problem, Vault has a composite key, which requires several parts of the key, which we distribute to several employees.  In Avito, we set up Unseal options for 3 people out of 7. If we launch Vault, then in order for it to start working, at least 3 people must come and enter their part of the key.  The key is divided into 7 parts and you can bring any of them. <br><br>  We have compiled a small test Vault - a sandbox for developers where they can play.  It is in the form of a Docker container and creates simple secrets so that people can touch the tool with their hands, get comfortable.  In the sandbox there is no Consul and clustering, it‚Äôs just the file system on which Vault holds the encrypted secrets, and a small script for initialization. <br><br>  This is what we currently store in Vault: <br><br><ul><li>  Practically all secrets for Kubernetes microservices: passwords for databases, API keys, everything listed above. </li><li>  Secrets for calculations on the "iron" servers and LXC. </li><li>  Secrets for CI / CD builds in TeamCity, we also put in Vault.  Coverage is not 100%, but quite acceptable. </li><li>  Keys of all certificates: internal PKI, external CA, for example, GeoTrust and the like. </li><li>  Shared secrets for teams. </li></ul><br>  Inside itself, Vault stores everything only in JSON, it is not always convenient and requires additional actions from the developer, so basically we post the secrets as a file. <br><br><blockquote>  We try to deliver secrets in the form of files. <br></blockquote><br>  We do not tell the developer: ‚ÄúGo to Vault, take the secret!‚Äù, But put the file on the disk and inform you: ‚ÄúDeveloper, you will have a file on the disk, take the secret from it, and we will figure out how to get it from the Vault and bring you". <br><img src="https://habrastorage.org/webt/rg/9o/mj/rg9omjizdszcnw0lzrr_iogfosc.png"><br><br>  We have adopted a simple agreement for JSON fields, in which we indicate with what rights to upload the file.  This is the metadata for the file system, and the data field is an encoded string with the secret itself, which will become the contents of the file. <br><br><h2>  Puppet + Hiera + Vault <br></h2><br>  Almost the entire Avito infrastructure uses Puppet, all servers are rolled out to them. <br><br>  Puppet has a handy hierarchy tool - <strong>Hiera</strong> .  Vault integrates very well with Hiera through an add-on module, because the key-value query is being sent to this library, and Vault is the key-value base itself, but with all the security features - with transparent encryption and the ability to choose access to the keys. <br><br>  Therefore, the first thing we implemented is Vault in Puppet, but with one addition - we have an intermediate layer called the <strong>Router backend</strong> .  Router backend is a separate Hiera module, just files on the disk in which it is written where Hiera should go after the key - to the Vault or to another location. <br><br>  He needed to Hiera did not go to the Vault all the time, because it always goes across the hierarchy.  This is not a problem of Vault or the load on it, but a feature of the work of Hiera itself.  Therefore, if you leave only the module for the Vault without the Router backend, the Puppet master will take a very long time to build the configuration for the Puppet agent, since it will check each key in the Vault. <br><img src="https://habrastorage.org/webt/dv/di/f6/dvdif6z09jpflg98zykbwf7l7cq.png"><br><br>  For Puppet, the chicken and egg problem is solved by the fact that the authorizing party is Puppet-master.  It is he who gives the secret to access the secret.  The puppet master has access to all the secrets at once, but each host is allowed to receive only the one that is intended for it.  The host on the Puppet master is already authorized by its certificate, which is generated locally and does not leave the host limits.  In principle, the secret for accessing the secret remains, but this is not so critical. <br><br>  Our process of laying out a new secret in Puppet consists of the following steps. <br><br><ul><li>  We take a secret somewhere - someone gives it to us or spreads it. </li><li>  Put the secret in Vault, with a hierarchy like in Hiera: <strong>/puppet/role/www/site.ssl.key</strong> . </li><li>  We register the prefix in the manifest Puppet, indicating that the file is in Vault and where to get it. </li><li>  Register in YAML for Hiera router the path to the Vault and point to the backend so that Hiera can find it. </li><li>  Pull request via GIT into the manifest repository. </li><li>  We run or wait for the Puppet agent to run. </li></ul><br>  Puppet agents are run every 30 minutes, so you have to wait a bit until the secret rolls out.  This does not cause problems - <strong>we do not lay out secrets every day</strong> .  While Kubernetes is not included in the case, there is little overhead and we are ready to lay out the secrets in the Vault with our hands with minimal automation. <br><br>  An additional advantage is that we get the ‚Äúchip‚Äù of Hiera - the <strong>secret can be laid out immediately for a group of hosts</strong> or, depending on the role of the host, which we set in the role variable. <br><br>  The only <strong>danger is</strong> that if you have Puppet, and you use Hiera, do not substitute anything into the templates for variables, because many facts and variables are collected on the client side.  If the attacker replaces the fact on the client, the Puppet-master will give him other people's secrets.  <strong>Be sure to check the variables</strong> : use only those that the Puppet-master does not allow to determine on the client side. <br><br><h2>  How to deal with SCM without a master? <br></h2><br>  If suddenly you do not have Puppet, then, most likely, Ansible.  For Chef and other centralized SCM, their solutions are a plugin that can access Vault.  I offer several options that can be implemented with Ansible. <br><br><h3>  Local agent <br></h3><br>  Locally for the server, generate a token, which is actually a password to access the Vault.  Token acts constantly.  You can update it or automate it.  With this token, you go to Vault and take your secrets. <br><br>  The idea is that on your server, where you need to deliver the secrets, the agent is spinning, who comes to the Vault, looks at all the secrets and puts them in the form of files.  We use the agent on several separate servers where there is no Puppet. <br><br>  <strong>Minuses:</strong> <br><br><ul><li>  It is easy to enter a token in a small segment, but if you have several dozen servers deployed per day, you will have to generate a token for each server and set a policy.  It is not comfortable. </li><li>  The token must be updated. </li><li>  Grouping servers by role, purpose, or fact is difficult; it must be synchronized with Vault. </li></ul><br><h3>  Transit encryption <br></h3><br>  Vault has a function of transit encryption, the essence of which is that the Vault acts as an <strong>encryption server</strong> .  You simply bring him the plaintext, and he encrypts and issues the closed text on his private key, which he has only.  Then you choose who can decrypt this closed text. <br><br>  Ansible has an entity, which is also called Vault.  This is not HashiCorp Vault, but <strong>Ansible Vault</strong> .  Here you need not to confuse, and the secrets can be stored both in the first and in the second.  In Ansible there is a ready-made plug-in for giving secrets from the Hashicorp Vault.  If you give personal access to the Vault, then you can decipher the secrets.  When you roll Ansible, it goes to Vault on your behalf, decrypts secrets that are in the encrypted form in the repository, and rolls it into production. <br><br>  There is a drawback here too - <strong>each administrator gets access to secrets</strong> .  But there is an audit: Vault is able to keep an activity log about which user came, which secret he read, which one got access.  You always know who, when and what you did with the secret.  This option seems to me quite good. <br><br>
<h3>  Big Fault No. 1 <br></h3><br>  The biggest drawback that causes us the most pain is that in Vault you cannot delegate the full control of any <strong>piece of</strong> <strong>data to</strong> anyone.  In Vault, access to the secret is carried out in paths that are similar to paths in UNIX ‚Äî the names are usually separated by slashes, and the result is a ‚Äúdirectory‚Äù.  When you have such a path, sometimes you want to take a part of the path and give it to someone else to manage. <br><img src="https://habrastorage.org/webt/w-/hq/gf/w-hqgfwmxgok3_dimlgnn8baxag.png"><br><br>  For example, you have <strong>entered</strong> certificates, named <strong>/ certs</strong> , and want to give to individual security personnel who deal with PKI.  Vault won't do it.  You cannot give the right to issue rights within this prefix - so that the security officers themselves can distribute the rights to certificates to someone else. <br><br>  <strong>In Vault there is no possibility to selectively issue rights to issue rights</strong> .  As soon as you gave the right to issue rights, you were given the opportunity to get full access to all the secrets.  In other words, you cannot give access to the Vault part. <br><br>  This is one of the biggest problems.  I have an idea how to solve it, I'll tell you about it later. <br><br><h2>  Kubernetes <br></h2><br>  In RIT ++, I <a href="https://www.youtube.com/watch%3Fv%3DIulNdGlQR3A">talked</a> about a separate system that we implemented for <strong>Kubernetes</strong> : it serves as a third party, goes to the API, checks access, and then requests a secret in Vault. <br><br>  Now our system is no longer relevant, because Kubernetes native support appeared in Vault 0.9.  Now Vault can go to Kubernetes and make sure that access to the secret is allowed.  He does this with the help of the <strong>Service Account Token</strong> .  For example, when your pod rolled out, there is a special, signed and authorized for it <strong>JWT</strong> , designed for requests to the Kubernetes API.  With a token, you can also log in to Vault and get secrets for your namespace. <br><br>  Everything is done at the level of the Vault itself.  True, for each namespace it will be necessary to start a role, that is, to inform Vault that there is such a namespace, there will be authorization in it, and to prescribe where to go to Kubernetes.  This is done once, and then Vault will go to the API itself, confirm the validity of JWT and issue its own access token. <br><br><h3>  Kubernetes Rules <br></h3><br>  In terms of the name of the services and additional metadata, we trust the developers.  There is a small chance that developers may accidentally or intentionally obtain the secrets of other services that revolve in one namespace, so we introduced a rule: <strong>one service</strong> - <strong>one namespace.</strong> <br><br>  New microservice?  Get a new namespace with your secrets.  It is impossible to cross the border into the neighboring one - there are your Service Account Token  <strong>The security boundary in Kubernetes is currently a namespace.</strong>  If in two different namespace you need one secret - we copy. <br><br>  Kubernetes has <strong>kubernetes secrets</strong> .  They are stored in etcd in Kubernetes in an unencrypted form and can ‚Äúlight up‚Äù in the dashboard or when launching kubectl get pods.  If authentication in etcd is disabled in your cluster, or if you have given someone full read-only access, then all secrets are visible to him.  That is why we introduced two rules: it is <strong>forbidden to use kubernetes secrets</strong> and it is <strong>forbidden to specify secrets in environment variables in manifests</strong> .  If you set up a secret in deployment.yaml in the environment, this is bad, because the manifest itself can be seen by everyone. <br><br><h3>  Kubernetes Shipping <br></h3><br>  As I said, we need to somehow put the file in Kubernetes.  We have some secret: the essence, the password, which in JSON is recorded in the Vault.  How to turn it into a file inside a container in Kubernetes now? <br><img src="https://habrastorage.org/webt/gm/ki/wb/gmkiwblvlm7ca4hiwmvhhx14wxu.png"><br><br>  The first delivery option. <br><br><ul><li>  We have a special init-container. </li><li>  It runs from our image. </li><li>  In the image is a small utility that with the Service Account Token goes to the Vault, takes the secret and puts it in the Shared volume. </li><li>  For the utility, a special Shared volume is mounted only in TMPFS memory so that secrets do not pass through the disk. </li><li>  Init-container goes to Vault, puts in this volume in the form of files all the secrets that it finds along the specified path. </li><li>  Further Shared volume is mounted in the main container in which it is required. </li><li>  When the main container is launched, it immediately gets what the developer needs - secrets as a file on disk. </li></ul><br>  The developer just need to remember the path in which lies his secret. <br><br>  We use approximately the following prefix: <br><br><pre><code class="plaintext hljs">/k8s/&lt;cluster&gt;/&lt;namespace&gt;/&lt;service&gt;/some_secret</code> </pre> <br>  The prefix name contains the cluster name, namespace and service name.  Each service has its own secret, each namespace has its own secret. <br><br>  The second option is your <strong>own entry point</strong> .  To him, we now turn to Avito, because with the init-container developers have a problem.  In the diagram, this option is on the right. <br><br>  Not everyone can afford their own entrypoint.  We can do it, so in every container we force our special entry point. <br><br>  Our entrypoint does the same thing as init-container: it goes to Vault with Service Account Token, takes secrets and puts them out.  Except in the files, he puts them back in the environment.  You get the opportunity to run the application as recommended by the <strong>Twelve-Factor App</strong> concept: the application takes all the settings, including secrets, from environment variables. <br><br>  Environment variables are not visible in manifests and dashboards, since they are set by PID 1 (the main container process) at launch.  These are not environment variables from deployment.yaml, but environment variables that the entrypoint has set during operation.  They are not visible in the dashboard, they are not visible, even if you make kubectl exec in a container, because in this case another process is launched, parallel to PID1. <br><br><h3>  Workflow <br></h3><br>  From an organizational point of view, the process goes as follows.  The developer learns from the security champion or from the documentation that he cannot keep secrets in the repository, but only in Vault.  Then he comes to us and asks where to put the secrets - submits an application to the security for the institution of the prefix.  In the future, you can create a prefix without a request, immediately when you create a service. <br><br>  The developer is waiting, and this is bad, because  for him the main thing is time-to-market.  Then he reads the instructions, dealt with long files - ‚Äúinsert that line there, insert this line here‚Äù.  Never before has a developer started an init-container, but he has to figure it out and set it up in deployment.yaml (helm chart). <br><br> <code>Commit -&gt; deploy -&gt; feel pain -&gt; fix -&gt; repeat</code> <br> <br>  Committed, waits until TeamCity rolls out, sees errors in TeamCity, starts to feel pain, tries to fix something, again experiences pain.  Additionally, it is superimposed that each rollout in TeamCity can still stand in a queue.  Sometimes the developer can not figure out himself, comes to us, and we understand together. <br><br>  Basically, the developer suffers because of his own mistakes: he <strong>incorrectly specified init-container or did not finish reading the documentation</strong> . <br><br>  Security also has problems.  The security worker receives a request, in which there is always little information, and we still find out the missing questions: we find out the names of the clusters, the namespace of the service, because the developer does not indicate them in the application and does not even always know what it is.  When we‚Äôll find out everything, create policies and roles in Vault, assign policies to groups and, together with the developer, begin to figure out where and why he made a mistake, and read the logs together. <br><br>  The problem is solved by the unit ‚ÄúArchitecture‚Äù by concealing from the developer deployment.yaml.  They develop a piece that generates everything for the developer, including the entrypoint.  Due to the fact that we substitute our entrypoint, we can use it not only to deliver secrets, but also for other things that you may need to do when starting. <br><br><h3>  Obvious problems with the secrets of Kubernetes. <br></h3><br><ul><li>  <strong>A very difficult workflow</strong> for both the developer and the security manager. </li><li>  <strong>You can not delegate anything to anyone.</strong>  The security officer has full access to the Vault, and it is impossible to give partial access (see Large Defect No. 1). </li><li>  Difficulties arise when developers move from a cluster to a cluster, from a namespace to a namespace, when shared secrets are needed, because it is initially assumed that there are different secrets in different clusters. </li></ul><br>  We say: ‚ÄúWhy do you need production secrets in a dev-cluster?  Get a test secret, go with it! ‚ÄùAs a result, there are <strong>mines</strong> <strong>and secrets</strong> that are difficult to manage.  If the secret has changed, do not forget about it, go and change everywhere, and there is no way to determine that it is one and the same secret, except by the name of the service. <br><br><h3>  Idea: Kubernetes KMS <br></h3><br>  New versions of Kubernetes have a KMS subsystem - Key Management Service - a new feature of Kubernetes to encrypt secrets.  In v1.11 she was in alpha state, in v1.12 she was transferred to beta. <br><img src="https://habrastorage.org/webt/yq/nw/i9/yqnwi9a_t6atxpxdu_qrtu0qz80.png"><br>  <em>The picture from the site of the project KMS provider for Vault, and there is an error on it.</em>  <em>If you find - write in the comments.</em> <br><br>  The point of KMS is to eliminate one single flaw - unencrypted data storage in etcd. <br><br>  KMS, like Ansible, knows this. <br><br><ul><li>  Go somewhere, encrypt Kubernetes native native secret and put it in encrypted form. </li><li>  If necessary, deliver to pod, decrypt and put in decrypted form. </li></ul><br>  The developers wrote a special service that does this using transit encryption.  The idea seems to be working, but it is important to remember that secrets are no longer only under the control of Vault and go somewhere else, to the area of ‚Äã‚Äãresponsibility of the Kubernetes administrators. <br><br>  Cons KMS. <br><br><ul><li>  <strong>Decentralization of storage</strong> - <strong>removal from Vault to Kubernetes (etcd)</strong> .  Secrets become uncontrollable Vault, and he is good as a centralized repository of secrets.  It turns out that half of the secrets in Vault, and half somewhere else. </li><li>  <strong>Kubernetes-only solution</strong> .  If you have Kubernetes-only infrastructure, you raise the Vault, and you hardly think what is stored there, because  it contains only encryption keys that you manage correctly - regularly rotate, etc ... The secrets themselves are in Kubernetes, and this is convenient. </li><li>  <strong>It is difficult to share secrets between clusters</strong> .  For each new cluster, you need to get everything new, copying secrets as in the case of a single Vault may not work. </li></ul><br>  Pros KMS. <br><br><ul><li>  <strong>Native support</strong> in Kubernetes, including hiding when showing environment. </li><li>  <strong>Authorization in the area of ‚Äã‚Äãresponsibility Kubernetes</strong> . </li><li>  <strong>Virtually no need to maintain Vault</strong> . </li><li>  <strong>Rotation of keys out of the box</strong> . </li></ul><br><h2>  CI / CD: TeamCity <br></h2><br>  In TeamCity, everything is simple, because JetBrains wrote a plugin that can write secrets to access the secret, encrypt them using TeamCity, and then substitute interest in the template somewhere in the template.  At this point, the TeamCity agent will go off to Vault, pick up the secret and bring it to the build as a parameter. <br><br>  Some secrets are needed when deploying, for example, database migration or alerts to Slack.  AppRole is added to each project - the settings also contain a secret (data for AppRole), but it is entered in the write-only mode ‚Äî the TeamCity does not allow reading it later. <br><br>  TeamCity itself makes sure that when a secret hits the build logs, it will automatically be masked.  As a result, the secret either does not ‚Äúdrive through‚Äù the disk at all, or is cleared from the disk by means of TeamCity.  As a result, the entire security of the secret is well provided by the TeamCity itself and the plugin, and no additional dances with a tambourine are required. <br><br><h3>  CI / CD is not TeamCity? <br></h3><br>  Here are the main questions you need to think about if you use another system (not TeamCity) as your CI. <br><br><ul><li>  Isolation: limit the scope of a secret to a project, team, etc. </li><li>  Who authorizes access to the secret. </li><li>  Exclude the ability to view the secret authorizing party. </li><li>  A separate build step to import the secret to the files. </li><li>  Clean up after yourself. </li></ul><br>  As a result, most likely you will write something very similar to the TeamCity plugin for your CI / CD.  The authorizing party here will most likely be the CI / CD, and it is she who will decide whether this build can have access to this secret, and give the secret itself or not to give it to the results. <br><br>  It is important not to forget to <strong>clean the build results at the end of the build</strong> , if they are laid out on the disk, or to ensure that they are only in memory. <br><br><h2>  Certificates <br></h2><br>  With certificates, nothing special - we use Vault mainly to store them. <br><img src="https://habrastorage.org/webt/ix/ye/4j/ixye4jru2blznsbq2jxmljomqi8.png"><br><br>  Vault has a special PKI backend for issuing certificates, in which you can start the Certificate Authority and sign new certificates.  We have a single internal PKI ... The root CA and second-level CAs exist separately, and we manage the third-level CA through Vault.  To store issued certificates of any level, including certificates signed by external CAs, we use a separate prefix, and put almost all valid certificates for accounting and monitoring purposes.  The format for storing certificates is its own, suitable for storing a separate private key and the certificate itself. <br><br><h2>  Summary <br></h2><br>  <strong>Too much manual work</strong> for a security person, <strong>too much entry threshold for a developer,</strong> and no built-in tools for delegation, although I really want to ... <br><br>  How to be?  Further dreams begin. <br><br><h2>  Ideas: how to do better <br></h2><br>  How can I get rid of a heap of copies of a secret? <br><br><h3>  Master-slave delivery <br></h3><br>  We have a master-secret and a special demon that walks, looks at the secret and its metadata, puts it in the right place, it turns out the slave-secret.  On the way, where the demon laid out the slave, nothing can be changed by hands, because the demon will come and re-place the master-secret over the slave. <br><br>  First, we wanted to make a symlink mechanism, just to point out: ‚ÄúLook for this secret there!‚Äù, As in Linux.  It turned out that there are problems with access rights: it is not known how to check access rights - as in Linux or not, with parental paths, with transitions between mount points.  Too many ambiguous moments and chances to make a mistake, so we refused from symlinks. <br><br><h3>  Ownership Authorization <br></h3><br>  The second thing we want to do is <strong>determine the owner for each secret</strong> .  By default, the secret belongs to the person who created it.  If necessary, you can extend the area of ‚Äã‚Äãresponsibility to the unit by issuing the owner group. <br><br>  When we learn to delegate, we will give the owner the right to a secret, and he can do what he wants with the secret. <br><br><ul><li>  Laying out in k8s - a policy is generated, a slave copy is created. </li><li>  Laying out on the server - a policy is generated, a slave copy is created. </li><li>  Spread in CI / CD - ... </li><li>  Transfer to another owner. </li><li>  Give new access, generate new ACLs. </li></ul><br>  Now we are responsible for all the secrets and security, and we want to shift the responsibility to the creator.  <strong>Security will not suffer</strong> , because the person who came to us with the request to keep a secret understands that he needs to keep the secret safely and is aware of his responsibility. <br><br>  Since this is the owner of the secret, for the delivery option master-slave, he could choose where and in what format to deliver the secret.  It turns out that the owner controls everything himself, no need to submit an application, you can take the necessary prefix yourself, you can also create secrets and delete it yourself. <br><br><h3>  Delegation via ACL templates <br></h3><br>  The Access Control List access policy in Vault is divided into two parts: <br><br><ul><li>  Access Control List in the classic view, which describes the access to the prefix, which way you can read and write, which way you can read, etc. </li><li>  When creating an ACL inside, you can register an asterisk at the end, which means "this prefix, and everything below it."  The prefix can be assigned to a separate operation, given to a user or group, that is, linked to several different entities. </li></ul><br>  Now only the Vault administrator can change the ACL.  Having access to such an ACL, you can prescribe everything that you want, for example, the <code>path ‚Äú*‚Äù { capabilities = [sudo, ...] }</code> , and get full access.  This is the essence of Big No. 1 flaw - <strong>it</strong> is <strong>impossible to prohibit changing the</strong> <strong>contents of an ACL.</strong> <br><br>  We want to set the ACL as a ready-made template that contains the path and placeholders that are allowed to generate new ACLs using this template. <br><br><h4>  Example <br></h4><br>  Below, the yellow font shows the path of the finished standard ACL from Vault and further allowed actions on this path.  We look at it as an ACL for permission to change another ACL at the bottom, which is specified as a template. <br><img src="https://habrastorage.org/webt/ew/xe/jc/ewxejc20z7xa7dqg-o8yxwaesxk.png"><br><br>  We want to delegate access to / k8s, we allow to generate only such templates.  For example, to give read access only to a specific cluster, namespace, service, but not to change the field of capabilities. <br><img src="https://habrastorage.org/webt/ew/xe/jc/ewxejc20z7xa7dqg-o8yxwaesxk.png"><br><br>  Additionally, we want to give permission to bind these ACLs and issue different rights. <br><br>  We applied the template to issue the rights to the developer.  When templating, he ran the <code>$ vault write policy-mgr/create/k8s-microservice ...</code> .  As a result, we got ACLs in which cluster = prod, namespace = ..., service = ..., etc. are indicated.  The rights were added automatically, a policy was created with the name <code>/k8s/some-srv</code> - this is just an ACL name that can be generated from a template. <br><img src="https://habrastorage.org/webt/ro/ih/ur/roihurfk7gxhvrv-hjpik6lctxc.png"><br><br>  As a result, the developer, at our discretion, assigns this ACL to anyone he wants, and becomes the owner himself, he can manage it as a secret: delete, give and take away from users and groups.  Now the person himself is responsible for his prefix: he manages all secrets, generates an ACL pattern, can assign an ACL to those he wants.  Naturally, we can also limit it. <br><br>  All magic works with the help of the new Vault entity - <strong>plugins</strong> .  They are a separate service, very similar to the one I mentioned at the beginning, and work almost exactly as well.  The only important difference is that they are not proxies.  The plug-ins are launched ‚Äúfrom the side‚Äù by Vault, and their main Vault process starts.  Due to this, all requests go not through the service, but to Vault, which already interacts with the plugin itself, sending it a verified and cleared request. <br><br>  About plug-ins, how they are arranged and how to write them, you can read <a href="https://www.vaultproject.io/">on the Vault website</a> .  It is best to write them on Go, which is quite simple, because  for Go there is a framework.  Vault communicates with the plugin via grpc, runs it as a service, but do not be afraid, you don‚Äôt touch it - everything is already in the framework.  You simply write a more or less standard REST application, in which you specify endpoints, give them ready-made functions, handlers, on which there will be logic. <br><br>  Do not be afraid that you break something in the main Vault.  Plugin is a separate service.  Even if the plugin you have panicked and fell, the work of Vault will not break it.  Vault simply restarts the plugin and will continue to work. <br><br>  In addition, there are additional settings for the plugin itself: it always checks the hash sums so that no one replaces the binary.  <strong>The safety of running plugins is ensured</strong> . <br><br><h2>  Useful links: </h2><br><ul><li>  <a href="https://www.vaultproject.io/">www.vaultproject.io</a> </li><li>  <a href="https://github.com/jovandeginste/hiera-router">github.com/jovandeginste/hiera-router</a> </li><li>  <a href="https://github.com/jsok/hiera-vault">github.com/jsok/hiera-vault</a> </li><li>  <a href="https://www.owasp.org/index.php/Security_Champions">www.owasp.org/index.php/Security_Champions</a> </li><li>  <a href="https://blog.jetbrains.com/teamcity/2017/09/vault/">blog.jetbrains.com/teamcity/2017/09/vault</a> </li><li>  <a href="https://github.com/oracle/kubernetes-vault-kms-plugin/">github.com/oracle/kubernetes-vault-kms-plugin</a> </li></ul><br><blockquote>  About DevOps and security, CI / CD, k8s, Puppet and everything in this spirit will be spoken in <a href="https://www.highload.ru/">HighLoad ++</a> (nearest to St. Petersburg in April) and <a href="https://devopsconf.io/">DevOpsConf</a> .  Come share your experience or <a href="http://youtube.com/c/DevOpsChannel/">look</a> at others.  In order not to forget, subscribe to the blog and <a href="http://eepurl.com/bN_0E1">newsletter</a> , in which we will remind of deadlines and collect useful materials. <br></blockquote></div><p>Source: <a href="https://habr.com/ru/post/438740/">https://habr.com/ru/post/438740/</a></p>
<section class="navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container">Waiting for the list from <a href="../../index.html">here</a>...</nav>
</section>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52319614 = new Ya.Metrika({
                  id:52319614,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52319614" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>
</body>

</html>
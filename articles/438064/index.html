<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Checklist: what to do before running microservices in prod</title>
  <meta name="description" content="This article contains a brief squeeze from my own experience and that of my colleagues, with whom I have been able to clean up incidents day and night...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="https://quick-geek.github.io/search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <section class="page js-page"><h1>Checklist: what to do before running microservices in prod</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/y7/-a/th/y7-ath7wga1jfx9issm1rhog2lg.jpeg" width="45%" align="right">  This article contains a brief squeeze from my own experience and that of my colleagues, with whom I have been able to clean up incidents day and night.  And many incidents would never have occurred if everyone‚Äôs favorite microservices were written at least a little more carefully. </p><br><p>  Unfortunately, some <s>low</s> -level programmers seriously believe that a Dockerfile with any team at all inside is a microservice in itself and can be deployed even now.  Dockers are spinning, lavenshka is muddied.  This approach turns into problems starting with a drop in performance, inability to debug, and service failures and ending in a nightmare called Data Inconsistency. </p><br><p>  If you feel that the time has come to launch another applet in Kubernetes / ECS / whatever, then I have something to object to. </p><br><p>  <strong>Russian version <a href="https://habr.com/en/post/438186/">is also available</a></strong> . </p><a name="habracut"></a><br><p>  I formed for myself a certain set of criteria for assessing the readiness of applications for launch in production.  Some items on this checklist cannot be applied to all applications, but only to special ones.  Others generally apply to everything.  I am sure you can add your options in the comments or dispute any of these points. </p><br><p>  If your micro service does not meet at least one of the criteria, I will not allow it into my ideal cluster, built in a bunker 2000 meters under the ground with heated floors and a closed self-sufficient Internet feed system. </p><br><p>  Go.... </p><br><p>  <i>Note: the order of the items does not matter.</i>  <i>Anyway, for me.</i> </p><br><h2 id="korotkoe-opisanie-v-readme">  Short description in the readme </h2><br><blockquote>  It contains a short description of itself at the very beginning of Readme.md in its repository. </blockquote><p>  God, it seems so simple.  But how often have I come across that the repository does not contain the slightest explanation of why it is needed, what tasks it solves, and so on.  There is no need to talk about something more complicated, such as configuration options. </p><br><h2 id="integraciya-s-sistemoy-monitoringa">  Integration with monitoring system </h2><br><blockquote>  Send metrics to DataDog, NewRelic, Prometheus, and so on. </blockquote><p>  Analysis of resource consumption, memory leaks, stacktraces, service interdependencies, error rate ‚Äî it is extremely difficult to control what happens in a large distributed application without understanding all of this (and not only). </p><br><h2 id="opovescheniya-nastroeny">  Alerts are configured </h2><br><blockquote>  For the service included alerts (alerts) that cover all standard situations, plus known unique situations. </blockquote><p>  Metrics are good, but no one will follow them.  Therefore, we automatically receive calls / pushes / sms if: </p><br><ul><li>  CPU / memory consumption has increased dramatically. </li><li>  Traffic has increased dramatically / dropped. </li><li>  The number of transactions processed per second has changed dramatically in any direction. </li><li>  The size of the artifact after assembly has changed dramatically (exe, app, jar, ...). </li><li>  The percentage of errors or their frequency exceeded the permissible threshold. </li><li>  The service has stopped sending metrics (often an overlooked situation). </li><li>  The regularity of certain expected events is broken (cron job does not work, not all events are processed, etc.) </li><li>  ... </li></ul><br><h2 id="runbooks-sozdany">  Runbooks created </h2><br><blockquote>  A document has been created for the service describing known or expected abnormal situations. </blockquote><br><ul><li>  how to make sure that the error is internal and does not depend on third-parties; </li><li>  if it depends, where, to whom and what to write; </li><li>  how to safely restart it; </li><li>  how to restore from backup and where are backups; </li><li>  what special dashboards / queries are created to monitor this service; </li><li>  Does the service have its own admin panel and how to get there? </li><li>  is there an API / CLI and how to use to fix known problems; </li><li>  and so on. </li></ul><br><p>  The list can be very different in different organizations, but at least the basic things should be there. </p><br><h2 id="vse-logi-pishutsya-v-stdoutstderr">  All logs are written in STDOUT / STDERR </h2><br><blockquote>  The service does not create any files with logs in the mode of operation in production, does not send them to any external services, does not contain any redundant abstractions for log rotation, etc. </blockquote><p>  When an application creates files with logs - these logs are useless.  You will not enter 5 containers running in parallel, hoping to catch the necessary error (and you will be <em>crying</em> ...).  Restarting the container will result in the complete loss of these logs. </p><br><p>  If an application writes logs to a third-party system, for example in Logstash, this creates useless redundancy.  Neighboring service can not do this, because  does it have another framework?  You get a zoo. </p><br><p>  The application writes a part of the logs to the files, and a part to the stdout because the developer is convenient to see the INFO in the console, and DEBUG in the files?  This is generally the worst option.  No one needs the complexity and completely extra code and configuration that you need to know and maintain. </p><br><h2 id="logi---eto-json">  Logs - this is Json </h2><br><blockquote>  Each line of the log is written in Json format and contains a consistent set of fields. </blockquote><p>  Until now, almost everyone writes logs in plain text.  This is a real disaster.  I would be happy to never know about <a href="https://github.com/elastic/logstash/blob/v1.4.2/patterns/grok-patterns">Grok Patterns</a> .  Sometimes I dream about them and I freeze, trying not to move, so as not to attract their attention.  Just try once parsing Java exceptions in the logs. </p><br><p>  Json is a blessing, it is a fire presented from heaven.  Just add there: </p><br><ul><li>  timestamp <strong>with milliseconds as</strong> per <a href="https://www.ietf.org/rfc/rfc3339.txt">RFC 3339</a> ; </li><li>  level: info, warning, error, debug </li><li>  user_id; </li><li>  app_name, </li><li>  and other fields. </li></ul><br><p>  Download to any suitable system (properly configured ElasticSearch, for example) and enjoy.  Connect the logs of many microservices and feel again <em>what</em> good monolithic applications were. </p><br><p>  <em>(You can also add Request-Id and get tracing ...)</em> </p><br><h2 id="logi-s-urovnyami-verbosity">  Logs with verbosity levels </h2><br><blockquote>  The application must support an environment variable, for example LOG_LEVEL, with at least two modes of operation: ERRORS and DEBUG. </blockquote><p>  It is desirable that all services in the same ecosystem maintain the same environment variable.  Not a config option, not an option on the command line (although this is wrapped, of course), but immediately by default from the environment.  You should be able to get as many logs as possible if something goes wrong and as few logs as possible if everything is fine. </p><br><h2 id="fiksirovannye-versii-zavisimostey">  Fixed versions of dependencies </h2><br><blockquote>  Dependencies for package managers are fixed, including minor versions (For example, cool_framework = 2.5.3). </blockquote><p>  About this many where already mentioned, of course.  Some fix dependencies on major versions, hoping that in minor versions there will be only bug fixes and security fixes.  It is not right. <br>  Each change in each dependency must be reflected by a <em>separate commit</em> .  So that it can be canceled in case of problems.  Is it hard to control with your hands?  There are useful robots, <a href="https://dependabot.com/">like this</a> , that will track the updates and create Pull Requests for each of them. </p><br><h2 id="dockerized">  Dockerized </h2><br><blockquote>  The repository contains the production-ready Dockerfile and docker-compose.yml </blockquote><p>  Docker has long become a standard for many companies.  There are exceptions, but even if you do not have a Docker in production, then any engineer should be able to simply do the docker-compose up and not think about anything else to get the dev-build for local verification.  And the system administrator should have an assembly already verified by developers with the necessary versions of libraries, utilities, and so on, in which the application <em>at least somehow works</em> in order to adapt it for production. </p><br><h2 id="konfiguraciya-cherez-okruzhenie">  Configuration through the environment </h2><br><blockquote>  All important configuration options are read from the environment and the environment takes precedence over configuration files (but lower than the command line arguments at startup). </blockquote><p>  No one will ever want to read your configuration files and study their format.  Just accept it. </p><br><p>  More details here: <a href="https://12factor.net/config">https://12factor.net/config</a> </p><br><h2 id="readiness-and-liveness-probes">  Readiness and Liveness probes </h2><br><blockquote>  Contains the appropriate endpoints or cli commands to test the readiness to serve requests at startup and for uptime. </blockquote><p>  If an application serves HTTP requests, it should by default have two interfaces: </p><br><ol><li><p>  To verify that the application is live and not stuck, use the liveness test.  If the application does not respond, it can be automatically stopped by orchestrators like Kubernetes, " <em>but this is not accurate</em> ."  In fact, killing a hung application can cause a domino effect and permanently put your service.  But this is not a developer problem, just make this endpoint. </p><br></li><li><p>  To verify that the application is not just started, but is ready to accept requests, a Readiness test is performed.  If an application has established a connection with a database, a queue system, and so on, it must respond with a status from 200 to 400 (for Kubernetes). </p><br></li></ol><br><h2 id="ogranicheniya-resursov">  Resource limits </h2><br><blockquote> Contains limits for memory, CPU, disk space and any other available resources in a consistent format. </blockquote><p>  The concrete implementation of this item will be very different in different organizations and for different orchestrators.  However, these limits must be set in the same format for all services, be different for different environments (prod, dev, test, ...) and be <em>outside the repository with the application code</em> . </p><br><h2 id="sborka-i-dostavka-avtomatizirovana">  Assembly and delivery is automated </h2><br><blockquote>  The CI / CD system used in your organization or project is configured and can deliver the application to the desired environment according to the accepted workflow. </blockquote><p>  <em>Nothing is ever delivered to production manually.</em> </p><br><p>  No matter how difficult it is to automate the assembly and delivery of your project, this must be done before this project gets into production.  This item includes building and running Ansible / Chef cookbooks / Salt / ..., building mobile applications, building operating system forks, building virtual machine images, whatever. <br>  Can't automate?  So you can not run it into the world.  After you, no one will collect it. </p><br><h2 id="graceful-shutdown--korrektnoe-vyklyuchenie">  Graceful shutdown - correct shutdown </h2><br><blockquote>  The application can process SIGTERM and other signals and systematically interrupt their work after the processing of the current task. </blockquote><p>  This is an extremely important point.  Docker-processes become orphaned and work for months in the background, where no one sees them.  Non-transactional operations terminate in the middle of execution, creating inconsistency of data between services and databases.  This leads to errors that cannot be foreseen and can be very, very expensive. </p><br><p>  If you are not in control of any dependencies and cannot guarantee that your code will correctly handle SIGTERM, use something like <a href="https://github.com/Yelp/dumb-init">dumb-init</a> . </p><br><p>  More information here: </p><br><ul><li>  <a href="https://12factor.net/disposability">https://12factor.net/disposability</a> </li><li>  <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod/">https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods</a> </li></ul><br><h2 id="soedinenie-s-bazoy-dannyh-regulyarno-proveryaetsya">  Database connection is checked regularly. </h2><br><blockquote>  The application constantly pings the database and automatically responds to the "lost connection" exception for any requests, trying to restore it on its own or correctly completes its work. </blockquote><p>  I saw a lot of cases (it‚Äôs not just a turn of speech) when services created to process queues or events lost connection by timeout and started infinitely filling errors in the logs, returning messages in the queue, sending them to Dead Letter Queue or simply not doing their job. </p><br><h2 id="masshtabiruetsya-gorizontalno">  Scaled horizontally </h2><br><blockquote>  As the load grows, it is enough to run more instances of the application to ensure that all requests or tasks are processed. </blockquote><p>  Not all applications can scale horizontally.  A prime example is <a href="https://www.oreilly.com/library/view/kafka-the-definitive/9781491936153/ch04.html">Kafka Consumers</a> .  This is not necessarily bad, but if a specific application cannot be launched twice, all interested parties need to know about this in advance.  This information should be a eyesore, hang in the Readme and wherever possible.  Some applications in general can not be run in parallel under any circumstance, which creates serious difficulties in supporting it. </p><br><p>  It is much better if the application itself controls these situations or a wrapper is written for it, which effectively monitors the "competitors" and simply prevents the process from starting or starting work until another process completes its own or some external configuration allows N processes to work simultaneously. </p><br><h2 id="dead-letter-queues-i-ustoychivost-k-plohim-soobscheniyam">  Dead letter queues and bad message resistance </h2><br><blockquote>  If the service listens to queues or responds to events, changing the format or content of messages does not cause it to fall.  Unsuccessful attempts to process the task are repeated N times, after which the message is sent to Dead Letter Queue. </blockquote><p>  Many times I have seen endlessly restarted consumers and queues swelled to such an extent that their subsequent processing took many days.  Any listener of the queue must be ready to change the format, to random errors in the message itself (typing data in json, for example) or when processing it by a child code.  I even came across a situation where the standard library for working with RabbitMQ for one extremely popular framework did not support retries at all, counters of attempts, etc. </p><br><p>  Even worse, the message is simply destroyed in case of failure. </p><br><h2 id="ogranichenie-na-kolichestvo-obrabatyvaemyh-soobscheniy-i-zadach-odnim-processom">  Limit on the number of processed messages and tasks by one process </h2><br><blockquote>  It supports an environment variable that can be forced to limit the maximum number of processed tasks, after which the service will shut down correctly. </blockquote><p>  Everything flows, everything changes, especially memory.  The continuously growing schedule of memory consumption and OOM Killed in the end - this is the norm of life of modern cubernetic minds.  Implementing a primitive check that would just spare you the very need to examine all these memory leaks would make life easier.  I have often seen people spend a lot of time and effort (and money) to stop this turnover, but there are no guarantees that your colleague‚Äôs next committ will not make everything worse.  If the application can survive a week - this is an excellent indicator.  Let it then simply end itself and restart.  This is better than SIGKILL (about SIGTERM, see above) or the exception "out of memory".  For a couple of decades, this gag is enough for you. </p><br><h2 id="ne-ispolzuet-third-party-integracii-s-filtraciey-po-ip-adresam">  Does not use third-party IP address filtering integration </h2><br><blockquote>  If an application makes requests to a third-party service that allows calls from limited IP addresses, the service makes these calls indirectly through a reverse proxy. </blockquote><p>  This is a rare case, but extremely unpleasant.  It is very inconvenient when one tiny service blocks the possibility of changing the cluster or moving to another region of the entire infrastructure.  If you need to communicate with someone who does not know how to oAuth or VPN, configure the <a href="https://en.wikipedia.org/wiki/Reverse_proxy">reverse proxy</a> in advance.  Do not implement in your program the dynamic addition / deletion of similar external integrations, since by doing this you nail yourself to the only available runtime environment.  It is better to immediately automate these processes to manage Nginx configs, and in your application, refer to it. </p><br><h2 id="ochevidnyy-http-user-agent">  Obvious HTTP User-agent </h2><br><blockquote>  The service replaces the User-agent header with customized one for all requests to any API and this header contains enough information about the service itself and its version. </blockquote><p>  When you have 100 different applications communicate with each other, you can go crazy, seeing in the logs something like "Go-http-client / 1.1" and the dynamic IP address of the Kubernetes container.  Always identify your application and its version explicitly. </p><br><h2 id="ne-narushaet-licenzii">  Does not violate the license </h2><br><blockquote>  Does not contain dependencies that unduly limit the application, is not a copy of someone else's code, and so on. </blockquote><p>  This is a self-evident case, but it has been <em>possible</em> to see that even a lawyer who wrote the NDA now has hiccups. </p><br><h2 id="ne-ispolzuet-nepodderzhivaemye-zavisimosti">  Does not use unsupported dependencies </h2><br><blockquote>  When you first start the service, it does not include dependencies that are already out of date. </blockquote><p>  If the library that you have taken into the project is no longer supported by anyone - look for another way to achieve the goal or develop the library itself. </p><br><h2 id="zaklyuchenie">  Conclusion </h2><br><p>  In my list there are some more very specific checks for specific technologies or situations, and I just forgot to add something.  I am sure you will also find something to remember. </p></div><p>Source: <a href="https://habr.com/ru/post/438064/">https://habr.com/ru/post/438064/</a></p>
<section class="navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container">Waiting for the list from <a href="../../index.html">here</a>...</nav>
</section>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52319614 = new Ya.Metrika({
                  id:52319614,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52319614" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>
</body>

</html>
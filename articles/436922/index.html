<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Optimizing Prometheus 2.6.0 startup times with pprof</title>
  <meta name="description" content="Prometheus 2.6.0 optimizes WAL loading, which speeds up the startup process. 


 The unofficial goal of the development of Prometheus 2.x TSDB is to s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="https://quick-geek.github.io/search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <section class="page js-page"><h1>Optimizing Prometheus 2.6.0 startup times with pprof</h1><div class="post__text post__text-html js-mediator-article"><p>  Prometheus <a href="https://www.robustperception.io/new-features-in-prometheus-2-6-0">2.6.0</a> optimizes WAL loading, which speeds up the startup process. </p><br><p>  The unofficial goal of the development of Prometheus 2.x TSDB is to speed up the launch so that it takes less than a minute.  In recent months, there have been reports that the process is a bit delayed, and if Prometheus restarts for some reason, this is already a problem.  Almost all this time, WAL is loaded (pre-registration recording), which includes samples from the last few hours that have yet to be compressed into a block.  In late October, I finally managed to figure it out;  the result is <a href="https://github.com/prometheus/tsdb/pull/440">PR # 440</a> , which reduces the CPU time by 6.5 times and the calculation time by 4 times.  Consider how I achieved these improvements. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b59/bb0/1f7/b59bb01f785b863d244cb527c6b27632.png" alt="image"></p><a name="habracut"></a><br><p> First, a test setup is needed.  I created a small Go program that generates TSDB with WAL with a billion samples scattered over 10,000 time series.  Then I opened this TSDB and looked at how long it took to use the <code>time</code> utility (not the built-in structure, because it does not include memory statistics), and also created a CPU profile using the <a href="https://golang.org/pkg/runtime/pprof/">runtime / pprof package</a> : </p><br><pre> <code class="plaintext hljs">f, err := os.Create("cpu.prof") if err != nil { log.Fatal(err) } pprof.StartCPUProfile(f) defer pprof.StopCPUProfile()</code> </pre> <br><p>  The CPU profile does not allow us to directly establish the calculation time of interest, however, there is a significant correlation.  As a result, on my desktop computer (i7-3770 processor with 16 GB of RAM and solid-state drives) the download took about 4 minutes and a little less than 6 GB of RAM at the peak: </p><br><pre> <code class="plaintext hljs">1727.50user 16.61system 4:01.12elapsed 723%CPU (0avgtext+0avgdata 5962812maxresident)k 23625165inputs+95outputs (196major+2042817minor)pagefaults 0swaps</code> </pre> <br><p>  This is not good, so let's load the profile using <code>go tool pprof cpu.prof</code> and see how long the process takes if we use the <code>top</code> command. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/562/0e1/996/5620e19968ec33e73d42238e1ed1e909.png" alt="image"></p><br><p>  Here, <code>flat</code> is the amount of time spent on a given function, and <code>cum</code> is the time spent on a given function and on all functions caused by it.  It may also be useful to view this data in a graph to get an idea of ‚Äã‚Äãthe question.  I prefer to use the <code>web</code> command for this, but there are other options, including svg, png and pdf files. </p><br><p>  It can be seen that about a third of our CPU is spent on adding samples to the internal database, about two thirds on processing WAL as a whole, and a quarter on clearing the memory ( <code>runtime.scanobject</code> ).  Let's look at the code for the first of these processes using the <code>list memSeries.*append</code> : </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/208/454/263/208454263da34943818a5f89ca2112da.png" alt="image"></p><br><p>  Here the following is striking: more than half of the time is spent on getting the head piece of data for the series in line 1443. Also, it is not a short time to set the number of samples in this piece of data in line 1449. The time it takes to add line 1465 - expected, since this is the core of the actions of this function.  Accordingly, I expected the operation to take up most of the time. </p><br><p>  Take a look at the <code>memSeries.head</code> element: it computes a piece of data that is returned each time.  The data fragment is only changed after every 120 additions, and so we can <a href="https://github.com/prometheus/tsdb/pull/440/commits/a64b0d51c4da614efb493627a7b5425bc65c6769">save the current head fragment in the data structure of the series</a> .  This takes up some of the RAM ( <a href="https://github.com/prometheus/tsdb/commit/910f3021b054c52cb8bde1ab1964eae3eceb84fd">which I will return to later</a> ), but saves a significant amount of CPU.  And in general, also accelerates the work of Prometheus. </p><br><p>  Then let's take a look at <code>Head.processWALSamples</code> : </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/df3/677/ce9/df3677ce990c5d263a0790d88c4da721.png" alt="image"></p><br><p>  This addition is already optimized above, so look at the next obvious culprit, <code>getByID</code> in line 252: <br>  (code) </p><br><p>  It seems that there is a certain blocking conflict, and time is spent on performing a search on a two-level map.  <a href="https://github.com/prometheus/tsdb/pull/440/commits/d8c8e4e6e4f690c0bd7c165f7b9718fce58c165a">The cache for each identifier</a> significantly reduces this figure. </p><br><p>  It is worth <code>Head.processWALSamples</code> another look at <code>Head.processWALSamples</code> , and one wonders how much time is spent in line 249. Let's go back a little, to the question of how WAL loading works: WAL decoding from disk.  Rows are segmented by these gorutinami, so that parallelism can be an advantage.  The method of implementation is as follows: all samples are sent to the first grade that processes the elements it needs.  She then sends all the samples to the second state, which processes the elements she needs, and so on, until the last state <code>Head.processWALSamples</code> sends all the data back to the control city. </p><br><p>  In the meantime, the additions are distributed among the cores - which is what you need - there are also many duplicate tasks in each plan, which must process all the samples and calculate the module.  In fact, the more cores, the more work is duplicated.  I made changes to segment the data in the controller's gorutin, so each <code>Head.processWALSamples</code> <a href="https://github.com/prometheus/tsdb/pull/440/commits/c7e7fd355e524e4212851000f1673b853fb0f3c2">now receives only the samples it needs</a> .  On my computer - 8 running gourutin - the calculation time was saved a little, but the CPU volume is decent.  For computers with a large number of cores, the advantages should be greater. </p><br><p>  And back to the question: time to clear the memory.  We cannot (usually) determine this through the CPU profiles.  Instead, you should pay attention to the dynamic memory profiles to find the elements that stand out.  This requires some extension of the code at the end of the program: </p><br><pre> <code class="plaintext hljs">runtime.GC() hf, err := os.Create("heap.prof") if err != nil { log.Fatal(err) } pprof.WriteHeapProfile(hf)</code> </pre> <br><p>  Formal memory cleaning is associated with some information in dynamic memory, which is collected and cleaned only during memory cleaning. </p><br><p>  We use the same tool again, but specify the <code>-alloc_space</code> label, since we are interested in all memory allocation operations, and not only operations that use memory at a particular moment;  thus, we run the <code>go tool pprof -alloc_space heap.prof</code> .  If you look at the upper distributor, then the culprit is obvious: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8ba/0ba/cbf/8ba0bacbf8231b7fdac52a657212ee22.png" alt="image"></p><br><p>  Take a look at the code: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/453/531/ca4/453531ca4cda944db146ce07c20edc2f.png" alt="image"></p><br><p>  It seems that the extensible array of <code>samples</code> is a problem.  If we could reuse the array at the same time as calling <code>RecordDecoder.Samples</code> , this would save a significant amount of memory.  It turns out that the code was composed in this way, but a small coding error led to the fact that it did not work.  <a href="https://github.com/prometheus/tsdb/pull/440/commits/f0e79ec264b69dd286840af349ffd8546b03e444">If corrected</a> , the memory is cleared in 8 seconds of the CPU instead of 151 seconds. </p><br><p>  The overall results are quite tangible: </p><br><pre> <code class="plaintext hljs">269.18user 10.69system 1:05.58elapsed 426%CPU (0avgtext+0avgdata 3529556maxresident)k 23174929inputs+70outputs (815major+1083172minor)pagefaults 0swap</code> </pre> <br><p>  In our country, not only the calculation time was reduced by 4 times, and the CPU operating time - by 6.5 times, but also the amount of occupied memory is reduced by more than 2 GB. </p><br><p>  It looks as if everything is simple, but the trick is this: I decently rummaged through the code base and analyze everything as if in hindsight.  Studying the code, I came to a <code>NumSamples</code> several times, for example, when deleting a <code>NumSamples</code> call, reading and decoding in separate streams, and also in several variants of the <code>processWALSamples</code> work <code>processWALSamples</code> .  I am almost sure that by adjusting the amount of gorutin, more can be achieved, but for this, tests should be carried out on machines more powerful than mine, so that there are more cores.  I have achieved my goal: productivity has increased - and I realized that it is better not to make the registry of programs too large, and therefore I decided to stop at what had been achieved. </p></div><p>Source: <a href="https://habr.com/ru/post/436922/">https://habr.com/ru/post/436922/</a></p>
<section class="navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container">Waiting for the list from <a href="../../index.html">here</a>...</nav>
</section>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52319614 = new Ya.Metrika({
                  id:52319614,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52319614" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>
</body>

</html>
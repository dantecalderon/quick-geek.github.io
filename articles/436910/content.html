<div class="post__text post__text-html js-mediator-article">  <i><b>Note</b></i>  <i><b>trans.</b></i>  <i>: The original article was written by Miłosz Smółka, one of the founders of the small Polish company <a href="https://threedotslabs.com/">Three Dots Labs</a> , which specializes in “advanced backend solutions”.</i>  <i>The author draws on his experience of active exploitation of GitLab CI and shares the accumulated tips for other users of this Open Source product.</i>  <i>After reading them, we realized how close the problems he described to us were, so we decided to share the proposed solutions with a wider audience.</i> <br><br><img src="https://habrastorage.org/web/168/262/b4e/168262b4e3af4467978ffc20dd8bba99.png"><br><br>  This time I will cover more advanced topics in GitLab CI.  A frequent task here is to implement non-standard features in the pipeline.  Most of the tips are specific to GitLab, although some of them can be applied to other CI systems. <a name="habracut"></a><br><br><h2>  Running integration tests </h2><br>  As a rule, checking code using <b>unit tests is</b> easy to connect to any CI system.  This is usually no more difficult than running one of the commands built into the standard set of programming language utilities.  In such tests, you will most likely use different mocks and plugs to hide implementation details and focus on testing specific logic.  For example, you can use an in-memory database as storage or write stubs for HTTP clients that will always return already prepared responses. <br><br>  However, sooner or later you will need <b>integration tests</b> to cover more unusual situations with tests.  I will not go into the discussion about all possible types of testing and just say that by <i>integration,</i> I mean tests that use some kind of external resources.  It can be a real database server, an HTTP service, a connected storage, etc. <br><br>  In GitLab, it is easy to run pluggable resources as Docker containers associated with a container running scripts.  These dependencies can be defined using <a href="https://docs.gitlab.com/ee/ci/docker/using_docker_images.html"><code>services</code></a> .  They are available by the image name or by the name of your choice, if you specify it in the <code>alias</code> field. <br><br>  Here is a simple example of using a plugin with MySQL: <br><br><pre> <code class="plaintext hljs">integration_tests: stage: tests services: - name: mysql:8 alias: db script: - ./run_tests.sh db:3306</code> </pre><br>  In this case, the test scripts will need to connect to the <code>db</code> host.  Using alias is usually a good idea because it allows you to replace images without the need to modify test code.  For example, you can replace the <code>mysql</code> image with <code>mariadb</code> , and the script will still work correctly. <br><br><h4>  Waiting for containers </h4><br>  Since pluggable containers take a long time to load, you may need to implement a wait before sending any requests.  The simple way is the <a href="https://github.com/vishnubob/wait-for-it">wait-for-it.sh</a> script with a defined timeout. <br><br><h3>  Using Docker Compose </h3><br>  For most cases, <code>services</code> should be sufficient.  However, sometimes you may need to interact with external services.  For example, in the case of launching Kafka and ZooKeeper in two separate containers (this is how the official images are assembled).  Another example is the launch of tests with a dynamic number of nodes, for example, Selenium.  The best solution for running such services would be <a href="https://docs.docker.com/compose/">Docker Compose</a> : <br><br><pre> <code class="plaintext hljs">version: '3' services: zookeeper: image: confluentinc/cp-zookeeper environment: ZOOKEEPER_CLIENT_PORT: 2181 kafka: image: confluentinc/cp-kafka environment: KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092 ports: - 9092:9092</code> </pre><br>  If you are using your installation with GitLab runners on trustworthy servers, you can start the Docker Composer through the <a href="https://docs.gitlab.com/runner/executors/shell.html">Shell executor</a> .  Another possible option is the <a href="https://hub.docker.com/_/docker">Docker in Docker</a> ( <code>dind</code> ) <code>dind</code> .  But in that case, read <a href="https://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/">this article</a> first. <br><br>  One way to use Compose is to set up an environment, run tests, and then destroy everything.  A simple bash script will look like this: <br><br><pre> <code class="plaintext hljs">docker-compose up -d ./run_tests.sh localhost:9092 docker-compose down</code> </pre> <br>  As long as you run tests in a minimal environment, everything will be fine.  Although there may be a situation in which you need to install some dependencies ... There is another way to run tests in Docker Compose - it allows you to create your Docker image with a test environment.  In one of the containers you run the tests and exit with the appropriate return code: <br><br><pre> <code class="plaintext hljs">version: '3' services: zookeeper: image: confluentinc/cp-zookeeper environment: ZOOKEEPER_CLIENT_PORT: 2181 kafka: image: confluentinc/cp-kafka environment: KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092 tests: image: registry.example.com/some-image command: ./run_tests.sh kafka:9092</code> </pre><br>  Notice that we got rid of the need to map ports.  In this example, tests can interact with all services directly. <br><br>  And their launch is carried out by one command: <br><br><pre> <code class="plaintext hljs">docker-compose up --exit-code-from tests</code> </pre> <br>  The option <code>--exit-code-from</code> implies <code>--abort-on-container-exit</code> , which means: the whole environment initiated by <code>docker-compose up</code> will be stopped after one of the containers is finished.  The completion code of this command will be equivalent to the exit code of the selected service (i.e., these are the <code>tests</code> in the example above).  If the command that runs the tests finishes with a non-zero code, then the entire <code>docker-compose up</code> will finish working with it. <br><br><h2>  Use of labels as CI tags </h2><br>  <b>Warning</b> : this is a rather unusual idea, but it seemed to me very useful and flexible. <br><br>  As you may know, GitLab has the Labels feature available at the project and group levels.  Labels can be installed on tickets and merge requests.  However, they have no relationship with the pipelines. <br><br><img src="https://habrastorage.org/webt/xt/pn/79/xtpn79pe46ztibrzwyeroay952k.png"><br><br>  A minor revision will allow access to the merge request labels in job scripts.  In GitLab 11.6, everything has become even easier, because  The <code>CI_MERGE_REQUEST_IID</code> environment variable appeared (yes, it is with the <code>IID</code> , not the <code>ID</code> ), if the pipeline uses <code>only: merge_requests</code> . <br><br>  If <code>only: merge_requests</code> not used or you are working with an older version of GitLab, MR can still be obtained by calling the API: <br><br><pre> <code class="bash hljs">curl <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$CI_API_V4_URL</span></span></span><span class="hljs-string">/projects/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$CI_PROJECT_ID</span></span></span><span class="hljs-string">/repository/commits/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$CI_COMMIT_SHA</span></span></span><span class="hljs-string">/merge_requests?private_token=</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$GITLAB_TOKEN</span></span></span><span class="hljs-string">"</span></span></code> </pre> <br>  The field we need is <code>iid</code> .  However, remember that for a given commit, many MRs can return. <br><br>  When the MR IID is received, it remains only to access the <a href="https://docs.gitlab.com/ee/api/merge_requests.html">Merge Requests API</a> and use the <code>labels</code> field from the answer: <br><br><pre> <code class="bash hljs">curl <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$CI_API_V4_URL</span></span></span><span class="hljs-string">/projects/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$CI_PROJECT_ID</span></span></span><span class="hljs-string">/merge_requests/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$CI_MERGE_REQUEST_IID</span></span></span><span class="hljs-string">?private_token=</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$GITLAB_TOKEN</span></span></span><span class="hljs-string">"</span></span></code> </pre> <br><h3>  Authorization </h3><br>  Unfortunately, at the moment <a href="https://gitlab.com/gitlab-org/gitlab-ce/issues/29566">it is not possible</a> to use <code>$CI_JOB_TOKEN</code> to access the project API (at least, if the project is not public).  If the project has limited access (internal or private), for authorization in the GitLab API you will need to generate a personal API token. <br><br><img src="https://habrastorage.org/webt/jo/c_/jn/joc_jntn1lbz5eb6tif6cfo41xs.png"><br><br>  However, this is not the safest solution, so be careful.  If the token falls into bad hands, then it may appear to write access to all your projects.  One of the ways to reduce risks is to create a separate account with the right only to read the repository and generate a personal token for this account. <br><br><h4>  How safe are your variables? </h4><br>  Just a few versions ago, the <i>Variables</i> section was called <i>Secret Variables</i> , which sounds as though they were created for the reliable storage of credentials and other critical information.  In fact, the variables are simply hidden from users who do not have Maintainer rights.  They are not encrypted on the disk, and they can be easily leaked through environment variables in scripts. <br><br>  Keep this in mind when adding any variables, and consider storing secrets in safer solutions (for example, <a href="https://www.vaultproject.io/">Vault from HashiCorp</a> ). <br><br><h3>  Use cases </h3><br>  What to do with the lists of labels - you decide.  Here are some ideas: <br><br><ul><li>  Use them for segmentation tests. </li><li>  Use key-value semantics with a colon as a delimiter (for example, labels like <code>tests:auth</code> , <code>tests:user</code> ) </li><li>  Include certain features for job'ov. </li><li>  Allow debugging of certain jobs if the label exists. </li></ul><br><h2>  Call external API </h2><br>  Although GitLab comes with a set of features already available, it’s very likely that you will want to use other utilities that can be integrated with pipelines.  The simplest method of implementation is, of course, the calls of the good old <code>curl</code> . <br><br>  If you create your own tools, you can teach them to listen to <a href="https://docs.gitlab.com/ee/user/project/integrations/webhooks.html">GitLab Webhooks</a> (see the <b>Integrations</b> tab in the project settings).  However, if you are going to use them with some critical systems, make sure that they meet the requirements of high availability. <br><br><h3>  Example: Grafana annotations </h3><br>  If you are working with <a href="https://grafana.com/">Grafana</a> , <a href="http://docs.grafana.org/reference/annotations/">annotations</a> are a great way to mark events that have occurred over time on charts.  They can be added not only manually by clicking on the GUI, but also by <a href="http_api/annotations/">invoking the Grafana REST API</a> : <br><br><img src="https://habrastorage.org/webt/9e/rr/0z/9err0z9dowhzj9jr1q_asbxsxs0.png"><br><br>  To access the API you will need to generate an API Key.  Consider creating a separate user with limited access: <br><br><img src="https://habrastorage.org/webt/qv/ab/ax/qvabaxtz1ivbshbiw1eeyx10vme.png"><br><br>  Define two variables in the project settings: <br><br><ul><li>  <code>GRAFANA_URL</code> - URL to the Grafana installation (for example, <code>https://grafana.example.com</code> ); </li><li>  <code>GRAFANA_APIKEY</code> - generated API key. </li></ul><br>  To be able to reuse it, put the script in a <a href="https://threedots.tech/post/keeping-common-scripts-in-gitlab-ci/">repository with common scripts</a> : <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash set -e if [ $# -lt 2 ]; then echo "Usage: $0 &lt;text&gt; &lt;tag&gt;" exit 1 fi readonly text="$1" readonly tag="$2" readonly time="$(date +%s)000" cat &gt;./payload.json &lt;&lt;EOF { "text": "$text", "tags": ["$tag"], "time": $time, "timeEnd": $time } EOF curl -X POST "$GRAFANA_URL/api/annotations" \ -H "Authorization: Bearer $GRAFANA_APIKEY" \ -H "content-type: application/json" \ -d @./payload.json</span></span></code> </pre> <br>  Now you can add to the CI configuration its call with the necessary parameters: <br><br><pre> <code class="plaintext hljs">deploy: stage: deploy script: - $SCRIPTS_DIR/deploy.sh production - $SCRIPTS_DIR/grafana-annotation.sh "$VERSION deployed to production" deploy-production</code> </pre> <br>  These calls can be placed in the <code>deploy.sh</code> script to simplify the CI configuration. <br><br><h2>  Bonus: quick tips </h2><br>  GitLab has <a href="https://docs.gitlab.com/ee/ci/yaml">excellent documentation</a> for all possible keywords that can be used to configure CI.  I do not want to duplicate its contents here, but I will point out some useful cases.  Click on the headings to familiarize yourself with the documentation on the topic. <br><br><h3>  <a href="https://docs.gitlab.com/ee/ci/yaml/">Advanced use only / except</a> </h3><br>  By defining templates for CI variables, you can define non-standard assemblies for some branches.  This can help, for example, to identify push fixes for urgent fixes, but do not abuse it: <br><br><pre> <code class="plaintext hljs">only: refs: - branches variables: - $CI_COMMIT_REF_NAME =~ /^hotfix/</code> </pre> <br>  GitLab has many <a href="https://docs.gitlab.com/ee/ci/variables/">predefined variables</a> in every CI job — use them. <br><br><h3>  <a href="https://docs.gitlab.com/ee/ci/yaml/">Yaml anchors</a> </h3><br>  Use them to avoid duplication. <br><br>  From version 11.3, you can also use the <a href="https://docs.gitlab.com/ee/ci/yaml/">extends keyword</a> : <br><br><pre> <code class="plaintext hljs">.common_before_script: &amp;common_before_script before_script: - ... - ... deploy: &lt;&lt;: *common_before_script</code> </pre> <br><h3>  <a href="https://docs.gitlab.com/ee/ci/yaml/">Elimination of artifacts</a> </h3><br>  By default, all artifacts collected in the pipeline will be transferred to all subsequent jobs.  If you explicitly list the artifacts on which jobs depend, you can save time and disk space: <br><br><pre> <code class="plaintext hljs">dependencies: - build</code> </pre> <br>  Or - vice versa - completely skip everything if none of them are required: <br><br><pre> <code class="plaintext hljs">dependencies: []</code> </pre> <br><h3>  <a href="https://docs.gitlab.com/ee/ci/yaml/">Git strategy</a> </h3><br>  Skip repository cloning if job will not use these files: <br><br><pre> <code class="plaintext hljs">variables: GIT_STRATEGY: none</code> </pre> <br>  Everything! <br><br>  Thank you for reading!  With feedback and questions, contact me on <a href="https://twitter.com/m1_10sz">Twitter</a> or <a href="https://www.reddit.com/user/mi_losz">Reddit</a> . <br><br>  More tips on GitLab can be found in previous publications: <br><br><ul><li>  <a href="https://threedots.tech/post/keeping-common-scripts-in-gitlab-ci/">Keeping common scripts in GitLab CI</a> ; </li><li>  <a href="https://threedots.tech/post/automatic-semantic-versioning-in-gitlab-ci/">Automatic Semantic Versioning in GitLab CI</a> . </li></ul><br><h2>  PS from translator </h2><br>  Read also in our blog: <br><br><ul><li>  " <a href="https://habr.com/ru/company/flant/blog/332712/">GitLab CI for continuous integration and delivery in production.</a>  <a href="https://habr.com/ru/company/flant/blog/332712/">Part 1: our pipeline</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/332842/">GitLab CI for continuous integration and delivery in production.</a>  <a href="https://habr.com/ru/company/flant/blog/332842/">Part 2: overcoming difficulties</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/340996/">Building projects with GitLab CI: one .gitlab-ci.yml for hundreds of applications</a> "; </li><li>  “ <a href="https://habr.com/ru/company/flant/blog/345580/">Build and heat applications in Kubernetes using dapp and GitLab CI</a> ”; </li><li>  “ <a href="https://habr.com/ru/company/flant/blog/345116/">Best CI / CD practices with Kubernetes and GitLab (review and video of the report)</a> ”. </li></ul></div>
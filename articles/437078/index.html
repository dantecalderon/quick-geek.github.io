<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How to speed up work with APIs in the R language using parallel computing, using the Yandex.Direct API as an example</title>
  <meta name="description" content="The R language today is one of the most powerful and multifunctional tools for working with data, but as we know almost always, in any barrel of honey...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="https://quick-geek.github.io/search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <section class="page js-page"><h1>How to speed up work with APIs in the R language using parallel computing, using the Yandex.Direct API as an example</h1><div class="post__text post__text-html js-mediator-article"><p>  The R language today is one of the most powerful and multifunctional tools for working with data, but as we know almost always, in any barrel of honey there is a fly in the ointment.  The fact is that R is single stream by default. </p><br><p>  Most likely, it will not disturb you for quite a long time, and you are unlikely to ask this question.  But for example, if you are faced with the task of collecting data from a large number of advertising accounts from an API, such as Yandex.Direct, then you can significantly, at least two or three times, reduce the time for data collection using multithreading. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/86f/042/b60/86f042b609e10a79893f2dfbc24fd6f8.jpg" alt="image"></p><a name="habracut"></a><br><p>  The theme of multithreading in R is not new, and has repeatedly raised Habr√© <a href="https://habr.com/post/168399/">here</a> , <a href="https://habr.com/post/168399/">here</a> and <a href="https://habr.com/post/163277/">here</a> , but the latest publication dates from 2013, and as they say everything new is well forgotten old.  In addition, multithreading was previously discussed for calculating models and teaching neural networks, and we will talk about the use of asynchrony to work with the API.  Nevertheless, I would like to take this opportunity to thank the authors of the above articles because  in writing this article they helped me a lot with their publications. </p><br><h2 id="soderzhanie">  Content </h2><br><ul><li>  <a href="https://habr.com/ru/post/437078/">What is multithreading</a> </li><li>  <a href="https://habr.com/ru/post/437078/">What packages will we use</a> </li><li>  <a href="https://habr.com/ru/post/437078/">Task</a> </li><li>  <a href="https://habr.com/ru/post/437078/">Authorization in Yandex.Direct, ryandexdirect package</a> </li><li>  <a href="https://habr.com/ru/post/437078/">Solution in a single-threaded, sequential mode, using a for loop</a> </li><li>  <a href="https://habr.com/ru/post/437078/">Solution using multithreading in R</a> <br><ul><li>  <a href="https://habr.com/ru/post/437078/">Package doSNOW and features work in multithreaded mode</a> </li><li>  <a href="https://habr.com/ru/post/437078/">DoParallel package</a> </li></ul></li><li>  <a href="https://habr.com/ru/post/437078/">Speed ‚Äã‚Äãtest between the three approaches reviewed, rbenchmark package</a> </li><li>  <a href="https://habr.com/ru/post/437078/">Conclusion</a> </li></ul><br><h2 id="chto-takoe-mnogopotochnost">  What is multithreading </h2><br><p>  <u><strong>Singleline (Sequential Computing)</strong></u> - the calculation mode in which all actions (tasks) are performed sequentially, the total duration of all specified operations in this case will be equal to the sum of the duration of all operations. </p><br><p>  <u><strong>Multithreading (Parallel Computing)</strong></u> is a computation mode in which the specified actions (tasks) are performed in parallel, i.e.  at the same time, the total time for performing all operations will not be equal to the sum of the duration of all operations. </p><br><p>  To simplify the perception, let's consider the following table: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/f01/295/d5d/f01295d5dcf31db7d8ea8826c724f271.png" alt="image"></p><br><p>  The first line of the table is conditional time units, in this case, it does not matter to us that it is seconds, minutes, or any other time intervals. </p><br><p>  In this example, we need to perform 4 operations, each operation has a different calculation duration, in single-threaded mode, all 4 operations will be performed sequentially one after the other, therefore the total time for their execution will be t1 + t2 + t3 + t4, 3 + 1 + 5 + 4 = 13. </p><br><p>  In multithreaded mode, all 4 tasks will be executed in parallel, i.e.  to start the next task, there is no need to wait until the previous one is completed, so if we start the execution of our task in 4 threads, then the total calculation time will be equal to the calculation time of the largest task, in our case this is task t3, the duration of which is in our example 5 time units, respectively, and the execution time of all 4x operations in this case will be equal to 5 time units. </p><br><h2 id="kakie-pakety-my-budem-ispolzovat">  What packages will we use </h2><br><p> For calculations in multi-thread mode, we will use the <code>foreach</code> , <code>doSNOW</code> and <code>doParallel</code> . </p><br><p>  The <code>foreach</code> package allows you to use the <code>foreach</code> construct, which is an advanced for loop. </p><br><p>  The <code>doSNOW</code> and <code>doParallel</code> are essentially twin brothers that allow you to create virtual clusters and perform parallel computing with them. </p><br><p>  At the end of the article using the <code>rbenchmark</code> package <code>rbenchmark</code> we measure and compare the duration of data collection operations from the Yandex.Direct API using all the methods described below. </p><br><p>  To work with the Yandex.Direct API, we will use the ryandexdirect package, in this article we use it as an example, you can learn more about its capabilities and functions from the <a href="https://selesnow.github.io/ryandexdirect">official documentation</a> . </p><br><p>  Code to install all the necessary packages: </p><br><pre> <code class="plaintext hljs">install.packages("foreach") install.packages("doSNOW") install.packages("doParallel") install.packages("rbenchmark") install.packages("devtools") devtools::install_github("selesnow/ryandexdirect")</code> </pre> <br><h2 id="zadacha">  Task </h2><br><p>  You need to write a code that will request a list of keywords from any number of advertising accounts Yandex.Direct.  The result must be collected in a single date frame in which there will be an additional field with the login account of the advertising account to which the keyword belongs. </p><br><p>  In this case, our task is to write the code that will perform this operation as quickly as possible on any number of advertising accounts. </p><br><h2 id="avtorizaciya-v-yandeksdirekt">  Authorization in Yandex.Direct </h2><br><p>  To work with the API of the Yandex.Direct advertising platform, you initially need to be authorized under each account from which we plan to request a list of keywords. </p><br><p>  All the code given in this article reflects an example of working with regular Yandex.Direct advertising accounts, if you work under an agent account, then you need to use the <em>AgencyAccount</em> argument and pass the login name of the agency account to it.  You can learn more about working with Yandex.Direct agent accounts using ryandexdirect package <a href="https://alexeyseleznev.wordpress.com/2018/05/16/ryandexdirect-3-0-0-%25D0%25BE%25D0%25B1%25D0%25BD%25D0%25BE%25D0%25B2%25D0%25BB%25D1%2591%25D0%25BD%25D0%25BD%25D1%258B%25D0%25B9-r-%25D0%25BA%25D0%25BB%25D0%25B8%25D0%25B5%25D0%25BD%25D1%2582-%25D0%25B4%25D0%25BB%25D1%258F-%25D1%2580%25D0%25B0%25D0%25B1%25D0%25BE%25D1%2582%25D1%258B-%25D1%2581-api/">here</a> . </p><br><p>  For authorization, you need to execute the <code>yadirAuth</code> function from the <code>yadirAuth</code> package <code>ryandexdirect</code> you need to repeat the code below for each account from which you will request a list of keywords and their parameters. </p><br><pre> <code class="plaintext hljs">ryandexdirect::yadirAuth(Login = "–ª–æ–≥–∏–Ω —Ä–µ–∫–ª–∞–º–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ –Ω–∞ –Ø–Ω–¥–µ–∫—Å–µ")</code> </pre> <br><p>  The Yandex.Direct authorization process through the <code>ryandexdirect</code> package <code>ryandexdirect</code> completely secure, despite the fact that it passes through a third-party site.  In detail about the safety of its use, I have already told in the article <a href="https://habr.com/ru/post/430888/">"How safe is it to use R packages for working with the API of advertising systems"</a> . </p><br><p>  After <em>logging in</em> , under each account in your working directory will be created file <em>login.yadirAuth.RData</em> , which will store the credentials for each account.  The file name will begin with the login specified in the <em>Login</em> argument.  If you need to save files not in the current working directory, but in any other folder, use the <em>TokenPath</em> argument, but in this case, when requesting keywords using the <code>yadirGetKeyWords</code> function <code>yadirGetKeyWords</code> you also need to use the <em>TokenPath</em> argument and specify the path to the folder where you saved the files. with credentials. </p><br><h2 id="reshenie-v-odnopotochnom-posledovatelnom-rezhime-s-ispolzovaniem-cikla-for">  Solution in a single-threaded, sequential mode, using a for loop </h2><br><p>  The easiest way to collect data from multiple accounts at once is to use a <code>for</code> loop.  Simple but not the most effective, because  One of the principles of R-language development is to avoid using loops in code. </p><br><p>  Below is a sample code to collect data from 4 accounts using a for loop, in fact, you can use this example to collect data from any number of ad accounts. </p><br><div class="spoiler">  <b class="spoiler_title">Code 1: We process 4 accounts using the usual for loop</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(ryandexdirect) # –≤–µ–∫—Ç–æ—Ä –ª–æ–≥–∏–Ω–æ–≤ logins &lt;- c("login_1", "login_2", "login_3", "login_4") # —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–π –¥–∞—Ç–∞ —Ñ—Ä–µ–π–º res1 &lt;- data.frame() # —Ü–∏–∫–ª —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö for (login in logins) { temp &lt;- yadirGetKeyWords(Login = login) temp$login &lt;- login res1 &lt;- rbind(res1, temp) }</code> </pre> </div></div><br><p>  Measuring runtime using the system.time function showed the following result: </p><br><p>  <strong>Working hours:</strong> <br>  <u>User:</u> 178.83 <br>  <u>system:</u> 0.63 <br>  <u>passed:</u> 320.39 </p><br><p>  The collection of keywords for 4 accounts took 320 seconds, while from the informational messages that the <code>yadirGetKeyWords</code> function displays during the work, the largest account from which 5970 keywords were received was processed for 142 seconds. </p><br><h2 id="reshenie-s-pomoschyu-mnogopotochnosti-v-r">  Solution using multithreading in R </h2><br><p>  Above, I already wrote that for multithreading, we will use the <code>doSNOW</code> and <code>doParallel</code> . </p><br><p>  I want to draw attention to the fact that almost any API has its limitations, and the Yandex.Direct API is not an exception.  In fact, the <a href="https://tech.yandex.ru/direct/doc/dg-v4/concepts/Restrictions-docpage/">help guide</a> for the Yandex.Direct API says: </p><br><blockquote>  Allowed no more than five simultaneous requests to the API on behalf of one user. </blockquote><p>  Therefore, in spite of the fact that in this case we will consider an example with the creation of 4 threads, you can create 5 threads with Yandex.Direct, even if you send all requests under the same user.  But the most efficient use of 1 thread per 1 core of your processor, you can determine the number of physical processor cores using the <code>parallel::detectCores(logical = FALSE)</code> command, the number of logical cores can be found using <code>parallel::detectCores(logical = TRUE)</code> .  In more detail, it is possible to understand what a physical and logical core is on <a href="https://ru.wikipedia.org/wiki/Hyper-threading">Wikipedia</a> . </p><br><p>  In addition to the limit on the number of requests, there is a daily limit on the number of points for accessing the Yandex.Direct API, it may be different for all accounts, each request also consumes a different number of points depending on the operation being performed.  For example, for requesting a list of keywords, 15 points will be deducted from you for a completed request and 3 points for every 2000 words, you can learn about how points are written off in the <a href="https://tech.yandex.ru/direct/doc/dg/concepts/units-docpage/">official certificate</a> .  You can also see information about the number of points written and available, as well as about their daily limit in the informational messages returned to the console by the <code>yadirGetKeyWords</code> function. </p><br><pre> <code class="plaintext hljs">Number of API points spent when executing the request: 60 Available balance of daily limit API points: 993530 Daily limit of API points:996000</code> </pre> <br><p>  Let's <code>doSNOW</code> at <code>doSNOW</code> and <code>doParallel</code> in order. </p><br><h3 id="paket-dosnow-i-osobennosti-raboty-v-mnogopotochnom-rezhime">  Package doSNOW and features work in multithreaded mode </h3><br><p>  Let's rewrite the same operation to the multithreaded mode of calculations, create 4 threads, and use the <code>foreach</code> construct instead of the <code>for</code> <code>foreach</code> . </p><br><div class="spoiler">  <b class="spoiler_title">Code 2: Parallel computing with the doSNOW package</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(foreach) library(doSNOW) # –≤–µ–∫—Ç–æ—Ä –ª–æ–≥–∏–Ω–æ–≤ logins &lt;- c("login_1", "login_2", "login_3", "login_4") cl &lt;- makeCluster(4) registerDoSNOW(cl) res2 &lt;- foreach(login=logins, .combine= 'rbind', .inorder=F ) %dopar% {cbind(ryandexdirect::yadirGetKeyWords(Login = login), login) } stopCluster(cl)</code> </pre> </div></div><br><p>  I will give a small explanation of <em>code 2</em> , the function <code>makeCluster</code> is responsible for the number of threads, in this case we created a cluster of 4 processor cores, but as I wrote earlier when working with the Yandex.Direct API, you can create 5 threads no matter how many accounts you need to process 5-15-100 or more, you can simultaneously send requests to API 5. </p><br><p>  Next, the <code>registerDoSNOW</code> function starts the created cluster. </p><br><p>  After that, we use the <code>foreach</code> construct, as I said earlier, this construct is an advanced for loop.  You set the counter as the first argument, in the above example I called it <em>login</em> and it would iterate through the elements of the <em>logins</em> vector at each iteration, we would get the same result in the <code>for</code> loop if we wrote <code>for ( login in logins)</code> . </p><br><p>  Next, you need to specify the function in the <em>.combine</em> argument, with which you will combine the results obtained at each iteration, the most frequent options are: </p><br><ul><li>  <code>rbind</code> - connect the resulting tables row by row under each other; </li><li>  <code>cbind</code> - join the resulting tables in columns; </li><li>  <code>"+"</code> - summarize the result obtained at each iteration. </li></ul><br><p>  You can also use any other function, even self-written. </p><br><p>  The argument <em>.inorder = F</em> allows you to speed up the function a little more if you don‚Äôt fundamentally in what order to combine the results, in this case the order is not important to us. </p><br><p>  Next comes the <code>%dopar%</code> that starts the loop in parallel computing mode, if you use the <code>%do%</code> statement, then the iterations will be executed sequentially, just like when using the usual <code>for</code> loop. </p><br><p>  The <code>stopCluster</code> function stops the cluster. </p><br><p>  Multithreading, or rather <code>foreach</code> constructs in multi-threaded mode, have some peculiarities, in fact in this case we start every parallel process in a new, clean R session, so you cannot use self-writing functions and objects inside it that are outside of the <code>foreach</code> construct.  Below is an example of incorrect code that will <u><strong>not</strong></u> work. </p><br><div class="spoiler">  <b class="spoiler_title">Code 3: Incorrect use of samopny functions inside foreach</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(foreach) library(doSNOW) myfun &lt;- function(x, y) { return(x + y)} vec_x &lt;- c(1:1000) cl &lt;- makeCluster(4) registerDoSNOW(cl) result &lt;- foreach(x = vec_x, .combine= '+', .inorder=F ) %dopar% {myfun(x, runif(1, 1, 100000))}</code> </pre> </div></div><br><p>  This example will not work.  the <code>myfun</code> self- <code>myfun</code> function <code>myfun</code> defined outside the <code>foreach</code> construct, and as I said, <code>foreach</code> runs every thread in a clean R session, with an empty working environment, and does not see the objects and functions that you created outside its scope. </p><br><p>  Also, <code>foreach</code> does not see packages that were previously connected, so in order to use functions from any package, in our case <code>ryandexdirect</code> you need to either register its connection through <code>foreach</code> through the <code>library</code> function, or access its functions via package_name :: function_name, as I did in the example code above. </p><br><p>  If you want to use any samopny functions inside the <code>foreach</code> , then either declare them inside the <code>foreach</code> or first save their code to the .R file and read it inside the <code>foreach</code> using the <code>source</code> function.  The same applies to any other objects created during the R session in your working environment outside of the <code>foreach</code> structure, if you plan to use them inside <code>%dopar%</code> you need to save them before running the structure using the <code>save</code> or <code>saveRDS</code> , and inside <code>%dopar%</code> load on each iteration using the <code>load</code> or <code>readRDS</code> .  Below is an example of proper work with objects created in the working environment before running <code>foreach</code> . </p><br><div class="spoiler">  <b class="spoiler_title">Code 4: An example of proper work with objects from the working environment inside foreach</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(foreach) library(doSNOW) mydata &lt;- read.csv("data.csv") cl &lt;- makeCluster(4) registerDoSNOW(cl) saveRDS(mydata, file = "mydata.rds") result &lt;- foreach(data_row = 1:nrow(mydata), .combine= 'rbind', .inorder=F ) %dopar% { mydata &lt;- readRDS("mydata.rds") ... –¢–ï–õ–û –¶–ò–ö–õ–ê –ü–ï–†–ï–ë–ò–†–ê–Æ–©–ï–ì–û –°–¢–†–û–ö–ò –¢–ê–ë–õ–ò–¶–´ mydata –ß–ï–†–ï–ó mydata[ data_row, ] ... }</code> </pre> </div></div><br><p>  In this case, the execution time measurement using the system.time function showed the following result: </p><br><p>  <strong>Working hours:</strong> <br>  <u>User:</u> 0.17 <br>  <u>system:</u> 0.08 <br>  <u>passed:</u> 151.47 </p><br><p>  The same result, i.e.  we got a collection of keywords from 4 Yandex.Direct accounts in 151 seconds, i.e.  2 times faster.  Besides, it‚Äôs not just in the past example that I wrote how long it took to load a list of keywords from the largest account (142 seconds), i.e.  in this example, the total time is almost identical to the processing time of the largest account.  The fact is that with the help of the <code>foreach</code> function we simultaneously launched the process of collecting data in 4 streams, i.e.  simultaneously collected data from all 4 accounts, respectively, the total work time is equal to the processing time of the largest account. </p><br><h3 id="paket-doparallel">  DoParallel package </h3><br><p>  As I wrote above, the <code>doSNOW</code> and <code>doParallel</code> are twins, so the syntax is the same. </p><br><div class="spoiler">  <b class="spoiler_title">Code 5: Parallel computing using the doParallel package</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(foreach) library(doParallel) logins &lt;- c("login_1", "login_2", "login_3", "login_4") cl &lt;- makeCluster(4) registerDoParallel(cl) res3 &lt;- data.frame() res3 &lt;- foreach(login=logins, .combine= 'rbind', .inorder=F) %dopar% {cbind(ryandexdirect::yadirGetKeyWords(Login = login), login) stopCluster(cl)</code> </pre> </div></div><br><p>  <strong>Working hours:</strong> <br>  <u>User:</u> 0.25 <br>  <u>system:</u> 0.01 <br>  <u>passed:</u> 173.28 </p><br><p>  As you can see in this case, the execution time is slightly different from the past example of parallel computing code using the <code>doSNOW</code> package. </p><br><h2 id="test-skorosti-mezhdu-tremya-rassmotrennymi-podhodami">  Speed ‚Äã‚Äãtest between the three approaches considered </h2><br><p>  Now run the speed test with the <code>rbenchmark</code> package. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/a63/b9d/2d4/a63b9d2d476203e701c1c789f013793b.png" alt="image"></p><br><p>  As you can see, even on a test of 4 accounts, <code>doSNOW</code> and <code>doParallel</code> received data on keywords 2 times faster than a consecutive for loop, if you create a cluster of 5 cores and process 50 or 100 accounts, the difference will be even more significant. </p><br><div class="spoiler">  <b class="spoiler_title">Code 6: Comparison script for multithreading speed and sequential calculations</b> <div class="spoiler_text"><pre> <code class="plaintext hljs"># –ø–æ–¥–∫–ª—é—á–∞–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ library(ryandexdirect) library(foreach) library(doParallel) library(doSNOW) library(rbenchmark) # —Å–æ–∑–¥–∞—ë–º —Ñ—É–Ω–∫—Ü–∏—é —Å–±–æ—Ä–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ü–∏–∫–ª–∞ for for_fun &lt;- function(logins) { res1 &lt;- data.frame() for (login in logins) { temp &lt;- yadirGetKeyWords(Login = login) res1 &lt;- rbind(res1, temp) } return(res1) } # —Å–æ–∑–¥–∞—ë–º —Ñ—É–Ω–∫—Ü–∏—é —Å–±–æ—Ä–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ foreach –∏ –ø–∞–∫–µ—Ç–∞ doSNOW dosnow_fun &lt;- function(logins) { cl &lt;- makeCluster(4) registerDoSNOW(cl) res2 &lt;- data.frame() system.time({ res2 &lt;- foreach(login=logins, .combine= 'rbind') %dopar% {temp &lt;- ryandexdirect::yadirGetKeyWords(Login = login } }) stopCluster(cl) return(res2) } # —Å–æ–∑–¥–∞—ë–º —Ñ—É–Ω–∫—Ü–∏—é —Å–±–æ—Ä–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ foreach –∏ –ø–∞–∫–µ—Ç–∞ doParallel dopar_fun &lt;- function(logins) { cl &lt;- makeCluster(4) registerDoParallel(cl) res2 &lt;- data.frame() system.time({ res2 &lt;- foreach(login=logins, .combine= 'rbind') %dopar% {temp &lt;- ryandexdirect::yadirGetKeyWords(Login = login) } }) stopCluster(cl) return(res2) } # –∑–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–≤—É–º –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏—è–º within(benchmark(for_cycle = for_fun(logins = logins), dosnow = dosnow_fun(logins = logins), doparallel = dopar_fun(logins = logins), replications = c(20), columns=c('test', 'replications', 'elapsed'), order=c('elapsed', 'test')), { average = elapsed/replications })</code> </pre></div></div><br><p>  In conclusion, I will give an explanation of the above <em>code 5</em> , with which we tested the speed of work. </p><br><p>  Initially, we created three functions: </p><br><p>  <code>for_fun</code> - a function requesting keywords from a variety of accounts, sequentially going through them in a normal cycle. </p><br><p>  <code>dosnow_fun</code> is a function requesting a list of keywords in multi-threaded mode using the <code>doSNOW</code> package. </p><br><p>  <code>dopar_fun</code> - function requesting a list of keywords in multi-threaded mode, using the <code>doParallel</code> package. </p><br><p>  Next, inside the within construction, we run the <code>benchmark</code> function from the <code>rbenchmark</code> package, specify the test names (for_cycle, dosnow, doparallel), and specify the functions for each test, respectively: <code>for_fun(logins = logins)</code> ;  <code>dosnow_fun(logins = logins)</code> ;  <code>dopar_fun(logins = logins)</code> . </p><br><p>  The <em>replications</em> argument is responsible for the number of tests, i.e.  how many times we will run each function. </p><br><p>  The <em>columns</em> argument allows you to specify which columns you want to get, in our case, 'test', 'replications', 'elapsed' means to return the columns: the name of the test, the number of tests, the total run time of all tests. </p><br><p>  You can also add calculated columns, ( <code>{ average = elapsed/replications }</code> ), i.e.  in the output there will be an average column which divides the total time by the number of tests, so we will calculate the average execution time of each function. </p><br><p>  <em>The order</em> is responsible for sorting the test results. </p><br><h2 id="zaklyuchenie">  Conclusion </h2><br><p>  In this article, in principle, a fairly universal method for accelerating work with API is described, but each API has its limits, so specifically in this form, with so many threads, the given example is suitable for working with Yandex.Direct API, for using it with API Other services initially need to read the documentation about the limits in the API on the number of simultaneously sent requests, otherwise you may get an error <code>Too Many Requests</code> . </p></div><p>Source: <a href="https://habr.com/ru/post/437078/">https://habr.com/ru/post/437078/</a></p>
<section class="navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container">Waiting for the list from <a href="../../index.html">here</a>...</nav>
</section>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52319614 = new Ya.Metrika({
                  id:52319614,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52319614" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>
</body>

</html>
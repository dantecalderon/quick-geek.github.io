<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Fight for quality solutions on Erlang / Elixir</title>
  <meta name="description" content="@jcutrer 


 Today we will talk about event logs, quantitative metrics and monitoring all of this in order to increase the team‚Äôs response rate to inc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="https://quick-geek.github.io/search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <section class="page js-page"><h1>Fight for quality solutions on Erlang / Elixir</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/s8/mq/lh/s8mqlhd99fmiu32vwgxnk4x-8yu.jpeg"><br>  <a href="https://unsplash.com/%40jcutrer">@jcutrer</a> </p><br><p>  Today we will talk about event logs, quantitative metrics and monitoring all of this in order to increase the team‚Äôs response rate to incidents and to reduce the target system‚Äôs downtime. </p><br><p>  Erlang / OTP as a framework and ideology of building distributed systems gives us regulated approaches to development, tools and implementation of standard components.  Suppose we have applied the potential of OTP and have gone all the way from prototype to production.  Our Erlang project feels great on the combat servers, the code base is constantly evolving, new requirements and functionality appear, new people join the team, and everything seems to be good.  But sometimes something goes wrong and technical problems, multiplied by the human factor, can lead to an accident. </p><br><p>  Since it is impossible to lay straws absolutely for all possible cases of failures and problems, or it is not economically feasible, it is necessary to reduce the system downtime in case of failures with management and software solutions. </p><a name="habracut"></a><br><p>  In information systems there will always be the probability of occurrence of failures of different nature: </p><br><ul><li>  Hardware failures and power failures </li><li>  Network failures: configuration errors, firmware curves </li><li>  Logical errors: starting from coding errors of algorithms and ending with architectural problems arising at the boundaries of subsystems and systems. </li><li>  Security issues and related attacks and hacks, including internal fraud. </li></ul><br><p>  Immediately delineate the responsibility: for the operation of computing equipment and data networks will be responsible for monitoring the infrastructure, for example, organized by means of zabbix.  Much has been written about the installation and setup of such monitoring, we will not repeat it. </p><br><p>  From the point of view of the developer, the problem of accessibility and quality lies in the plane of early detection of errors and problems with performance and early response to them.  This requires approaches and means of assessment.  So, we will try to derive quantitative metrics, analyzing which we can significantly improve the quality at different stages of project development and operation. </p><br><h3 id="sistemy-sborki">  Assembly systems </h3><br><p>  Let me remind you once again about the importance of the engineering approach and testing in software development.  Erlang / OTP offers two testing frameworks at once: eunit and common test. </p><br><p>  The number of successful and problem tests, their time and percentage of code coverage by tests can be used as metrics for the initial assessment of the state of the code base and its dynamics.  Both frameworks allow you to save test results in Junit format. <br>  For example, for rebar3 and ct, you need to add the following lines to rebar.config: </p><br><pre><code class="erlang hljs">{cover_enabled, true}. {cover_export_enabled, true}. {ct_opts,[ {ct_hooks, [{cth_surefire, [{path, <span class="hljs-string"><span class="hljs-string">"report.xml"</span></span>}]}]} ]}.</code> </pre> <br><p>  The number of successful and unsuccessful tests will allow you to build a trend graph: <br><img src="https://habrastorage.org/webt/mw/lc/mw/mwlcmw24mj6f9wz5ctxshc4baf4.png"><br>  looking at which, you can evaluate the dynamics of the team and the regression of tests.  For example, in Jenkins, this graph can be obtained using the Test Results Analyzer Plugin. </p><br><p>  If the tests are reddened or started to take a long time, the metrics will allow sending the release for revision even at the assembly stage and automatic testing. </p><br><h3 id="metriki-prilozheniy">  Application Metrics </h3><br><p>  In addition to the operating system metrics, monitoring should include application metrics, such as the number of views per second, the number of payments, and other critical indicators. </p><br><p>  In my projects, I use the <code>${application}.${metrics_type}.${name}</code> template for naming metrics.  This naming allows you to get lists of metrics like </p><br><pre> <code class="bash hljs">messaging.systime_subs.messages.delivered = 1654 messaging.systime_subs.messages.proxied = 0 messaging.systime_subs.messages.published = 1655 messaging.systime_subs.messages.skipped = 3</code> </pre> <br><p>  Perhaps the more metrics, the easier it is to understand what is happening in a complex system. </p><br><h3 id="metriki-erlang-vm">  Erlang VM metrics </h3><br><p>  Special attention should be paid to monitoring Erlang VM.  The ideology of let it crash is beautiful, and the proper use of OTP will certainly help lift the fallen parts of the application inside the Erlang VM.  But do not forget about the Erlang VM itself, because it is difficult to drop it, but you can.  All options are based on the exhaustion of resources.  We list the main ones: </p><br><ul><li><p>  Overflow table of atoms. <br>  Atoms are identifiers whose main task is to improve the readability of the code.  Atoms once created remain forever in the memory of the Erlang VM instance, since they are not cleared by the garbage collector.  Why is this happening?  The garbage collector works separately in each process with data from this process, while atoms can be distributed over the data structures of multiple processes. <br>  By default, 1,048,576 atoms can be created.  In articles about how to kill Erlang VM, you can usually find something like this </p><br><pre> <code class="erlang hljs">[list_to_atom(integer_to_list(I)) || I &lt;- lists:seq(erlang:system_info(atom_count), erlang:system_info(atom_limit))]</code> </pre> <br><p>  as an illustration of this effect.  It would seem that an artificial problem is unattainable in real systems, but there are cases ... For example, in the external API handler, when parsing queries, <code>binary_to_atom/2</code> instead of <code>binary_to_existing_atom/2</code> or <code>list_to_atom/1</code> instead of <code>list_to_existing_atom/1</code> . <br>  To monitor the state of atoms is to use the following parameters: </p><br><ol><li>  <code>erlang:memory(atom_used)</code> - the amount of memory used for atoms </li><li>  <code>erlang:system_info(atom_count)</code> - the number of atoms created in the system.  Together with <code>erlang:system_info(atom_limit)</code> you can calculate atom utilization. </li></ol><br></li><li><p>  Process leaks <br>  I just want to say that when process_limit is reached (+ P argument erl) erlang vm does not fall, but it goes into an alarm state, for example, even connecting to it will most likely be impossible.  Ultimately, the exhaustion of available memory when allocated to leaked processes will lead to a drop in erlang vm. </p><br><ol><li>  <code>erlang:system_info(process_count)</code> - the number of active processes at the moment.  Together with <code>erlang:system_info(process_limit)</code> you can calculate the utilization of processes. </li><li>  <code>erlang:memory(processes)</code> - allocated memory for processes </li><li>  <code>erlang:memory(processes_used)</code> - used memory for processes. </li></ol><br></li><li><p>  Overflow mailbox process. <br>  A typical example of a similar problem is that the sender process sends messages to the recipient process without waiting for confirmation, while <code>receive</code> in the recipient process ignores all of these messages due to a missing or incorrect pattern.  As a result, messages are saved in the mailbox.  Although in erlang there is a mechanism for slowing down the sender if the handler does not cope with processing, all the same after the exhaustion of the available memory, vm drops. <br>  Whether etop can help you understand if the mailbox overflows. </p><br><pre> <code class="bash hljs">$ erl -name etop@host -hidden -s etop -s erlang halt -output text -node dest@host -setcookie some_cookie -tracing off -sort msg_q -interval 1 -lines 25</code> </pre> <br><p><img src="https://habrastorage.org/webt/k3/rc/xu/k3rcxuudnptazhjl0pxql1vmfji.png"><br>  As a metric for continuous monitoring, you can take the number of problematic processes.  To identify them, you can use the following function: </p><br><pre> <code class="erlang hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">top_msq_q</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">-&gt;</span></span> [{P, RN, L, IC, ST} || P &lt;- processes(), { _, L } &lt;- [ process_info(P, message_queue_len) ], L &gt;= <span class="hljs-number"><span class="hljs-number">1000</span></span>, [{_, RN}, {_, IC}, {_, ST}] &lt;- [process_info(P, [registered_name, initial_call, current_stacktrace]) ] ].</code> </pre> <br><p>  This list can also be logged, then when receiving a notification from monitoring, the analysis of the problem is simplified. </p><br></li><li><p>  Leaks binaries. <br>  Memory for large (more than 64 bytes) binaries is allocated in the general heap.  A dedicated block has a reference count showing the number of processes that have access to it.  After resetting the counter, the cleaning takes place.  The simplest system, but as they say, there are nuances.  In principle, there is the likelihood of a process generating so much garbage on the heap that the system does not have enough memory to carry out cleaning. <br>  The monitoring metric is <code>erlang:memory(binary)</code> , showing the memory allocated for binaries. </p><br></li></ul><br><p>  So, the cases leading to the drop in vm have been disassembled, but apart from them, it is not bad to monitor no less important parameters that directly or indirectly affect the correct functioning of your applications: </p><br><ul><li>  Memory used by ETS tables: <code>erlang:memory(ets)</code> . </li><li>  Memory compiled modules: <code>erlang:memory(code)</code> . <br>  If your solutions do not use dynamic code compilation, then this parameter can be excluded. <br>  Separately, I want to mention erlydtl.  If you compile the templates dynamically, then as a result of the compilation, a beam is created that is loaded into the vm memory.  It can also cause memory leaks. </li><li>  System memory: <code>erlang:memory(system)</code> .  Shows memory consumption by erlang runtime. </li><li>  Total memory consumed: <code>erlang:memory(total)</code> .  This is the sum of memory consumed by processes and runtime. </li><li>  Information about reductions: <code>erlang:statistics(reductions)</code> . </li><li>  The number of processes and ports that are ready for execution: <code>erlang:statistics(run_queue)</code> . </li><li>  Uptime instance vm: <code>erlang:statistics(runtime)</code> - allows without analyzing the logs to understand whether there was a restart. </li><li>  Network Activity: <code>erlang:statistics(io)</code> . </li></ul><br><h3 id="otpravka-metrik-v-zabbix">  Sending metrics in zabbix </h3><br><p>  Let's create a file containing application metrics and erlang vm metrics, which will be updated every N seconds.  For each erlang node, the metrics file must contain the metrics of the applications running on it and the metrics of the erlang vm instance.  The result should be something like this: </p><br><pre> <code class="bash hljs">messaging.systime_subs.messages.delivered = 1654 messaging.systime_subs.messages.proxied = 0 messaging.systime_subs.messages.published = 1655 messaging.systime_subs.messages.skipped = 3 ‚Ä¶. erlang.io.input = 2205723664 erlang.io.output = 1665529234 erlang.memory.binary = 1911136 erlang.memory.ets = 1642416 erlang.memory.processes = 23596432 erlang.memory.processes_used = 23598864 erlang.memory.system = 50883752 erlang.memory.total = 74446048 erlang.processes.count = 402 erlang.processes.run_queue = 0 erlang.reductions = 148412771 ....</code> </pre> <br><p>  With the help of <code>zabbix_sender</code> we will send this file to zabbix, where a graphical representation and the ability to create automation and notification triggers will already be available. </p><br><p>  Now, having the metrics in the monitoring system and the automation triggers and notification events created on their basis, we have a chance to avoid accidents by responding in advance to all dangerous deviations from the full-featured state. </p><br><h3 id="centralnyy-sbor-logov">  Central collection of logs </h3><br><p>  When in the project 1-2 servers, you can probably still live without a central collection of logs, but as soon as a distributed system appears with multiple servers, clusters, environments, there is a need to solve the problem of collecting and conveniently viewing logs. </p><br><p>  To write logs in my projects, I use lager.  Often, on the way from prototype to production, projects go through the following stages of collecting logs: </p><br><ul><li>  The simplest logging with output to a local file or even to stdout (lager_file_backend) </li><li>  Centralized logging using, for example, syslogd and automatically sending logs to the collector.  For such a scheme is suitable <a href="https://github.com/basho/lager_syslog">lager_syslog</a> . <br>  The main drawback of the scheme is that it is necessary to go to the server for collecting logs, find the file with the necessary logs and somehow filter the events in search of the ones needed for debugging. </li><li>  Centralized collection of logs with storage in the repository with the ability to filter and search by records. </li></ul><br><p>  We will talk about the minuses, pros and quantitative metrics that can be used using the latter, and <code>lager_clickhouse</code> talk in the light of a specific implementation - <code>lager_clickhouse</code> , which I use in most of the projects I am developing.  A few words about <code>lager_clickhouse</code> .  This is the lager backend for saving events to clickhouse.  At the moment, this is an internal project, but there are plans to make it open.  When developing lager_clickhouse, I had to bypass some of the features of clickhouse, for example, to use event buffering in order not to make frequent requests to clickhouse.  The effort spent has paid off with stable work and good performance. </p><br><p>  The main disadvantage of the storage caching approach is an additional entity ‚Äî clickhouse and the need to develop event saving code in it and a user interface for analyzing and searching for events.  Also for some projects it may be critical to use tcp to send logs. </p><br><p>  But the pros, I think, outweigh all the possible disadvantages. </p><br><ul><li><p>  Easy and quick event search: </p><br><ul><li>  Filter by date without having to search for a file / files on a central server containing a range of events. </li><li>  Filtering by environment.  Logs from different subsystems and often from different clusters are written to one repository.  At the moment, the separation occurs by tags, which are set on each node of the cluster. </li><li>  Filter by node name </li><li>  Filtering by the name of the module that sent the event </li><li>  Filter by event type </li><li>  Text search </li></ul><br><p>  An exemplary view of the log viewing interface is shown in the screenshot: <br><img src="https://habrastorage.org/webt/tz/6s/qy/tz6sqy5ofprtonxlxkhywfr7gmy.png"></p><br></li><li><p>  Ability to automate. <br>  With the introduction of the log repository, it became possible to get real-time information about the number of errors, the occurrence of critical faults, and system activity.  By entering certain limits, we can generate emergency events of the system‚Äôs exit from the functional state, the handlers of which will perform automation actions to eliminate this state and send notifications to the team members responsible for the functionality: </p><br><ul><li>  When a critical error occurs. </li><li>  In the event of a massive occurrence of errors (the time derivative increases faster than a certain limit). </li><li>  A separate metric is the speed of event generation, that is, how many new events appear in the event log.  Almost always you can know the approximate amount of logs generated by the project per unit of time.  If it is multiply exceeded, then most likely something goes wrong. </li></ul><br></li></ul><br><p>  A further development of the automation theme for handling emergency events was the use of lua scripts.  Any developer or administrator can write a script for processing logs and metrics.  Scripts bring flexibility and allow you to create personal automation and notification scripts. </p><br><h3 id="itogi">  Results </h3><br><p>  To understand the processes occurring in the system and investigate incidents, it is vital to have quantitative indicators and event logs, as well as convenient tools for analyzing them.  The more information available about the system is available to us, the easier it is to analyze its behavior and correct problems even at the stage of their occurrence.  In the case when our measures did not work, we always have schedules and detailed logs of the incident. </p><br><p>  How do you exploit solutions on Erlang / Elixir and what interesting cases did you encounter in production? </p></div><p>Source: <a href="https://habr.com/ru/post/437720/">https://habr.com/ru/post/437720/</a></p>
<section class="navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container">Waiting for the list from <a href="../../index.html">here</a>...</nav>
</section>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52319614 = new Ya.Metrika({
                  id:52319614,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52319614" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>
</body>

</html>
<div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/webt/il/db/l0/ildbl0rgeufxd3tgzdstzyosr5a.jpeg" width="500"></div>  <sub>In the photo - the first four-wheel flying bike.</sub>  <sub><a href="https://www.hammacher.com/product/first-flying-bicycle">A source.</a></sub> <br><br>  Today, thanks to the availability of necessary services, placing video on the network is not a difficult task.  However, there are not so many materials on the internal design of such systems, especially in the Russian-speaking segment. <br><br>  I have been engaged in designing and developing a high-quality video platform for some time.  In this article I want to describe those moments that I would like to know at the beginning of development. <br><br>  The article does not pretend to the status of leadership, in it I will try to describe only interesting or non-obvious points affecting the processing and delivery of video content based on HTML5. <br>  The material is designed for those who are already in the subject, or is ready to look for decoding abbreviations, terms and concepts. <br><br>  <a href="https://habr.com/ru/post/437936/">The second part of.</a> <br><a name="habracut"></a><br><h3>  Format </h3><br>  H264 High-profile, despite its popularity, it turns out, does not work everywhere - some browsers do not include its support.  Fortunately, on modern devices, almost everywhere where H264 is not supported, VP8 / 9 work.  VP9 is preferable to use, because  old versions of decoders that can VP8, but not VP9 or H264, I have not met.  VP9 gives the picture quality comparable to H264 with a bitrate of ~ 30% lower - this is important for reducing the load on the channels.  Additionally, if the use of MPEG-codec can potentially have legal claims (a very complicated story), then VP9 is fine with that.  True, the coding speed of VP9 is lower by about an order of magnitude, so more resources should be allocated for its processing. <br><br>  If there is a need to support old equipment that does not cope with H264 High, then you can add 480p H264 Main as a third format with a lower bit rate. <br><br>  It is better not to use Hi10P in large quantities due to weak hardware decoding support. <br>  H265 is clearly going to demand license fees, which is not for everyone. <br><br><h3>  Soft vs hard </h3><br>  Hardware encoders do not use most of the advanced features of the codecs (the saving of space on the chips affects), yielding non-optimally scrambled files.  The choice of format is limited, not everything is possible to adjust the encoding parameters - often, from the actual values ​​affecting the result there is only the bitrate, and even that is perceived in a very peculiar way.  If everything is done as it should, then on normal chips you can get quite sane result with a linear (impact in dynamic scenes) and a bit too high bitrate. <br><br>  And, of course, for a hardware encoder to work, you need a device - a video card or a processor with a video core, which are not available in all servers. <br><br>  But they are fast.  Highly.  Compared to software processing, the speed can grow a couple of hundred times, to the level at which the disk IO might not be enough. <br><br>  Processing by hardware is very much dependent on the solution provider - each vendor has its own set of libraries and utilities for this, and there is something to choose from: Intel Quick Sync, NVenc, AMD VCE. <br><br>  With software processing, there are no such restrictions, and with an equivalent bitrate, the result is better.  To work with various formats and codecs there is ffmpeg;  the “apparatchik” has no such luxury (with reservations). <br><br><h3>  Video quality criteria </h3><br>  To determine the target quality, the easiest way to count in bits per pixel is BPP.  This parameter is independent of resolution, frame rate, and duration.  From him already count the bitrate by the formula <br><pre><code class="plaintext hljs">BPP * Framerate * Width * Height</code> </pre>  Optimal BPP values ​​are best chosen by independent experiments under the video that you plan to process.  A good starting value for H264 is around 0.09 bps / pixel.  For high-performance codecs like H265 and VP9, ​​this parameter can be reduced in proportion to the comparative compression ratio.  Also, BPP can be slightly reduced for high resolution video, because  The efficiency of codecs slightly increases with resolution, however, for this amendment, the resolution of the coding section (slices, a feature of codecs allowing video coding by semi-independent fractional resolution units) should be taken into account. <br><br>  For the resulting bitrate formula, it is desirable to predetermine the maximum values, based on the expected Internet speed of the client - very few people will be comfortable watching the very high-quality but constantly buffered video. <br><br>  That is why it is inconvenient to use the Q-parameters of codecs (quality parrots) - fixed values ​​give an unpredictable final bitrate. <br><br>  maxRate is best done with a margin, because  codecs may not accurately maintain the required values, even with two-pass encoding. <br><br>  To preserve the quality of dynamic scenes, it is better to enable VBR mode of codecs, however minRate is better to set at least 90% of the final bitrate so that the rate peaks do not lead to buffer underrun. <br><br>  In quality control, utilities like Intel VPA, ffprobe and Python are useful.  Using the latter, it is convenient to make comparisons of the source code and the converted video, count arbitrary metrics, such as the average pixel deviation. <br><br>  The PSNR and SSIM calculation in practice is extremely inefficient due to the psycho-visual optimizations included by default in codecs.  If there is a desire to calculate these metrics more or less adequately, you can disable optimization through <pre> <code class="plaintext hljs">-tune [psnr|ssim]</code> </pre>  However, the final file, of course, will be different from what was done without these flags. <br><br><h3>  Preview </h3><br>  The main problem of generating previews of images is a fuzzy source.  Definition and search for clear images is a very nontrivial and resource-intensive task.  Fortunately, the solution to this problem in most codecs is included in the video encoding process.  You can take the key frame closest to a certain position, of all the frames surrounding it, it will be the clearest.  In ffmpeg, you can do it like this: <br><br><pre> <code class="plaintext hljs">-ss [позиция] -vf \"select='eq(pict_type,PICT_TYPE_I)'\" -vsync vfr</code> </pre> <br>  Standard encoders do not compress in the best way, so after receiving the image it is better to press it with something like optipng - an average saving of 500kB on the FHD preview. <br><br>  High-resolution images are best interlaced.  Thus, we will slightly increase the size (by 5-10%), but seriously reduce the display time on the loading page. <br><br>  The article has already turned out to be dense, and I have doubts that all the information should be packaged in one huge text.  If the continuation on this topic is interesting, write in the comments or tick in the survey. <br><br>  The platform is closed, but you can look at its work <a href="http://policat.tk/">here</a> . <br><br>  <sub>* I have no relation to the authors of the relevant sites and can not share their views and opinions.</sub>  <sub>Decisions about who and how to access the code, I can not comment.</sub> <br><br>  Ready to answer questions. </div>
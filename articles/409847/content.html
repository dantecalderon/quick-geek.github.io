<div class="post__text post__text-html js-mediator-article"><h2>  The WiFi to energy converter is unusable, but may nevertheless be a source of future energy. </h2><br><img src="https://habrastorage.org/getpro/geektimes/post_images/7b2/8c0/714/7b28c0714e63b7d3e27041c9bfd84675.jpg"><br><br>  I am a little turned on energy efficiency.  I am upset by the fact that the idiots who built my house did not use the latest information available at the time of construction - after all, then my house would hardly need heating.  And one of the most interesting things for me is the prospect of re-use of discarded energy.  I like the idea of ​​collecting energy, which would otherwise be doomed to dissipate in the environment, and turn it into something useful. <br><br>  Therefore, the <a href="https://dx.doi.org/10.1038/s41598-017-15298-5">work</a> on the reuse of microwave energy could not pass by me.  Unfortunately, the collection of WiFi radiation is unlikely to give us something useful.  But first, let's look at the very interesting ideas behind this device. <br><a name="habracut"></a><br><h2>  Stop Reflections </h2><br>  The basic idea of ​​collecting WiFi radiation is quite old: you just need to make a circuit that absorbs all microwave energy.  Take an artificial example: imagine a microwave impulse that goes through a piece of coaxial cable.  Coaxial cable consists of a central conductor wire surrounded by a cylinder of non-conductive dielectric, and all this is wrapped in a conductor.  Microwave energy is not transmitted through the central wire.  It is located in electric and magnetic fields in a dielectric.  They propagate along the cable as waves, at a speed depending, in particular, on the properties of the dielectric. <br><br>  When the wave reaches the end of the cable, it has a problem.  Right at the interface between air and dielectric, it needs to instantly go from one speed to another.  If all microwave energy would be transmitted from the end of the cable, then the electric field in the same place would have two different values, but this does not happen.  Therefore, the wave is reflected from the end and returns along the cable (in the process, probably destroying the transmitter). <br><br>  If we do not want energy to be reflected, we need to restrict the cable so that from the microwave point of view the cable looks as if it stretches infinitely.  This concept is called “matching,” and is fundamental to the development of microwave electronics, optics and, in principle, in physics and engineering. <br><br>  In the case of coaxial cable, the dielectric is usually chosen so that a 50 Ohm resistor is consistent with the cable properties.  So if I place a 50 ohm resistor between the outer conductive coating and the center cable, all microwave energy will be absorbed by the resistor. <br><br>  For coaxial cable or any transmission line in general, developing electrical circuits that are consistent with the properties of the line is a simple task.  The antenna in your mobile phone is exactly this scheme: the antenna and its terminal scheme must match each other and correspond as closely as possible to the properties of propagation in space.  Good matching means the ability of a small antenna to absorb a lot of radiation. <br><br><h2>  WiFi loss </h2><br>  The limitations of WiFi are the same as those of receivers.  But his energy does not just go to the receiving antenna, it spreads much more widely.  This means that most of it disappears.  If we placed the correct antennas over the entire area, we would be able to return some of this energy.  But it turns out that this is quite a difficult task. <br><br>  First, such receivers would have to be built into the walls of a house or apartment.  This means that, unlike the antennas on the devices, they cannot be tuned to the optimum reception.  WiFi signals come from all directions, and there can be any polarization (spatial orientation of the electric field with respect to the direction of wave propagation).  Antennas are sensitive to both direction and polarization. <br><br>  Then, the energy is quite smeared.  About 10 mW of energy is radiated near the source.  But if you move 10 meters away, the energy passing through your body will decrease to 10–20 µW.  Losses accumulate.  Distance is a problem, and if your antenna is only configured for one polarization, you will already lose half the energy.  Add all the losses in the circuit that collects energy and converts it into direct current.  It all starts to look very difficult. <br><br><h2>  Build meta antennas </h2><br>  To circumvent such problems, three researchers proposed an antenna network trying to minimize these losses. <br><br>  First you need to eliminate the dependence on polarization.  They approached this by developing a flat antenna that optimally responds to both vertical and horizontal polarization of microwaves.  Although antennas respond to both polarizations, the physical location of the wire connecting the antenna to the rest of the circuit determines which of the polarizations produces energy.  Antennas with wires on the side are sensitive to horizontally polarized light, and antennas with wires on top are sensitive to vertically polarized light [ <i>the author has written light - light.</i>  <i>Perhaps he was mistaken and meant just radio waves / approx.</i>  <i>trans.</i>  ]. <br><br>  I will clarify that the connecting wires can also be considered as antennas with which the receiving flat antenna re-radiates the received energy. <br><br>  To create an energy-collecting device on this principle, the researchers created a grid of antennas.  The odd antenna columns were tuned to receive vertically polarized light, and the even columns were horizontal. <br><br>  It may seem to you that all this is stupid, because with each polarization you lose half the energy.  Not in this case.  All antennas communicate with each other.  A column of antennas with wires on top still accepts both polarizations.  Vertically polarized microwaves are transmitted to wires located on top of each antenna.  Horizontally polarized microwaves are transmitted to antennas in adjacent columns, where they fall into wires located on the side of each antenna.  With the correct scheme, all the energy can be transferred to the converter circuit. <br><br>  So the antenna looks like a lattice of metal plates located on a non-conductive material.  And, like our coaxial cable from the example, the energy collected by the antenna is stored in the fields in the dielectric.  This means that we need a dielectric that absorbs a minimum of energy.  The amount of energy absorbed by a dielectric is often referred to as the loss tangent.  The researchers searched and found the material, with a loss tangent of about 100 times less than those commonly used in printed circuit boards. <br><br><h2>  Do not let reality to my model </h2><br>  In the models, of course, the array of antennas absorbs 100% of the radiation energy of WiFi (more precisely, WiFi 2.4 GHz).  But how does this work in practice?  It's all a bit complicated.  If you measure the energy coming to the connecting wires directly, you can get about 97% of the transmission, which is basically cool. <br><br>  But we want to use this energy, and it is here that everything spoils.  If the wires are directly connected to the load resistance (and turn WiFi energy into heat), everything works well and 92% of the radiation is absorbed by the resistance.  The loss of 5% is due to absorption in the dielectric during the transfer of energy to the resistors. <br><br>  Real losses begin when the microwave energy is converted into a usable DC electrical signal.  Even in models it turns out no more than 80%.  In the experiments, the researchers managed to bring the result to 70%.  I would agree to 70%, but not this time.  The problem is that 70% efficiency is obtained only with a sufficiently high primary signal power.  The researchers tested this signal with energies (and this is the total energy that falls on the antenna array, and not the one that was initially radiated) from 1 to 10 mW.  In the case of 1 mW, the conversion efficiency was 30%.  Linear dependence (on a logarithmic scale) says that if in the real world a transmitter with a power of 100 mW is located 10 m from the antenna, then the antenna will receive energy of the order of microwatts.  And this corresponds to a conversion efficiency of 5%, which is not very good. <br><br>  The researchers claim that the problem lies in the network of energy conversion.  When microwave energy is transferred to where it is being converted into direct current, losses occur.  Even greater losses occur on the diodes.  Diodes allow current to flow in one direction, so a diode network can take an oscillating microwave field, where the voltage changes from negative to positive every few nanoseconds, and produce a positive voltage. <br><br>  But the diodes are not perfect - they need time to switch, they need the applied voltage to reach a certain value before they allow the current to flow.  As a result, a substantial part of the energy of microwaves is not converted, but is lost in the form of heat, since it does not reach the required level. <br><br>  I am sure that this problem of diode work is fundamental, and that, although these losses can be slightly reduced, I do not think that in the near future we will be able to make an order of magnitude more efficient diodes.  On the other hand, I think that the authors could clarify that in fact it is not so important.  Since all the antennas are connected to each other, their lattice can be made larger, and the total amount of received energy will be large enough to achieve peak efficiency. <br><br>  But I'm not sure that will work.  At a distance of 10 m, the antenna array should cover the entire wall of the room.  Unfortunately, then other problems come into force.  Currently, the transfer of energy from individual antennas to the diodes costs us about 5% of the total energy.  But losses are scaled with distance.  In the real world, where antennas extend across the entire wall, distances increase by about 40 times. <br><br>  As a result, the antenna circuit turned out cool.  Its advantage is that it works regardless of orientation relative to the WiFi-transmitter and from interference.  But the antenna has to be connected with imperfect components, and because of this it is very difficult to imagine how to make it work in reality. <br><br><h2>  Give me back my half watt </h2><br>  And if we could do it, would it be worth it?  “Yes,” thinks my brain, preoccupied with energy efficiency, “of course.”  But after a long treatment of the rest of my brain with caffeine, the idea starts to look not so worthwhile. <br><br>  According to the specifications of my base stations, the transmitter energy does not exceed 100–200 mW per channel.  I have one two-channel and one three-channel station, which gives the maximum total power of 800 mW.  According to my bill for electricity goes 0.02 kWh per month.  The energy absorbed by my connected devices can be neglected.  My computer reports a signal strength of -54 dBm, which corresponds to a value slightly less than 4 µW.  Suppose that all the energy transmitted via WiFi is available for capturing. <br><br>  This means that capturing the energy of the microwave radiation emitted by my base stations would save me about two dollars a year.  In other words, I would remove 0.02 kWh from my total monthly consumption bill for electricity, which in winter runs up to 19 kWh. <br><br>  This does not mean that all this is completely in vain.  This idea can be valuable for transmitting wireless energy.  Microwaves can be focused on a rather small area.  With certain calculations, the transmitter can use multipath interference in most situations to efficiently transfer energy to a small target area, leaving the energy density in all other places of the surrounding space relatively low (so that no one has to go through a 100 W beam).  Under such conditions, an extremely flexible and efficient antenna system becomes much simpler to implement.  With acceptable conversion efficiency, most of us will like it. <br><br>  Another use is the creation of improved WiFi networks.  Most of the problems of today's networks come from interference, or multipath interference from your WiFi transmitter, or the struggle for channels from neighbors.  To correct this situation, it would be possible to arrange such antennas (without conversion schemes) in strategic places of the house so that they block some interference.  The advantage over a sheet of aluminum foil they will have is that their effective area is greater than their physical size.  Under certain conditions, several square meters of foil can be replaced with a smaller antenna. <br><br>  Are a couple of such examples enough to start developing such a system?  Not sure.  Nevertheless, I am sure that such a scheme of antennas will necessarily appear in any device. </div>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How to create AI racist without much effort</title>
  <meta name="description" content="Cautionary lesson 

 Let's make a tonality classifier! 

 Tonality analysis (sentiment analysis) is a very common task in natural language processing ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({
      google_ad_client: "ca-pub-6974184241884155",
      enable_page_level_ads: true
    });
  </script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="https://quick-geek.github.io/search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <section class="page js-page"><h1>How to create AI racist without much effort</h1><div class="post__text post__text-html js-mediator-article">  Cautionary lesson <br><br>  <b>Let's make a tonality classifier!</b> <br><br>  Tonality analysis (sentiment analysis) is a very common task in natural language processing (NLP), and this is not surprising.  For business, it is important to understand what opinions people express: positive or negative.  This analysis is used to monitor social networks, customer feedback and even in algorithmic stock trading (as a result, bots <a href="https://www.theatlantic.com/technology/archive/2011/03/does-anne-hathaway-news-drive-berkshire-hathaways-stock/72661/">buy Berkshire Hathaway shares after publishing positive reviews about the role of Anne Hathaway in the last film</a> ). <br><br>  The method of analysis is sometimes too simplified, but it is one of the easiest ways to get measurable results.  Just submit the text - and the output is positive and negative ratings.  No need to deal with the tree of parsing, to build a graph or some other complex representation. <br><a name="habracut"></a><br>  And this will do.  Let's take the path of least resistance and make the simplest classifier, which certainly looks very familiar to all those involved in current developments in the field of NLP.  For example, such a model can be found in the article <i><a href="http://cs.umd.edu/~miyyer/pubs/2015_acl_dan.pdf">Deep Averaging Networks</a></i> (Iyyer et al., 2015).  We are not at all trying to challenge their results or criticize the model;  just give the famous way of representing the words. <br><br>  Work plan: <br><br><ul><li>  Introduce a typical way of <b>representing the words</b> to work with meanings (values). </li><li>  Implement <b>training and test data sets</b> with standard lists of positive and negative words. </li><li>  <b>Train the classifier</b> on gradient descent to recognize other positive and negative words based on their vector representation. </li><li>  Using this classifier, calculate <b>tonality estimates</b> for text sentences. </li><li>  <b>See the monster</b> that we have created. </li></ul><br>  And then we will see "how to create an AI racist without much effort."  Of course, you can not leave the system in such a monstrous form, so then we are going to: <br><br><ul><li>  <b>To evaluate the problem</b> statistically so that it becomes possible to measure progress as it is solved. </li><li>  <b>Improve data</b> to get a more accurate and less racist semantic model. </li></ul><br><h1>  Software dependencies </h1><br>  This tutorial is written in Python and relies on a typical Python machine learning stack: <code>numpy</code> and <code>scipy</code> for numerical calculations, <code>pandas</code> for data management and <code>scikit-learn</code> for machine learning.  At the end, <code>matplotlib</code> and <code>seaborn</code> for charting. <br><br>  In principle, <code>scikit-learn</code> can be replaced by TensorFlow or Keras, or something like that: they can also teach a classifier on a gradient descent.  But we do not need their abstractions, because here the learning takes place in one stage. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> statsmodels.formula.api <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SGDClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> accuracy_score <span class="hljs-comment"><span class="hljs-comment"># –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ %matplotlib inline seaborn.set_context('notebook', rc={'figure.figsize': (10, 6)}, font_scale=1.5)</span></span></code> </pre> <br><h1>  Step 1. Vector word representation </h1><br>  Vector views are often used when textual input is available.  Words become vectors in multidimensional space, where adjacent vectors represent similar meanings.  Using vector representations, you can compare words by (roughly) their meaning, and not only by exact matches. <br><br>  Successful learning requires hundreds of gigabytes of text.  Fortunately, various research teams have already carried out this work and have provided pre-trained models of vector representations that are available for download. <br><br>  The two most well-known data sets for the English language are <b>word2vec</b> (trained in Google News texts) and <b>GloVe</b> (on Common Crawl web pages).  Any of them will give a similar result, but we take the GloVe model, because it has a more transparent data source. <br><br>  GloVe comes in three sizes: 6 billion, 42 billion and 840 billion. The latest model is the most powerful, but requires significant resources for processing.  The 42 billion version is pretty good, and the dictionary is neatly cut to 1 million words.  We are on the path of least resistance, so let's take the 42 billion version. <br><br><blockquote>  <b>- Why is it so important to use a ‚Äúwell-known‚Äù model?</b> <br><br>  - I am glad that you asked about this, hypothetical interlocutor!  At each step, we are trying to do something extremely typical, and for some reason the best model for the vector representation of words has not yet been defined.  I hope this article will cause the desire to use <a href="https://github.com/commonsense/conceptnet-numberbatch">modern high-quality models</a> , especially those that take into account the algorithmic error and try to correct it.  However, more on that later. </blockquote><br>  Download glove.42B.300d.zip from <a href="https://nlp.stanford.edu/projects/glove/">the GloVe website</a> and extract the <code>data/glove.42B.300d.txt</code> .  Next, we define a function for reading vectors in a simple format. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_embeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" –ó–∞–≥—Ä—É–∑–∫–∞ DataFrame –∏–∑ —Ñ–∞–π–ª–∞ –≤ –ø—Ä–æ—Å—Ç–æ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É—é—Ç word2vec, GloVe, fastText –∏ ConceptNet Numberbatch. –ò—Ö –≥–ª–∞–≤–Ω–æ–µ —Ä–∞–∑–ª–∏—á–∏–µ –≤ –Ω–∞–ª–∏—á–∏–∏ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –Ω–∞—á–∞–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏ –º–∞—Ç—Ä–∏—Ü—ã. """</span></span> labels = [] rows = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(infile): items = line.rstrip().split(<span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(items) == <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-comment"><span class="hljs-comment"># This is a header row giving the shape of the matrix continue labels.append(items[0]) values = np.array([float(x) for x in items[1:]], 'f') rows.append(values) arr = np.vstack(rows) return pd.DataFrame(arr, index=labels, dtype='f') embeddings = load_embeddings('data/glove.42B.300d.txt') embeddings.shape</span></span></code> </pre> <br> <code>(1917494, 300)</code> <br> <h1>  Step 2. The gold standard vocabulary dictionary </h1><br>  Now we need information, which words are considered positive, and which are negative.  There are many such dictionaries, but we will take a very simple dictionary (Hu and Liu, 2004), which is used in the article <i>Deep Averaging Networks</i> . <br><br>  We load the dictionary from <a href="https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html">the Bing Liu website</a> and extract the data in <code>data/positive-words.txt</code> and <code>data/negative-words.txt</code> . <br><br>  Next, we define how to read these files, and assign them as the variables <code>pos_words</code> and <code>neg_words</code> : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_lexicon</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª —Å–ª–æ–≤–∞—Ä—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ë–∏–Ω–≥–∞ –õ—é (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html) —Å –∞–Ω–≥–ª–∏–π—Å–∫–∏–º–∏ —Å–ª–æ–≤–∞–º–∏ –≤ –∫–æ–¥–∏—Ä–æ–≤–∫–µ Latin-1. –í –ø–µ—Ä–≤–æ–º —Ñ–∞–π–ª–µ —Å–ø–∏—Å–æ–∫ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤, –∞ –≤ –¥—Ä—É–≥–æ–º - –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö. –í —Ñ–∞–π–ª–∞—Ö –µ—Å—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–¥–µ–ª—è—é—Ç—Å—è —Å–∏–º–≤–æ–ª–æ–º ';' –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–ª–µ–¥—É–µ—Ç –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å. """</span></span> lexicon = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'latin-1'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> infile: line = line.rstrip() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> line.startswith(<span class="hljs-string"><span class="hljs-string">';'</span></span>): lexicon.append(line) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> lexicon pos_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/positive-words.txt'</span></span>) neg_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/negative-words.txt'</span></span>)</code> </pre> <br><h1>  Step 3. We teach the model to predict tonality </h1><br>  Based on the vectors of positive and negative words, we use the Pandas <code>.loc[]</code> command to search for vector representations of all words. <br><br>  Some words are missing in the GloVe dictionary.  Most often these are typos like ‚Äúfancinating‚Äù.  Here we see a bunch of <code>NaN</code> , which indicates the absence of a vector, and delete them with the command <code>.dropna()</code> . <br><br> <code>pos_vectors = embeddings.loc[pos_words].dropna() <br> neg_vectors = embeddings.loc[neg_words].dropna()</code> <br> <br>  Now we create data arrays at the input (vector representations) and output (1 for positive words and -1 for negative).  We also check that vectors are word-bound so that we can interpret the results. <br><br> <code>vectors = pd.concat([pos_vectors, neg_vectors]) <br> targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index]) <br> labels = list(pos_vectors.index) + list(neg_vectors.index)</code> <br> <br><blockquote>  <b>- Wait a minute.</b>  <b>Some words are neither positive nor negative, they are neutral.</b>  <b>Shouldn't you create a third class for neutral words?</b> <br><br>  - I think that he would come in handy.  Later we will see what problems arise from the assignment of tonality to neutral words.  If we can reliably determine neutral words, then it is quite possible to increase the complexity of the classifier to three digits.  But you need to find a dictionary of neutral words, because Liu has only positive and negative vocabulary. <br><br>  So I tried my version with 800 examples of words and increased the weight to predict neutral words.  But the end results were not very different from what you now see. <br><br>  <b>- How does this list distinguish between positive and negative words?</b>  <b>Is it not context sensitive?</b> <br><br>  - Good question.  The analysis of common tonalities is not as simple as it seems.  The border is rather arbitrary in some places.  In this list, the word ‚Äúimpudent‚Äù is marked as ‚Äúbad,‚Äù and ‚Äúambitious‚Äù as ‚Äúgood.‚Äù  ‚ÄúComical‚Äù is bad, and ‚Äúfunny‚Äù is good.  ‚ÄúRefund‚Äù is good, although it is usually mentioned in a bad context, when you owe someone money or someone owes you. <br><br>  Everyone understands that the tonality is determined by the context, but in a simple model one has to ignore the context and hope that the average tonality will be guessed correctly. </blockquote><br>  Using the <code>train_test_split</code> function, <code>train_test_split</code> simultaneously divide input vectors, output values ‚Äã‚Äãand labels into training and test data, while leaving 10% for testing. <br><br><pre> <code class="python hljs">train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Now we create a classifier and pass vectors through it in 100 iterations.  We use the logistic loss function so that the final classifier can infer the probability that the word is positive or negative. <br><br><pre> <code class="python hljs">model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) SGDClassifier(alpha=<span class="hljs-number"><span class="hljs-number">0.0001</span></span>, average=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, class_weight=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, epsilon=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, eta0=<span class="hljs-number"><span class="hljs-number">0.0</span></span>, fit_intercept=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, l1_ratio=<span class="hljs-number"><span class="hljs-number">0.15</span></span>, learning_rate=<span class="hljs-string"><span class="hljs-string">'optimal'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_jobs=<span class="hljs-number"><span class="hljs-number">1</span></span>, penalty=<span class="hljs-string"><span class="hljs-string">'l2'</span></span>, power_t=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, warm_start=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  We evaluate the classifier on test vectors.  It demonstrates 95% accuracy.  Not bad. <br><br> <code>accuracy_score(model.predict(test_vectors), test_targets) <br> 0.95022624434389136</code> <br> <br>  We define the tonality prediction function for certain words, and then use it with some examples from test data. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vecs_to_sentiment</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(vecs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># predict_log_proba –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç log-–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ predictions = model.predict_log_proba(vecs) # –î–ª—è —Å–≤–µ–¥–µ–Ω–∏—è –≤–æ–µ–¥–∏–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ # –≤—ã—á–∏—Ç–∞–µ–º log-–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π. return predictions[:, 1] - predictions[:, 0] def words_to_sentiment(words): vecs = embeddings.loc[words].dropna() log_odds = vecs_to_sentiment(vecs) return pd.DataFrame({'sentiment': log_odds}, index=vecs.index) # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º 20 –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö words_to_sentiment(test_labels).ix[:20]</span></span></code> </pre> <br><table border="1" width="350"><thead><tr><th></th><th>  key </th></tr></thead><tbody><tr><th>  fidget </th><td>  -9.931679 </td></tr><tr><th>  interrupt </th><td>  -9.634706 </td></tr><tr><th>  bravely </th><td>  1.466919 </td></tr><tr><th>  imaginary </th><td>  -2.989215 </td></tr><tr><th>  taxation </th><td>  0.468522 </td></tr><tr><th>  world famous </th><td>  6.908561 </td></tr><tr><th>  inexpensive </th><td>  9.237223 </td></tr><tr><th>  disappointment </th><td>  -8.737182 </td></tr><tr><th>  totalitarian </th><td>  -10.851580 </td></tr><tr><th>  warlike </th><td>  -8.328674 </td></tr><tr><th>  freezes </th><td>  -8.456981 </td></tr><tr><th>  sin </th><td>  -7.839670 </td></tr><tr><th>  fragile </th><td>  -4.018289 </td></tr><tr><th>  fooled </th><td>  -4.309344 </td></tr><tr><th>  unsolved </th><td>  -2.816172 </td></tr><tr><th>  cleverly </th><td>  2.339609 </td></tr><tr><th>  demonizes </th><td>  -2.102152 </td></tr><tr><th>  carefree </th><td>  8.747150 </td></tr><tr><th>  unpopular </th><td>  -7.887475 </td></tr><tr><th>  to sympathize </th><td>  1.790899 </td></tr></tbody></table><br>  It can be seen that the classifier works.  He learned to generalize tonality in words outside the training data. <br><br><h1>  Step 4. Get the tonality estimate for the text. </h1><br>  There are many ways to add a vector to the overall score.  Again, we follow the path of least resistance, so we just take the average value. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re TOKEN_RE = re.compile(<span class="hljs-string"><span class="hljs-string">r"\w.*?\b"</span></span>) <span class="hljs-comment"><span class="hljs-comment"># regex –Ω–∞—Ö–æ–¥–∏—Ç –æ–±—ä–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å –±—É–∫–≤—ã (\w) –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç # —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Å–∏–º–≤–æ–ª—ã (.+?) –¥–æ –æ–∫–æ–Ω—á–∞–Ω–∏—è —Å–ª–æ–≤–∞ (\b). –≠—Ç–æ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ # –ø—Ä–æ—Å—Ç–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞. def text_to_sentiment(text): tokens = [token.casefold() for token in TOKEN_RE.findall(text)] sentiments = words_to_sentiment(tokens) return sentiments['sentiment'].mean()</span></span></code> </pre> <br>  Here a lot of things suggest optimization: <br><br><ul><li>  The introduction of the inverse relationship between the weight of the word and its frequency, so that the same prepositions do not strongly influence the tonality. </li><li>  Setting that short sentences do not end with extreme values ‚Äã‚Äãof tonality. </li><li>  Phrase counting. </li><li>  A more robust word segmentation algorithm that apostrophes do not bring down. </li><li>  Consideration of negatives like ‚Äúnot satisfied‚Äù. </li></ul><br>  But everything requires additional code and does not fundamentally change the results.  At least, now you can roughly compare different sentences: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is pretty cool"</span></span>) <span class="hljs-number"><span class="hljs-number">3.889968926086298</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is okay"</span></span>) <span class="hljs-number"><span class="hljs-number">2.7997773492425186</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"meh, this example sucks"</span></span>) <span class="hljs-number"><span class="hljs-number">-1.1774475917460698</span></span></code> </pre> <br><h1>  Step 5. Behold the monster we created </h1><br>  Not every sentence is clearly toned.  Let's see what happens with neutral sentences: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Italian food"</span></span>) <span class="hljs-number"><span class="hljs-number">2.0429166109408983</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Chinese food"</span></span>) <span class="hljs-number"><span class="hljs-number">1.4094033658140972</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Mexican food"</span></span>) <span class="hljs-number"><span class="hljs-number">0.38801985560121732</span></span></code> </pre> <br>  I have already met such a phenomenon when analyzing reviews of restaurants, taking into account the vector representations of words.  For no apparent reason <a href="http://blog.conceptnet.io/2017/04/24/conceptnet-numberbatch-17-04-better-less-stereotyped-word-vectors/">, all Mexican restaurants had a lower grade</a> . <br><br>  Vector representations capture subtle sense differences in context.  Therefore, they reflect the prejudices of our society. <br><br>  Here are some other neutral suggestions: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Emily"</span></span>) <span class="hljs-number"><span class="hljs-number">2.2286179364745311</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Heather"</span></span>) <span class="hljs-number"><span class="hljs-number">1.3976291151079159</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Yvette"</span></span>) <span class="hljs-number"><span class="hljs-number">0.98463802132985556</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Shaniqua"</span></span>) <span class="hljs-number"><span class="hljs-number">-0.47048131775890656</span></span></code> </pre> <br>  Well damn‚Ä¶ <br><br>  The system associated with the names of people completely different feelings.  You can look at these and many other examples and see that tonality is usually higher for stereotypically white names and lower for stereotypically black names. <br><br>  This test was used by Kaliskan, Bryson and Narayanan in his scientific work published in the journal <i>Science</i> in April 2017.  It proves that the <a href="http://opus.bath.ac.uk/55288/">semantics of the language corpus contains social prejudices</a> .  We will use this method. <br><br><h1>  Step 6. Assessing the problem </h1><br>  We want to understand how to avoid such mistakes.  Let's skip more data through the classifier and statistically measure its ‚Äúbias‚Äù. <br><br>  Here we have four lists of names that reflect different ethnic origins, mainly in the United States.  The first two are lists of predominantly ‚Äúwhite‚Äù and ‚Äúblack‚Äù names, adapted on the basis of an article by Kaliskana et al. I also added Spanish and Muslim names from Arabic and Urdu. <br><br>  This data is used to test the bias of the algorithm during the ConceptNet build process: it can be found in the <code>conceptnet5.vectors.evaluation.bias</code> module.  There is an idea to expand the dictionary to other ethnic groups, taking into account not only names, but also surnames. <br><br>  Here are the listings: <br><br><pre> <code class="python hljs">NAMES_BY_ETHNICITY = { <span class="hljs-comment"><span class="hljs-comment"># –ü–µ—Ä–≤—ã–µ –¥–≤–∞ —Å–ø–∏—Å–∫–∞ –∏–∑ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∫ –Ω–∞—É—á–Ω–æ–π —Å—Ç–∞—Ç—å–µ –ö–∞–ª–∏—Å–∫–∞–Ω–∞ –∏ –¥—Ä. 'White': [ 'Adam', 'Chip', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Ian', 'Justin', 'Ryan', 'Andrew', 'Fred', 'Jack', 'Matthew', 'Stephen', 'Brad', 'Greg', 'Jed', 'Paul', 'Todd', 'Brandon', 'Hank', 'Jonathan', 'Peter', 'Wilbur', 'Amanda', 'Courtney', 'Heather', 'Melanie', 'Sara', 'Amber', 'Crystal', 'Katie', 'Meredith', 'Shannon', 'Betsy', 'Donna', 'Kristin', 'Nancy', 'Stephanie', 'Bobbie-Sue', 'Ellen', 'Lauren', 'Peggy', 'Sue-Ellen', 'Colleen', 'Emily', 'Megan', 'Rachel', 'Wendy' ], 'Black': [ 'Alonzo', 'Jamel', 'Lerone', 'Percell', 'Theo', 'Alphonse', 'Jerome', 'Leroy', 'Rasaan', 'Torrance', 'Darnell', 'Lamar', 'Lionel', 'Rashaun', 'Tyree', 'Deion', 'Lamont', 'Malik', 'Terrence', 'Tyrone', 'Everol', 'Lavon', 'Marcellus', 'Terryl', 'Wardell', 'Aiesha', 'Lashelle', 'Nichelle', 'Shereen', 'Temeka', 'Ebony', 'Latisha', 'Shaniqua', 'Tameisha', 'Teretha', 'Jasmine', 'Latonya', 'Shanise', 'Tanisha', 'Tia', 'Lakisha', 'Latoya', 'Sharise', 'Tashika', 'Yolanda', 'Lashandra', 'Malika', 'Shavonn', 'Tawanda', 'Yvette' ], # –°–ø–∏—Å–æ–∫ –∏—Å–ø–∞–Ω—Å–∫–∏—Ö –∏–º—ë–Ω —Å–æ—Å—Ç–∞–≤–ª–µ–Ω –ø–æ –¥–∞–Ω–Ω—ã–º –ø–µ—Ä–µ–ø–∏—Å–∏ –Ω–∞—Å–µ–ª–µ–Ω–∏—è –°–®–ê. 'Hispanic': [ 'Juan', 'Jos√©', 'Miguel', 'Lu√≠s', 'Jorge', 'Santiago', 'Mat√≠as', 'Sebasti√°n', 'Mateo', 'Nicol√°s', 'Alejandro', 'Samuel', 'Diego', 'Daniel', 'Tom√°s', 'Juana', 'Ana', 'Luisa', 'Mar√≠a', 'Elena', 'Sof√≠a', 'Isabella', 'Valentina', 'Camila', 'Valeria', 'Ximena', 'Luciana', 'Mariana', 'Victoria', 'Martina' ], # –°–ª–µ–¥—É—é—â–∏–π —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–ª–∏–≥–∏—é –∏ —ç—Ç–Ω–∏—á–µ—Å–∫—É—é # –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å, —è –≤ –∫—É—Ä—Å–µ. –¢–∞–∫–∂–µ –∫–∞–∫ –∏ —Å–∞–º–∏ –∏–º–µ–Ω–∞. # # –û–Ω —Å–æ—Å—Ç–∞–≤–ª–µ–Ω –ø–æ –¥–∞–Ω–Ω—ã–º —Å–∞–π—Ç–æ–≤ —Å –∏–º–µ–Ω–∞–º–∏ –¥–µ—Ç–µ–π –¥–ª—è # —Ä–æ–¥–∏—Ç–µ–ª–µ–π-–º—É—Å—É–ª—å–º–∞–Ω –≤ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –Ω–∞–ø–∏—Å–∞–Ω–∏–∏. –Ø –Ω–µ –ø—Ä–æ–≤–æ–¥–∏–ª # –≥—Ä–∞–Ω–∏ –º–µ–∂–¥—É –∞—Ä–∞–±—Å–∫–∏–º, —É—Ä–¥—É –∏ –¥—Ä—É–≥–∏–º–∏ —è–∑—ã–∫–∞–º–∏. # # –ë—É–¥—É —Ä–∞–¥ –æ–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –±–æ–ª–µ–µ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏. 'Arab/Muslim': [ 'Mohammed', 'Omar', 'Ahmed', 'Ali', 'Youssef', 'Abdullah', 'Yasin', 'Hamza', 'Ayaan', 'Syed', 'Rishaan', 'Samar', 'Ahmad', 'Zikri', 'Rayyan', 'Mariam', 'Jana', 'Malak', 'Salma', 'Nour', 'Lian', 'Fatima', 'Ayesha', 'Zahra', 'Sana', 'Zara', 'Alya', 'Shaista', 'Zoya', 'Yasmin' ] }</span></span></code> </pre> <br>  With the help of Pandas we will compile a table of names, their predominant ethnic origin and assessment of tonality: <br><br><pre> <code class="plaintext hljs">def name_sentiment_table(): frames = [] for group, name_list in sorted(NAMES_BY_ETHNICITY.items()): lower_names = [name.lower() for name in name_list] sentiments = words_to_sentiment(lower_names) sentiments['group'] = group frames.append(sentiments) # –°–≤–æ–¥–∏–º –¥–∞–Ω–Ω—ã–µ —Å–æ –≤—Å–µ—Ö —ç—Ç–Ω–∏—á–µ—Å–∫–∏—Ö –≥—Ä—É–ø–ø –≤ –æ–¥–Ω—É –±–æ–ª—å—à—É—é —Ç–∞–±–ª–∏—Ü—É return pd.concat(frames) name_sentiments = name_sentiment_table()</code> </pre> <br>  Sample data: <br><br> <code>name_sentiments.ix[::25]</code> <br> <table border="1" width="350"><thead><tr><th></th><th>  key </th><th>  Group </th></tr></thead><tbody><tr><th>  mohammed </th><td>  0.834974 </td><td>  Arab / Muslim </td></tr><tr><th>  alya </th><td>  3.916803 </td><td>  Arab / Muslim </td></tr><tr><th>  terryl </th><td>  -2.858010 </td><td>  Black </td></tr><tr><th>  jos√© </th><td>  0.432956 </td><td>  Hispanic </td></tr><tr><th>  luciana </th><td>  1.086073 </td><td>  Hispanic </td></tr><tr><th>  hank </th><td>  0.391858 </td><td>  White </td></tr><tr><th>  megan </th><td>  2.158679 </td><td>  White </td></tr></tbody></table><br>  Make a graph of the distribution of tonality for each name. <br><br><pre> <code class="python hljs">plot = seaborn.swarmplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments) plot.set_ylim([<span class="hljs-number"><span class="hljs-number">-10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>])</code> </pre> <br> <code>(-10, 10)</code> <br> <br><img src="https://habrastorage.org/webt/qv/y7/ge/qvy7gel8rrvm5txo-nou6g0i0re.png"><br><br>  Or in the form of a histogram with confidence intervals for averages of 95%. <br><br><pre> <code class="python hljs">plot = seaborn.barplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments, capsize=<span class="hljs-number"><span class="hljs-number">.1</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/uv/ib/n6/uvibn6olthaxt6cxbd96szehq94.png"><br><br>  Finally, run the <a href="http://www.statsmodels.org/stable/index.html">statsmodels</a> serious statistical package.  It will show how great the bias of the algorithm is (along with a bunch of other statistics). <br><br><br>  <font color="gray">OLS Regression Results</font> <br><table><tbody><tr><th>  Dep.  Variable: </th><td>  sentiment </td><th>  R-squared: </th><td>  0.208 </td></tr><tr><th>  Model: </th><td>  Ols </td><th>  Adj.  R-squared: </th><td>  0.192 </td></tr><tr><th>  Method: </th><td>  Least squares </td><th>  F-statistic: </th><td>  13.04 </td></tr><tr><th>  Date: </th><td>  Thu, 13 Jul 2017 </td><th>  Prob (F-statistic): </th><td>  1.31e-07 </td></tr><tr><th>  Time: </th><td>  11:31:17 </td><th>  Log-Likelihood: </th><td>  -356.78 </td></tr><tr><th>  No.  Observations: </th><td>  153 </td><th>  AIC: </th><td>  721.6 </td></tr><tr><th>  Df Residuals: </th><td>  149 </td><th>  BIC: </th><td>  733.7 </td></tr><tr><th>  Df Model: </th><td>  3 </td><th></th><td></td></tr><tr><th>  Covariance Type: </th><td>  nonrobust </td><th></th><td></td></tr></tbody></table><br>  F-statistic is the ratio of variation between groups to variation within groups, which can be taken as a general assessment of bias. <br><br>  Immediately below it is the probability that we will see the maximum F-statistic with a null hypothesis: that is, if there is no difference between the compared options.  The probability is very, very low.  In a scientific article, we would call the result ‚Äúvery statistically significant.‚Äù <br><br>  We need to improve the f-value.  The lower the better. <br><br> <code>ols_model.fvalue <br> 13.041597745167659</code> <br> <br><h1>  Step 7. Try other data. </h1><br>  Now we have the opportunity to numerically measure the harmful bias of the model.  Let's try to correct it.  To do this, you need to repeat a bunch of things that used to be just separate steps in a Python notepad. <br><br>  If I wrote good, supported code, I would not use global variables, such as <code>model</code> and <code>embeddings</code> .  But the current spaghetti code allows you to better examine each step and understand what is happening.  We reuse part of the code and at least define a function to repeat some steps: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">retrain_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(new_embs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" –ü–æ–≤—Ç–æ—Ä—è–µ–º —à–∞–≥–∏ —Å –Ω–æ–≤—ã–º –Ω–∞–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö. """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> model, embeddings, name_sentiments embeddings = new_embs pos_vectors = embeddings.loc[pos_words].dropna() neg_vectors = embeddings.loc[neg_words].dropna() vectors = pd.concat([pos_vectors, neg_vectors]) targets = np.array([<span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> pos_vectors.index] + [<span class="hljs-number"><span class="hljs-number">-1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> neg_vectors.index]) labels = list(pos_vectors.index) + list(neg_vectors.index) train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>) model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) accuracy = accuracy_score(model.predict(test_vectors), test_targets) print(<span class="hljs-string"><span class="hljs-string">"Accuracy of sentiment: {:.2%}"</span></span>.format(accuracy)) name_sentiments = name_sentiment_table() ols_model = statsmodels.formula.api.ols(<span class="hljs-string"><span class="hljs-string">'sentiment ~ group'</span></span>, data=name_sentiments).fit() print(<span class="hljs-string"><span class="hljs-string">"F-value of bias: {:.3f}"</span></span>.format(ols_model.fvalue)) print(<span class="hljs-string"><span class="hljs-string">"Probability given null hypothesis: {:.3}"</span></span>.format(ols_model.f_pvalue)) <span class="hljs-comment"><span class="hljs-comment"># –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –≥—Ä–∞—Ñ–∏–∫ —Å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–π –æ—Å—å—é Y plot = seaborn.swarmplot(x='group', y='sentiment', data=name_sentiments) plot.set_ylim([-10, 10])</span></span></code> </pre> <br><h3>  We try word2vec </h3><br>  It can be assumed that only GloVe has a problem.  Probably, in the Common Crawl base there are a lot of doubtful sites and at least 20 copies of the Urban Dictionary street slang dictionary.  It may be better on another base: how about the good old word2vec, trained on Google News? <br><br>  It seems the most authoritative source for word2vec data is <a href="https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit%3Fusp%3Dsharing">this file on Google Drive</a> .  Download it and save as <code>data/word2vec-googlenews-300.bin.gz</code> . <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é ConceptNet –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ word2vec –≤–æ —Ñ—Ä–µ–π–º Pandas –∏–∑ –µ–≥–æ –±–∏–Ω–∞—Ä–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ from conceptnet5.vectors.formats import load_word2vec_bin w2v = load_word2vec_bin('data/word2vec-googlenews-300.bin.gz', nrows=2000000) # –ú–æ–¥–µ–ª—å word2vec —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –∫ —Ä–µ–≥–∏—Å—Ç—Ä—É w2v.index = [label.casefold() for label in w2v.index] # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∂–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è w2v = w2v.reset_index().drop_duplicates(subset='index', keep='first').set_index('index') retrain_model(w2v)</span></span></code> </pre> <br> <code>Accuracy of sentiment: 94.30% <br> F-value of bias: 15.573 <br> Probability given null hypothesis: 7.43e-09</code> <br> <br>  So word2vec was even worse with an F-value of more than 15. <br><br>  In principle, it was foolish to expect the <i>news to</i> be better protected from bias. <br><br><h3>  We try ConceptNet Numberbatch </h3><br>  Finally, I can talk about my own project on the vector representation of words. <br><br>  ConceptNet with the function of vector representations is the knowledge graph I work on.  It normalizes vector representations at the training stage, identifying and removing some sources of algorithmic racism and sexism.  This method of correcting bias is based on the scientific article by Bulukbasi et al. <a href="https://arxiv.org/abs/1607.06520">‚ÄúDebiasing Word Embeddings‚Äù</a> and is generalized to eliminate several types of bias simultaneously.  As far as I know, this is the only semantic system in which there is something similar. <br><br>  From time to time, we export precomputed vectors from ConceptNet ‚Äî these releases are called <a href="https://github.com/commonsense/conceptnet-numberbatch">ConceptNet Numberbatch</a> .  In April 2017, the first release came out with a bias correction, so we‚Äôll load the English-speaking vectors and retrain our model. <br><br>  <code><a href="">numberbatch-en-17.04b.txt.gz</a></code> , save in the <code>data/</code> directory and retrain the model: <br><br><pre> <code class="python hljs">retrain_model(load_embeddings(<span class="hljs-string"><span class="hljs-string">'data/numberbatch-en-17.04b.txt'</span></span>))</code> </pre> <br> <code>Accuracy of sentiment: 97.46% <br> F-value of bias: 3.805 <br> Probability given null hypothesis: 0.0118</code> <br> <br><img src="https://habrastorage.org/webt/5d/iu/uq/5diuuqrst8bca5-m7fljox--pro.png"><br><br>  So did ConceptNet Numberbatch completely eliminate the problem?  No more algorithmic racism?  <b>Not.</b> <br><br>  Racism has become much less?  <b>Definitely</b> . <br><br>  The tonality ranges for ethnic groups overlap much more than in the GloVe or word2vec vectors.  Compared to GloVe, the value of F decreased more than three times, and compared to word2vec - more than four times.  And in general, we see much smaller differences in tonality when comparing different names: this should be so, because names really should not affect the result of the analysis. <br><br>  But a slight correlation still remained.  Perhaps I can pick up such data and training parameters that the problem seems solved.  But it will be a bad option, because <i>in fact the</i> problem remains, because in ConceptNet we have identified and compensated not all the causes of algorithmic racism.  But this is a good start. <br><br><h3>  No pitfalls </h3><br>  Note that with the transition to ConceptNet Numberbatch, the accuracy of tonality prediction has improved. <br><br>  Some might have suggested that the correction of algorithmic racism would worsen the results in some other way.  But no.  You may have data that is better and less racist. –î–∞–Ω–Ω—ã–µ —Ä–µ–∞–ª—å–Ω–æ —É–ª—É—á—à–∞—é—Ç—Å—è —Å —ç—Ç–æ–π –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π. –ü—Ä–∏–æ–±—Ä–µ—Ç—ë–Ω–Ω—ã–π –æ—Ç –ª—é–¥–µ–π —Ä–∞—Å–∏–∑–º word2vec –∏ GloVe –Ω–µ –∏–º–µ–µ—Ç –Ω–∏–∫–∞–∫–æ–≥–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç—ã –∞–ª–≥–æ—Ä–∏—Ç–º–∞. <br><br><h1> –î—Ä—É–≥–∏–µ –ø–æ–¥—Ö–æ–¥—ã </h1><br> –ö–æ–Ω–µ—á–Ω–æ, —ç—Ç–æ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å–ø–æ—Å–æ–± –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏. –ö–∞–∫–∏–µ-—Ç–æ –¥–µ—Ç–∞–ª–∏ –º–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏–Ω–∞—á–µ. <br><br> –í–º–µ—Å—Ç–æ –∏–ª–∏ –≤ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫ —Å–º–µ–Ω–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –º–æ–∂–Ω–æ –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è —É—Å—Ç—Ä–∞–Ω–∏—Ç—å —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –≤ –≤—ã–¥–∞—á–µ. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤–æ–æ–±—â–µ —É—Å—Ç—Ä–∞–Ω–∏—Ç—å –æ—Ü–µ–Ω–∫—É —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –∏–º—ë–Ω –∏ –≥—Ä—É–ø–ø –ª—é–¥–µ–π. <br><br> –ï—Å—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç –≤–æ–æ–±—â–µ –æ—Ç–∫–∞–∑–∞—Ç—å—Å—è –æ—Ç —Ä–∞—Å—á—ë—Ç–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö —Å–ª–æ–≤, –∞ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—Ç—å –µ—ë —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–ª–æ–≤ –∏–∑ —Å–ø–∏—Å–∫–∞. –ü–æ–∂–∞–ª—É–π, —ç—Ç–æ —Å–∞–º–∞—è —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ ‚Äî –≤–æ–æ–±—â–µ –±–µ–∑ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –±—É–¥–µ—Ç –Ω–µ –±–æ–ª—å—à–µ –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏, —á–µ–º —É –∞–≤—Ç–æ—Ä–∞ —Å–ø–∏—Å–∫–∞. –ù–æ –æ—Ç–∫–∞–∑ –æ—Ç –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –æ–∑–Ω–∞—á–∞–µ—Ç —É–º–µ–Ω—å—à–µ–Ω–∏–µ –ø–æ–ª–Ω–æ—Ç—ã (recall), –∞ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –∫ –Ω–∞–±–æ—Ä—É –¥–∞–Ω–Ω—ã—Ö ‚Äî –≤—Ä—É—á–Ω—É—é –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫. <br><br> –í –∫–∞—á–µ—Å—Ç–≤–µ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ –≤—ã –º–æ–∂–µ—Ç–µ —Å–æ–∑–¥–∞—Ç—å –±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã—Ö –æ—Ü–µ–Ω–æ–∫ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–ª–æ–≤ –∏ –ø–æ—Ä—É—á–∏—Ç—å —á–µ–ª–æ–≤–µ–∫—É —Ç–µ—Ä–ø–µ–ª–∏–≤–æ –∏—Ö –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å, —Å–æ—Å—Ç–∞–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤-–∏—Å–∫–ª—é—á–µ–Ω–∏–π —Å –Ω—É–ª–µ–≤–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é. –ù–æ —ç—Ç–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞. –° –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, –≤—ã –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —É–≤–∏–¥–∏—Ç–µ, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –º–æ–¥–µ–ª—å. –î—É–º–∞—é, –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ –∫ —ç—Ç–æ–º—É —Å–ª–µ–¥—É–µ—Ç —Å—Ç—Ä–µ–º–∏—Ç—å—Å—è. </div><p>Source: <a href="https://habr.com/ru/post/436506/">https://habr.com/ru/post/436506/</a></p>
<section class="navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container">Waiting for the list from <a href="../../index.html">here</a>...</nav>
</section>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52319614 = new Ya.Metrika({
                  id:52319614,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52319614" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>
</body>

</html>
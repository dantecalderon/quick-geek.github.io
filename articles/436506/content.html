<div class="post__text post__text-html js-mediator-article">  Cautionary lesson <br><br>  <b>Let's make a tonality classifier!</b> <br><br>  Tonality analysis (sentiment analysis) is a very common task in natural language processing (NLP), and this is not surprising.  For business, it is important to understand what opinions people express: positive or negative.  This analysis is used to monitor social networks, customer feedback and even in algorithmic stock trading (as a result, bots <a href="https://www.theatlantic.com/technology/archive/2011/03/does-anne-hathaway-news-drive-berkshire-hathaways-stock/72661/">buy Berkshire Hathaway shares after publishing positive reviews about the role of Anne Hathaway in the last film</a> ). <br><br>  The method of analysis is sometimes too simplified, but it is one of the easiest ways to get measurable results.  Just submit the text - and the output is positive and negative ratings.  No need to deal with the tree of parsing, to build a graph or some other complex representation. <br><a name="habracut"></a><br>  And this will do.  Let's take the path of least resistance and make the simplest classifier, which certainly looks very familiar to all those involved in current developments in the field of NLP.  For example, such a model can be found in the article <i><a href="http://cs.umd.edu/~miyyer/pubs/2015_acl_dan.pdf">Deep Averaging Networks</a></i> (Iyyer et al., 2015).  We are not at all trying to challenge their results or criticize the model;  just give the famous way of representing the words. <br><br>  Work plan: <br><br><ul><li>  Introduce a typical way of <b>representing the words</b> to work with meanings (values). </li><li>  Implement <b>training and test data sets</b> with standard lists of positive and negative words. </li><li>  <b>Train the classifier</b> on gradient descent to recognize other positive and negative words based on their vector representation. </li><li>  Using this classifier, calculate <b>tonality estimates</b> for text sentences. </li><li>  <b>See the monster</b> that we have created. </li></ul><br>  And then we will see "how to create an AI racist without much effort."  Of course, you can not leave the system in such a monstrous form, so then we are going to: <br><br><ul><li>  <b>To evaluate the problem</b> statistically so that it becomes possible to measure progress as it is solved. </li><li>  <b>Improve data</b> to get a more accurate and less racist semantic model. </li></ul><br><h1>  Software dependencies </h1><br>  This tutorial is written in Python and relies on a typical Python machine learning stack: <code>numpy</code> and <code>scipy</code> for numerical calculations, <code>pandas</code> for data management and <code>scikit-learn</code> for machine learning.  At the end, <code>matplotlib</code> and <code>seaborn</code> for charting. <br><br>  In principle, <code>scikit-learn</code> can be replaced by TensorFlow or Keras, or something like that: they can also teach a classifier on a gradient descent.  But we do not need their abstractions, because here the learning takes place in one stage. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> statsmodels.formula.api <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SGDClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> accuracy_score <span class="hljs-comment"><span class="hljs-comment"># Конфигурация для отображения графиков %matplotlib inline seaborn.set_context('notebook', rc={'figure.figsize': (10, 6)}, font_scale=1.5)</span></span></code> </pre> <br><h1>  Step 1. Vector word representation </h1><br>  Vector views are often used when textual input is available.  Words become vectors in multidimensional space, where adjacent vectors represent similar meanings.  Using vector representations, you can compare words by (roughly) their meaning, and not only by exact matches. <br><br>  Successful learning requires hundreds of gigabytes of text.  Fortunately, various research teams have already carried out this work and have provided pre-trained models of vector representations that are available for download. <br><br>  The two most well-known data sets for the English language are <b>word2vec</b> (trained in Google News texts) and <b>GloVe</b> (on Common Crawl web pages).  Any of them will give a similar result, but we take the GloVe model, because it has a more transparent data source. <br><br>  GloVe comes in three sizes: 6 billion, 42 billion and 840 billion. The latest model is the most powerful, but requires significant resources for processing.  The 42 billion version is pretty good, and the dictionary is neatly cut to 1 million words.  We are on the path of least resistance, so let's take the 42 billion version. <br><br><blockquote>  <b>- Why is it so important to use a “well-known” model?</b> <br><br>  - I am glad that you asked about this, hypothetical interlocutor!  At each step, we are trying to do something extremely typical, and for some reason the best model for the vector representation of words has not yet been defined.  I hope this article will cause the desire to use <a href="https://github.com/commonsense/conceptnet-numberbatch">modern high-quality models</a> , especially those that take into account the algorithmic error and try to correct it.  However, more on that later. </blockquote><br>  Download glove.42B.300d.zip from <a href="https://nlp.stanford.edu/projects/glove/">the GloVe website</a> and extract the <code>data/glove.42B.300d.txt</code> .  Next, we define a function for reading vectors in a simple format. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_embeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Загрузка DataFrame из файла в простом текстовом формате, который используют word2vec, GloVe, fastText и ConceptNet Numberbatch. Их главное различие в наличии или отсутствии начальной строки с размерами матрицы. """</span></span> labels = [] rows = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(infile): items = line.rstrip().split(<span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(items) == <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-comment"><span class="hljs-comment"># This is a header row giving the shape of the matrix continue labels.append(items[0]) values = np.array([float(x) for x in items[1:]], 'f') rows.append(values) arr = np.vstack(rows) return pd.DataFrame(arr, index=labels, dtype='f') embeddings = load_embeddings('data/glove.42B.300d.txt') embeddings.shape</span></span></code> </pre> <br> <code>(1917494, 300)</code> <br> <h1>  Step 2. The gold standard vocabulary dictionary </h1><br>  Now we need information, which words are considered positive, and which are negative.  There are many such dictionaries, but we will take a very simple dictionary (Hu and Liu, 2004), which is used in the article <i>Deep Averaging Networks</i> . <br><br>  We load the dictionary from <a href="https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html">the Bing Liu website</a> and extract the data in <code>data/positive-words.txt</code> and <code>data/negative-words.txt</code> . <br><br>  Next, we define how to read these files, and assign them as the variables <code>pos_words</code> and <code>neg_words</code> : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_lexicon</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Загружаем файл словаря тональности Бинга Лю (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html) с английскими словами в кодировке Latin-1. В первом файле список положительных слов, а в другом - отрицательных. В файлах есть комментарии, которые выделяются символом ';' и пустые строки, которые следует пропустить. """</span></span> lexicon = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'latin-1'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> infile: line = line.rstrip() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> line.startswith(<span class="hljs-string"><span class="hljs-string">';'</span></span>): lexicon.append(line) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> lexicon pos_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/positive-words.txt'</span></span>) neg_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/negative-words.txt'</span></span>)</code> </pre> <br><h1>  Step 3. We teach the model to predict tonality </h1><br>  Based on the vectors of positive and negative words, we use the Pandas <code>.loc[]</code> command to search for vector representations of all words. <br><br>  Some words are missing in the GloVe dictionary.  Most often these are typos like “fancinating”.  Here we see a bunch of <code>NaN</code> , which indicates the absence of a vector, and delete them with the command <code>.dropna()</code> . <br><br> <code>pos_vectors = embeddings.loc[pos_words].dropna() <br> neg_vectors = embeddings.loc[neg_words].dropna()</code> <br> <br>  Now we create data arrays at the input (vector representations) and output (1 for positive words and -1 for negative).  We also check that vectors are word-bound so that we can interpret the results. <br><br> <code>vectors = pd.concat([pos_vectors, neg_vectors]) <br> targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index]) <br> labels = list(pos_vectors.index) + list(neg_vectors.index)</code> <br> <br><blockquote>  <b>- Wait a minute.</b>  <b>Some words are neither positive nor negative, they are neutral.</b>  <b>Shouldn't you create a third class for neutral words?</b> <br><br>  - I think that he would come in handy.  Later we will see what problems arise from the assignment of tonality to neutral words.  If we can reliably determine neutral words, then it is quite possible to increase the complexity of the classifier to three digits.  But you need to find a dictionary of neutral words, because Liu has only positive and negative vocabulary. <br><br>  So I tried my version with 800 examples of words and increased the weight to predict neutral words.  But the end results were not very different from what you now see. <br><br>  <b>- How does this list distinguish between positive and negative words?</b>  <b>Is it not context sensitive?</b> <br><br>  - Good question.  The analysis of common tonalities is not as simple as it seems.  The border is rather arbitrary in some places.  In this list, the word “impudent” is marked as “bad,” and “ambitious” as “good.”  “Comical” is bad, and “funny” is good.  “Refund” is good, although it is usually mentioned in a bad context, when you owe someone money or someone owes you. <br><br>  Everyone understands that the tonality is determined by the context, but in a simple model one has to ignore the context and hope that the average tonality will be guessed correctly. </blockquote><br>  Using the <code>train_test_split</code> function, <code>train_test_split</code> simultaneously divide input vectors, output values ​​and labels into training and test data, while leaving 10% for testing. <br><br><pre> <code class="python hljs">train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Now we create a classifier and pass vectors through it in 100 iterations.  We use the logistic loss function so that the final classifier can infer the probability that the word is positive or negative. <br><br><pre> <code class="python hljs">model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) SGDClassifier(alpha=<span class="hljs-number"><span class="hljs-number">0.0001</span></span>, average=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, class_weight=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, epsilon=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, eta0=<span class="hljs-number"><span class="hljs-number">0.0</span></span>, fit_intercept=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, l1_ratio=<span class="hljs-number"><span class="hljs-number">0.15</span></span>, learning_rate=<span class="hljs-string"><span class="hljs-string">'optimal'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_jobs=<span class="hljs-number"><span class="hljs-number">1</span></span>, penalty=<span class="hljs-string"><span class="hljs-string">'l2'</span></span>, power_t=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, warm_start=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  We evaluate the classifier on test vectors.  It demonstrates 95% accuracy.  Not bad. <br><br> <code>accuracy_score(model.predict(test_vectors), test_targets) <br> 0.95022624434389136</code> <br> <br>  We define the tonality prediction function for certain words, and then use it with some examples from test data. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vecs_to_sentiment</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(vecs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># predict_log_proba показывает log-вероятность для каждого класса predictions = model.predict_log_proba(vecs) # Для сведения воедино положительной и отрицательной классификации # вычитаем log-вероятность отрицательной тональности из положительной. return predictions[:, 1] - predictions[:, 0] def words_to_sentiment(words): vecs = embeddings.loc[words].dropna() log_odds = vecs_to_sentiment(vecs) return pd.DataFrame({'sentiment': log_odds}, index=vecs.index) # Показываем 20 примеров из тестового набора данных words_to_sentiment(test_labels).ix[:20]</span></span></code> </pre> <br><table border="1" width="350"><thead><tr><th></th><th>  key </th></tr></thead><tbody><tr><th>  fidget </th><td>  -9.931679 </td></tr><tr><th>  interrupt </th><td>  -9.634706 </td></tr><tr><th>  bravely </th><td>  1.466919 </td></tr><tr><th>  imaginary </th><td>  -2.989215 </td></tr><tr><th>  taxation </th><td>  0.468522 </td></tr><tr><th>  world famous </th><td>  6.908561 </td></tr><tr><th>  inexpensive </th><td>  9.237223 </td></tr><tr><th>  disappointment </th><td>  -8.737182 </td></tr><tr><th>  totalitarian </th><td>  -10.851580 </td></tr><tr><th>  warlike </th><td>  -8.328674 </td></tr><tr><th>  freezes </th><td>  -8.456981 </td></tr><tr><th>  sin </th><td>  -7.839670 </td></tr><tr><th>  fragile </th><td>  -4.018289 </td></tr><tr><th>  fooled </th><td>  -4.309344 </td></tr><tr><th>  unsolved </th><td>  -2.816172 </td></tr><tr><th>  cleverly </th><td>  2.339609 </td></tr><tr><th>  demonizes </th><td>  -2.102152 </td></tr><tr><th>  carefree </th><td>  8.747150 </td></tr><tr><th>  unpopular </th><td>  -7.887475 </td></tr><tr><th>  to sympathize </th><td>  1.790899 </td></tr></tbody></table><br>  It can be seen that the classifier works.  He learned to generalize tonality in words outside the training data. <br><br><h1>  Step 4. Get the tonality estimate for the text. </h1><br>  There are many ways to add a vector to the overall score.  Again, we follow the path of least resistance, so we just take the average value. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re TOKEN_RE = re.compile(<span class="hljs-string"><span class="hljs-string">r"\w.*?\b"</span></span>) <span class="hljs-comment"><span class="hljs-comment"># regex находит объекты, которые начинаются с буквы (\w) и продолжает # сравнивать символы (.+?) до окончания слова (\b). Это относительно # простое выражение для извлечения слов из текста. def text_to_sentiment(text): tokens = [token.casefold() for token in TOKEN_RE.findall(text)] sentiments = words_to_sentiment(tokens) return sentiments['sentiment'].mean()</span></span></code> </pre> <br>  Here a lot of things suggest optimization: <br><br><ul><li>  The introduction of the inverse relationship between the weight of the word and its frequency, so that the same prepositions do not strongly influence the tonality. </li><li>  Setting that short sentences do not end with extreme values ​​of tonality. </li><li>  Phrase counting. </li><li>  A more robust word segmentation algorithm that apostrophes do not bring down. </li><li>  Consideration of negatives like “not satisfied”. </li></ul><br>  But everything requires additional code and does not fundamentally change the results.  At least, now you can roughly compare different sentences: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is pretty cool"</span></span>) <span class="hljs-number"><span class="hljs-number">3.889968926086298</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is okay"</span></span>) <span class="hljs-number"><span class="hljs-number">2.7997773492425186</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"meh, this example sucks"</span></span>) <span class="hljs-number"><span class="hljs-number">-1.1774475917460698</span></span></code> </pre> <br><h1>  Step 5. Behold the monster we created </h1><br>  Not every sentence is clearly toned.  Let's see what happens with neutral sentences: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Italian food"</span></span>) <span class="hljs-number"><span class="hljs-number">2.0429166109408983</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Chinese food"</span></span>) <span class="hljs-number"><span class="hljs-number">1.4094033658140972</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Mexican food"</span></span>) <span class="hljs-number"><span class="hljs-number">0.38801985560121732</span></span></code> </pre> <br>  I have already met such a phenomenon when analyzing reviews of restaurants, taking into account the vector representations of words.  For no apparent reason <a href="http://blog.conceptnet.io/2017/04/24/conceptnet-numberbatch-17-04-better-less-stereotyped-word-vectors/">, all Mexican restaurants had a lower grade</a> . <br><br>  Vector representations capture subtle sense differences in context.  Therefore, they reflect the prejudices of our society. <br><br>  Here are some other neutral suggestions: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Emily"</span></span>) <span class="hljs-number"><span class="hljs-number">2.2286179364745311</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Heather"</span></span>) <span class="hljs-number"><span class="hljs-number">1.3976291151079159</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Yvette"</span></span>) <span class="hljs-number"><span class="hljs-number">0.98463802132985556</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Shaniqua"</span></span>) <span class="hljs-number"><span class="hljs-number">-0.47048131775890656</span></span></code> </pre> <br>  Well damn… <br><br>  The system associated with the names of people completely different feelings.  You can look at these and many other examples and see that tonality is usually higher for stereotypically white names and lower for stereotypically black names. <br><br>  This test was used by Kaliskan, Bryson and Narayanan in his scientific work published in the journal <i>Science</i> in April 2017.  It proves that the <a href="http://opus.bath.ac.uk/55288/">semantics of the language corpus contains social prejudices</a> .  We will use this method. <br><br><h1>  Step 6. Assessing the problem </h1><br>  We want to understand how to avoid such mistakes.  Let's skip more data through the classifier and statistically measure its “bias”. <br><br>  Here we have four lists of names that reflect different ethnic origins, mainly in the United States.  The first two are lists of predominantly “white” and “black” names, adapted on the basis of an article by Kaliskana et al. I also added Spanish and Muslim names from Arabic and Urdu. <br><br>  This data is used to test the bias of the algorithm during the ConceptNet build process: it can be found in the <code>conceptnet5.vectors.evaluation.bias</code> module.  There is an idea to expand the dictionary to other ethnic groups, taking into account not only names, but also surnames. <br><br>  Here are the listings: <br><br><pre> <code class="python hljs">NAMES_BY_ETHNICITY = { <span class="hljs-comment"><span class="hljs-comment"># Первые два списка из приложения к научной статье Калискана и др. 'White': [ 'Adam', 'Chip', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Ian', 'Justin', 'Ryan', 'Andrew', 'Fred', 'Jack', 'Matthew', 'Stephen', 'Brad', 'Greg', 'Jed', 'Paul', 'Todd', 'Brandon', 'Hank', 'Jonathan', 'Peter', 'Wilbur', 'Amanda', 'Courtney', 'Heather', 'Melanie', 'Sara', 'Amber', 'Crystal', 'Katie', 'Meredith', 'Shannon', 'Betsy', 'Donna', 'Kristin', 'Nancy', 'Stephanie', 'Bobbie-Sue', 'Ellen', 'Lauren', 'Peggy', 'Sue-Ellen', 'Colleen', 'Emily', 'Megan', 'Rachel', 'Wendy' ], 'Black': [ 'Alonzo', 'Jamel', 'Lerone', 'Percell', 'Theo', 'Alphonse', 'Jerome', 'Leroy', 'Rasaan', 'Torrance', 'Darnell', 'Lamar', 'Lionel', 'Rashaun', 'Tyree', 'Deion', 'Lamont', 'Malik', 'Terrence', 'Tyrone', 'Everol', 'Lavon', 'Marcellus', 'Terryl', 'Wardell', 'Aiesha', 'Lashelle', 'Nichelle', 'Shereen', 'Temeka', 'Ebony', 'Latisha', 'Shaniqua', 'Tameisha', 'Teretha', 'Jasmine', 'Latonya', 'Shanise', 'Tanisha', 'Tia', 'Lakisha', 'Latoya', 'Sharise', 'Tashika', 'Yolanda', 'Lashandra', 'Malika', 'Shavonn', 'Tawanda', 'Yvette' ], # Список испанских имён составлен по данным переписи населения США. 'Hispanic': [ 'Juan', 'José', 'Miguel', 'Luís', 'Jorge', 'Santiago', 'Matías', 'Sebastián', 'Mateo', 'Nicolás', 'Alejandro', 'Samuel', 'Diego', 'Daniel', 'Tomás', 'Juana', 'Ana', 'Luisa', 'María', 'Elena', 'Sofía', 'Isabella', 'Valentina', 'Camila', 'Valeria', 'Ximena', 'Luciana', 'Mariana', 'Victoria', 'Martina' ], # Следующий список объединяет религию и этническую # принадлежность, я в курсе. Также как и сами имена. # # Он составлен по данным сайтов с именами детей для # родителей-мусульман в английском написании. Я не проводил # грани между арабским, урду и другими языками. # # Буду рад обновить список более авторитетными данными. 'Arab/Muslim': [ 'Mohammed', 'Omar', 'Ahmed', 'Ali', 'Youssef', 'Abdullah', 'Yasin', 'Hamza', 'Ayaan', 'Syed', 'Rishaan', 'Samar', 'Ahmad', 'Zikri', 'Rayyan', 'Mariam', 'Jana', 'Malak', 'Salma', 'Nour', 'Lian', 'Fatima', 'Ayesha', 'Zahra', 'Sana', 'Zara', 'Alya', 'Shaista', 'Zoya', 'Yasmin' ] }</span></span></code> </pre> <br>  With the help of Pandas we will compile a table of names, their predominant ethnic origin and assessment of tonality: <br><br><pre> <code class="plaintext hljs">def name_sentiment_table(): frames = [] for group, name_list in sorted(NAMES_BY_ETHNICITY.items()): lower_names = [name.lower() for name in name_list] sentiments = words_to_sentiment(lower_names) sentiments['group'] = group frames.append(sentiments) # Сводим данные со всех этнических групп в одну большую таблицу return pd.concat(frames) name_sentiments = name_sentiment_table()</code> </pre> <br>  Sample data: <br><br> <code>name_sentiments.ix[::25]</code> <br> <table border="1" width="350"><thead><tr><th></th><th>  key </th><th>  Group </th></tr></thead><tbody><tr><th>  mohammed </th><td>  0.834974 </td><td>  Arab / Muslim </td></tr><tr><th>  alya </th><td>  3.916803 </td><td>  Arab / Muslim </td></tr><tr><th>  terryl </th><td>  -2.858010 </td><td>  Black </td></tr><tr><th>  josé </th><td>  0.432956 </td><td>  Hispanic </td></tr><tr><th>  luciana </th><td>  1.086073 </td><td>  Hispanic </td></tr><tr><th>  hank </th><td>  0.391858 </td><td>  White </td></tr><tr><th>  megan </th><td>  2.158679 </td><td>  White </td></tr></tbody></table><br>  Make a graph of the distribution of tonality for each name. <br><br><pre> <code class="python hljs">plot = seaborn.swarmplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments) plot.set_ylim([<span class="hljs-number"><span class="hljs-number">-10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>])</code> </pre> <br> <code>(-10, 10)</code> <br> <br><img src="https://habrastorage.org/webt/qv/y7/ge/qvy7gel8rrvm5txo-nou6g0i0re.png"><br><br>  Or in the form of a histogram with confidence intervals for averages of 95%. <br><br><pre> <code class="python hljs">plot = seaborn.barplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments, capsize=<span class="hljs-number"><span class="hljs-number">.1</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/uv/ib/n6/uvibn6olthaxt6cxbd96szehq94.png"><br><br>  Finally, run the <a href="http://www.statsmodels.org/stable/index.html">statsmodels</a> serious statistical package.  It will show how great the bias of the algorithm is (along with a bunch of other statistics). <br><br><br>  <font color="gray">OLS Regression Results</font> <br><table><tbody><tr><th>  Dep.  Variable: </th><td>  sentiment </td><th>  R-squared: </th><td>  0.208 </td></tr><tr><th>  Model: </th><td>  Ols </td><th>  Adj.  R-squared: </th><td>  0.192 </td></tr><tr><th>  Method: </th><td>  Least squares </td><th>  F-statistic: </th><td>  13.04 </td></tr><tr><th>  Date: </th><td>  Thu, 13 Jul 2017 </td><th>  Prob (F-statistic): </th><td>  1.31e-07 </td></tr><tr><th>  Time: </th><td>  11:31:17 </td><th>  Log-Likelihood: </th><td>  -356.78 </td></tr><tr><th>  No.  Observations: </th><td>  153 </td><th>  AIC: </th><td>  721.6 </td></tr><tr><th>  Df Residuals: </th><td>  149 </td><th>  BIC: </th><td>  733.7 </td></tr><tr><th>  Df Model: </th><td>  3 </td><th></th><td></td></tr><tr><th>  Covariance Type: </th><td>  nonrobust </td><th></th><td></td></tr></tbody></table><br>  F-statistic is the ratio of variation between groups to variation within groups, which can be taken as a general assessment of bias. <br><br>  Immediately below it is the probability that we will see the maximum F-statistic with a null hypothesis: that is, if there is no difference between the compared options.  The probability is very, very low.  In a scientific article, we would call the result “very statistically significant.” <br><br>  We need to improve the f-value.  The lower the better. <br><br> <code>ols_model.fvalue <br> 13.041597745167659</code> <br> <br><h1>  Step 7. Try other data. </h1><br>  Now we have the opportunity to numerically measure the harmful bias of the model.  Let's try to correct it.  To do this, you need to repeat a bunch of things that used to be just separate steps in a Python notepad. <br><br>  If I wrote good, supported code, I would not use global variables, such as <code>model</code> and <code>embeddings</code> .  But the current spaghetti code allows you to better examine each step and understand what is happening.  We reuse part of the code and at least define a function to repeat some steps: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">retrain_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(new_embs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Повторяем шаги с новым набором данных. """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> model, embeddings, name_sentiments embeddings = new_embs pos_vectors = embeddings.loc[pos_words].dropna() neg_vectors = embeddings.loc[neg_words].dropna() vectors = pd.concat([pos_vectors, neg_vectors]) targets = np.array([<span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> pos_vectors.index] + [<span class="hljs-number"><span class="hljs-number">-1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> neg_vectors.index]) labels = list(pos_vectors.index) + list(neg_vectors.index) train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>) model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) accuracy = accuracy_score(model.predict(test_vectors), test_targets) print(<span class="hljs-string"><span class="hljs-string">"Accuracy of sentiment: {:.2%}"</span></span>.format(accuracy)) name_sentiments = name_sentiment_table() ols_model = statsmodels.formula.api.ols(<span class="hljs-string"><span class="hljs-string">'sentiment ~ group'</span></span>, data=name_sentiments).fit() print(<span class="hljs-string"><span class="hljs-string">"F-value of bias: {:.3f}"</span></span>.format(ols_model.fvalue)) print(<span class="hljs-string"><span class="hljs-string">"Probability given null hypothesis: {:.3}"</span></span>.format(ols_model.f_pvalue)) <span class="hljs-comment"><span class="hljs-comment"># Выводим результаты на график с совместимой осью Y plot = seaborn.swarmplot(x='group', y='sentiment', data=name_sentiments) plot.set_ylim([-10, 10])</span></span></code> </pre> <br><h3>  We try word2vec </h3><br>  It can be assumed that only GloVe has a problem.  Probably, in the Common Crawl base there are a lot of doubtful sites and at least 20 copies of the Urban Dictionary street slang dictionary.  It may be better on another base: how about the good old word2vec, trained on Google News? <br><br>  It seems the most authoritative source for word2vec data is <a href="https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit%3Fusp%3Dsharing">this file on Google Drive</a> .  Download it and save as <code>data/word2vec-googlenews-300.bin.gz</code> . <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Используем функцию ConceptNet для загрузки word2vec во фрейм Pandas из его бинарного формата from conceptnet5.vectors.formats import load_word2vec_bin w2v = load_word2vec_bin('data/word2vec-googlenews-300.bin.gz', nrows=2000000) # Модель word2vec чувствительна к регистру w2v.index = [label.casefold() for label in w2v.index] # Удаляем дубликаты, которые реже встречаются w2v = w2v.reset_index().drop_duplicates(subset='index', keep='first').set_index('index') retrain_model(w2v)</span></span></code> </pre> <br> <code>Accuracy of sentiment: 94.30% <br> F-value of bias: 15.573 <br> Probability given null hypothesis: 7.43e-09</code> <br> <br>  So word2vec was even worse with an F-value of more than 15. <br><br>  In principle, it was foolish to expect the <i>news to</i> be better protected from bias. <br><br><h3>  We try ConceptNet Numberbatch </h3><br>  Finally, I can talk about my own project on the vector representation of words. <br><br>  ConceptNet with the function of vector representations is the knowledge graph I work on.  It normalizes vector representations at the training stage, identifying and removing some sources of algorithmic racism and sexism.  This method of correcting bias is based on the scientific article by Bulukbasi et al. <a href="https://arxiv.org/abs/1607.06520">“Debiasing Word Embeddings”</a> and is generalized to eliminate several types of bias simultaneously.  As far as I know, this is the only semantic system in which there is something similar. <br><br>  From time to time, we export precomputed vectors from ConceptNet — these releases are called <a href="https://github.com/commonsense/conceptnet-numberbatch">ConceptNet Numberbatch</a> .  In April 2017, the first release came out with a bias correction, so we’ll load the English-speaking vectors and retrain our model. <br><br>  <code><a href="">numberbatch-en-17.04b.txt.gz</a></code> , save in the <code>data/</code> directory and retrain the model: <br><br><pre> <code class="python hljs">retrain_model(load_embeddings(<span class="hljs-string"><span class="hljs-string">'data/numberbatch-en-17.04b.txt'</span></span>))</code> </pre> <br> <code>Accuracy of sentiment: 97.46% <br> F-value of bias: 3.805 <br> Probability given null hypothesis: 0.0118</code> <br> <br><img src="https://habrastorage.org/webt/5d/iu/uq/5diuuqrst8bca5-m7fljox--pro.png"><br><br>  So did ConceptNet Numberbatch completely eliminate the problem?  No more algorithmic racism?  <b>Not.</b> <br><br>  Racism has become much less?  <b>Definitely</b> . <br><br>  The tonality ranges for ethnic groups overlap much more than in the GloVe or word2vec vectors.  Compared to GloVe, the value of F decreased more than three times, and compared to word2vec - more than four times.  And in general, we see much smaller differences in tonality when comparing different names: this should be so, because names really should not affect the result of the analysis. <br><br>  But a slight correlation still remained.  Perhaps I can pick up such data and training parameters that the problem seems solved.  But it will be a bad option, because <i>in fact the</i> problem remains, because in ConceptNet we have identified and compensated not all the causes of algorithmic racism.  But this is a good start. <br><br><h3>  No pitfalls </h3><br>  Note that with the transition to ConceptNet Numberbatch, the accuracy of tonality prediction has improved. <br><br>  Some might have suggested that the correction of algorithmic racism would worsen the results in some other way.  But no.  You may have data that is better and less racist. Данные реально улучшаются с этой коррекцией. Приобретённый от людей расизм word2vec и GloVe не имеет никакого отношения к точности работы алгоритма. <br><br><h1> Другие подходы </h1><br> Конечно, это только один способ анализа тональности. Какие-то детали можно реализовать иначе. <br><br> Вместо или в дополнение к смене векторной базы можно попытаться устранить эту проблему непосредственно в выдаче. Например, вообще устранить оценку тональности для имён и групп людей. <br><br> Есть вариант вообще отказаться от расчёта тональности всех слов, а рассчитывать её только для слов из списка. Пожалуй, это самая распространённая форма анализа тональности — вообще без машинного обучения. В результатах будет не больше предвзятости, чем у автора списка. Но отказ от машинного обучения означает уменьшение полноты (recall), а единственный способ адаптировать модель к набору данных — вручную отредактировать список. <br><br> В качестве гибридного подхода вы можете создать большое количество предполагаемых оценок тональности для слов и поручить человеку терпеливо их отредактировать, составить список слов-исключений с нулевой тональностью. Но это дополнительная работа. С другой стороны, вы действительно увидите, как работает модель. Думаю, в любом случае к этому следует стремиться. </div>